{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:45:54.153607Z",
     "start_time": "2024-11-18T22:45:54.146737Z"
    }
   },
   "source": [
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import unicodedata\n",
    "from datetime import timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybaseball\n",
    "import requests\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from bs4 import BeautifulSoup\n",
    "from pybaseball import statcast\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "pybaseball.cache.enable()\n",
    "\n",
    "# Load in my own 40 man Roster Scraper\n",
    "directory = os.path.expanduser('~/Desktop/Desktop - Cameron MacBook Pro/Random-Projects/MLB')\n",
    "sys.path.append(directory)\n",
    "from RosterScraper import RosterScraper"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in StatCast ID so batter names show in the Statcast data and loads in a scraped DF with every 40 man roster"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:46:03.768472Z",
     "start_time": "2024-11-18T22:45:54.348773Z"
    }
   },
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/1JgczhD5VDQ1EiXqVG-blttZcVwbZd5_Ne_mefUGwJnk/pub?output=csv'\n",
    "res = requests.get(url)\n",
    "ID = pd.read_csv(io.BytesIO(res.content), sep=',')\n",
    "ID.dropna(subset=['MLBID'], inplace=True)\n",
    "ID['MLBID'] = ID['MLBID'].astype(int)\n",
    "\n",
    "Rosters = RosterScraper()\n",
    "BID = Rosters[Rosters[\"Position\"] == \"Batter\"]\n",
    "PID = Rosters[Rosters[\"Position\"] == \"Pitcher\"]"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating functions for data manipulation so they can match when joining separate datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:46:03.776948Z",
     "start_time": "2024-11-18T22:46:03.769732Z"
    }
   },
   "source": [
    "def convert_name(name):\n",
    "    if name == 'Rockies':\n",
    "        return 'COL'\n",
    "    elif name == 'Reds':\n",
    "        return 'CIN'\n",
    "    elif name == 'Mariners':\n",
    "        return 'SEA'\n",
    "    elif name == 'Nationals':\n",
    "        return 'WSH'\n",
    "    elif name == 'Yankees':\n",
    "        return 'NYY'\n",
    "    elif name == 'Astros':\n",
    "        return 'HOU'\n",
    "    elif name == 'Red Sox':\n",
    "        return 'BOS'\n",
    "    elif name == 'Athletics':\n",
    "        return 'OAK'\n",
    "    elif name == 'Mets':\n",
    "        return 'NYM'\n",
    "    elif name == 'Braves':\n",
    "        return 'ATL'\n",
    "    elif name == 'Giants':\n",
    "        return 'SF'\n",
    "    elif name == 'Brewers':\n",
    "        return 'MIL'\n",
    "    elif name == 'Rays':\n",
    "        return 'TB'\n",
    "    elif name == 'Royals':\n",
    "        return 'KC'\n",
    "    elif name == 'White Sox':\n",
    "        return 'CWS'\n",
    "    elif name == 'Cubs':\n",
    "        return 'CHC'\n",
    "    elif name == 'Angels':\n",
    "        return 'LAA'\n",
    "    elif name == 'Tigers':\n",
    "        return 'DET'\n",
    "    elif name == 'Diamondbacks':\n",
    "        return 'ARI'\n",
    "    elif name == 'Guardians':\n",
    "        return 'CLE'\n",
    "    elif name == 'Orioles':\n",
    "        return 'BAL'\n",
    "    elif name == 'Twins':\n",
    "        return 'MIN'\n",
    "    elif name == 'Marlins':\n",
    "        return 'MIA'\n",
    "    elif name == 'Phillies':\n",
    "        return 'PHI'\n",
    "    elif name == 'Rangers':\n",
    "        return 'TEX'\n",
    "    elif name == 'Dodgers':\n",
    "        return 'LAD'\n",
    "    elif name == 'Padres':\n",
    "        return 'SD'\n",
    "    elif name == 'Pirates':\n",
    "        return 'PIT'\n",
    "    elif name == 'Blue Jays':\n",
    "        return 'TOR'\n",
    "    elif name == 'Cardinals':\n",
    "        return 'STL'\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def flip_names(name):\n",
    "    first_name, last_name = name.split(\", \")\n",
    "    return f\"{last_name} {first_name}\"\n",
    "\n",
    "def replace_special_chars(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "def append_suffix_to_duplicates(df, column):\n",
    "        seen = {}\n",
    "        for idx, value in enumerate(df[column]):\n",
    "            if value in seen:\n",
    "                seen[value] += 1\n",
    "                df.at[idx, column] = f\"{value}2\"\n",
    "            else:\n",
    "                seen[value] = 1"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the RotoGrinders website for daily pitchers and lineups"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:46:03.868915Z",
     "start_time": "2024-11-18T22:46:03.777804Z"
    }
   },
   "source": [
    "def getDKData2024():\n",
    "    eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
    "    todaysdate = eastern_time.strftime(\"%m-%d-%Y\")\n",
    "    url = 'https://rotogrinders.com/lineups/mlb?site=draftkings'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    gamelist = []\n",
    "    gamecards = soup.findAll(\"div\", {\"class\": \"game-card-teams\"})\n",
    "    for x in gamecards:\n",
    "        twoteams = x.findAll(\"span\", {\"class\": \"team-nameplate-mascot\"})\n",
    "        roadteam = convert_name(twoteams[0].text)\n",
    "        hometeam = convert_name(twoteams[1].text)\n",
    "        gamekey = \"{}@{}\".format(roadteam,hometeam)\n",
    "        gamelist.append(gamekey)\n",
    "\n",
    "    matchupsdf = pd.DataFrame()\n",
    "    for game in gamelist:\n",
    "        roadteam = game.split(\"@\")[0]\n",
    "        hometeam = game.split(\"@\")[1]\n",
    "        thisdf1 = pd.DataFrame({\"Team\": roadteam, \"Opp\": hometeam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
    "        thisdf2 = pd.DataFrame({\"Team\": hometeam, \"Opp\": roadteam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
    "        matchupsdf = pd.concat([matchupsdf,thisdf1,thisdf2])\n",
    "        \n",
    "    oppdict = dict(zip(matchupsdf.Team,matchupsdf.Opp))\n",
    "    hometeamdict = dict(zip(matchupsdf.Team,matchupsdf.HomeTeam))\n",
    "    roadteamdict = dict(zip(matchupsdf.Team,matchupsdf.RoadTeam))\n",
    "\n",
    "    disabled_span_list = []\n",
    "    for span in soup.findAll(\"span\", {\"class\": \"player-nameplate disabled\"}):\n",
    "        for a in span.findAll(\"a\"):\n",
    "            disabled_span_list.append(a.text)\n",
    "\n",
    "    spdata = pd.DataFrame()\n",
    "    for div in soup.findAll(\"span\", {\"class\": \"player-nameplate\", \"data-position\": \"SP\"}):\n",
    "        if \"TBD\" in str(div):\n",
    "            playername = \"TBD\"\n",
    "            pos = \"SP\"\n",
    "            sal = 0\n",
    "        else:\n",
    "            for a in div.findAll('a', {'class': 'player-nameplate-name'}):\n",
    "                playername = a.text.strip()\n",
    "\n",
    "            strdiv = str(div)\n",
    "            pos = strdiv[strdiv.find(\"data-position\")+15:strdiv.find(\"data-salary\")-2]\n",
    "            sal = strdiv[strdiv.find(\"data-salary\")+13:strdiv.find(\"<div class = 'player-nameplate-info'>\")-3]\n",
    "        try:\n",
    "            ownership = strdiv[strdiv.find('<span class=\"small muted\" data-auth=\"502\">') + 42:strdiv.find('%')]\n",
    "            ownership = ownership.replace(\"</span>\", \"\")\n",
    "            ownership = ownership.replace(\"</span\", \"\")\n",
    "            ownership = ownership.replace(\"</div>\", \"\")\n",
    "            ownership = ownership.replace(\" \", \"\")\n",
    "        except:\n",
    "            ownership = np.nan\n",
    "\n",
    "        thisspdata = pd.DataFrame([[playername, sal, ownership]], columns = [\"Player\", \"Salary\", \"Ownership\"])\n",
    "        spdata = pd.concat([spdata, thisspdata])\n",
    "\n",
    "    spdata['Player'] = spdata['Player'].replace('Luis Ortiz', 'Luis L. Ortiz')\n",
    "    spdata['Player'] = spdata['Player'].replace('Mike King', 'Michael King')\n",
    "    spdata['Player'] = spdata['Player'].replace('Robert Zastryzny', 'Rob Zastryzny')\n",
    "\n",
    "    spdata2 = pd.merge(spdata, PID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"PitcherTeam\"})\n",
    "    spdata3 = pd.merge(spdata2, matchupsdf[[\"Team\", \"Opp\"]], left_on = [\"PitcherTeam\"], right_on = [\"Team\"], how = \"left\").drop(columns = [\"Team\"])\n",
    "\n",
    "    append_suffix_to_duplicates(spdata3, 'PitcherTeam')\n",
    "    append_suffix_to_duplicates(spdata3, 'Opp')\n",
    "\n",
    "    opp_spname_dict = dict(zip(spdata3.Opp, spdata3.Player))\n",
    "    opp_spsal_dict = dict(zip(spdata3.Opp, spdata.Salary))\n",
    "    opp_spown_dict = dict(zip(spdata3.Opp, spdata3.Ownership))\n",
    "\n",
    "    ludf = pd.DataFrame()\n",
    "    \n",
    "    for li in soup.findAll(\"li\", {\"class\": \"lineup-card-player\"}):\n",
    "        for a in li.findAll(\"a\", {\"class\": [\"player-nameplate-name\", \"player-nameplate disabled\"]}):\n",
    "            playername = a.text\n",
    "\n",
    "        listring = str(li)\n",
    "        for span in li.find(\"span\", {\"class\": \"small\"}):\n",
    "            luspot = span.text\n",
    "            luspot = luspot.replace(\"\\n\", \"\")\n",
    "            luspot = luspot.strip()\n",
    "            luspot = int(luspot)\n",
    "        pos = listring[listring.find(\"data-position\")+15:listring.find(\"data-salary\")-2]\n",
    "        sal = listring[listring.find(\"data-salary\")+13:listring.find(\"<span class='small'>\")-3]\n",
    "        ownership = ownership.replace(\"</span>\", \"\")\n",
    "        ownership = ownership.replace(\"</span\", \"\")\n",
    "        ownership = ownership.replace(\"</li\", \"\")\n",
    "        ownership = ownership.replace(\"</div>\", \"\")\n",
    "        ownership = ownership.replace(\" \", \"\")\n",
    "\n",
    "        try:\n",
    "            sal = int(sal)\n",
    "        except:\n",
    "            sal = 0\n",
    "        thisludf = pd.DataFrame([[playername, luspot, sal, ownership]], columns = [\"Player\", \"Spot\", \"Sal\", \"Ownership\"])\n",
    "        ludf = pd.concat([ludf, thisludf])\n",
    "\n",
    "    ludf2 = pd.merge(ludf, BID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"BatterTeam\"})\n",
    "    ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
    "    ludf2['HomeTeam'] = ludf2['BatterTeam'].map(hometeamdict)\n",
    "    ludf2['RoadTeam'] = ludf2['BatterTeam'].map(roadteamdict)\n",
    "\n",
    "    ludf2_teamlist = list(ludf2[\"BatterTeam\"])\n",
    "\n",
    "    dhteams = []\n",
    "    for x in ludf2_teamlist:\n",
    "        if ludf2_teamlist.count(x) > 11:\n",
    "            if x in dhteams:\n",
    "                pass\n",
    "            else:\n",
    "                dhteams.append(x)\n",
    "\n",
    "    extract_dh = ludf2[ludf2[\"BatterTeam\"].isin(dhteams)]\n",
    "    new_ludf2 = ludf2[~ludf2[\"BatterTeam\"].isin(dhteams)]\n",
    "\n",
    "    new_team_list = []\n",
    "    new_home_list = []\n",
    "    new_road_list = []\n",
    "    runcounter = 0\n",
    "\n",
    "    for x, home, road in zip(extract_dh[\"BatterTeam\"].astype(str), \n",
    "                         extract_dh[\"HomeTeam\"].astype(str), \n",
    "                         extract_dh[\"RoadTeam\"].astype(str)):\n",
    "        if runcounter < 18:\n",
    "            new_team_list.append(x)\n",
    "            new_home_list.append(home)\n",
    "            new_road_list.append(road)\n",
    "            runcounter += 1\n",
    "        else:\n",
    "            new_team_list.append(x + \"2\")\n",
    "            new_home_list.append(home + \"2\")\n",
    "            new_road_list.append(road + \"2\")\n",
    "            runcounter += 1\n",
    "\n",
    "    extract_dh[\"BatterTeam\"] = new_team_list\n",
    "    extract_dh[\"HomeTeam\"] = new_home_list\n",
    "    extract_dh[\"RoadTeam\"] = new_road_list\n",
    "\n",
    "    ludf2 = pd.concat([extract_dh, new_ludf2])\n",
    "    ludf2[\"Opp\"] = ludf2[\"BatterTeam\"].map(oppdict)\n",
    "    ludf2['SP'] = ludf2['BatterTeam'].map(opp_spname_dict)\n",
    "    ludf2['SPSal'] = ludf2['BatterTeam'].map(opp_spsal_dict)\n",
    "    ludf2['SPOwnership'] = ludf2['BatterTeam'].map(opp_spown_dict)\n",
    "    ludf2['Date'] = todaysdate\n",
    "    ludf2['Time'] = np.nan\n",
    "\n",
    "    ludf3 = ludf2[['BatterTeam','RoadTeam','HomeTeam','Time','Spot','Player','Sal','Ownership','Date', \"SP\"]]\n",
    "\n",
    "    dkdata = ludf3.copy()\n",
    "\n",
    "    try:\n",
    "        checknan = dkdata[[\"BatterTeam\", \"SP\"]]\n",
    "        getnans = checknan[[\"SP\"].isna()]\n",
    "        if len(getnans) == 0:\n",
    "            nonans = 1\n",
    "            nanmapdict = {}\n",
    "        else:\n",
    "            nonans = 0\n",
    "            getnans[\"SP\"] = disabled_span_list\n",
    "            nanmapdict = dict(zip(getnans.Team, getnans.SP))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        dkdata[\"SP\"] = np.where(dkdata[\"SP\"].isna(), dkdata[\"BatterTeam\"].map(nanmapdict), dkdata[\"SP\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(1, len(dkdata) - 1):\n",
    "        if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i-1, 'BatterTeam']:\n",
    "            if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i+1, 'BatterTeam']:\n",
    "                dkdata.loc[i, 'BatterTeam'] = np.nan\n",
    "                dkdata.loc[i, 'HomeTeam'] = np.nan\n",
    "                dkdata.loc[i, 'RoadTeam'] = np.nan\n",
    "                dkdata.loc[i, 'SP'] = np.nan\n",
    "\n",
    "    \n",
    "    dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n",
    "    dkdata = dkdata.drop_duplicates(subset = [\"BatterTeam\", \"SP\"], keep = \"first\")\n",
    "    dkdata = dkdata.drop(columns = [\"Time\", \"Sal\", \"Ownership\"])\n",
    "\n",
    "    dkdata['BatterTeam'] = dkdata['BatterTeam'].replace('ARI', 'AZ')\n",
    "    dkdata['RoadTeam'] = dkdata['RoadTeam'].replace('ARI', 'AZ')\n",
    "    dkdata['HomeTeam'] = dkdata['HomeTeam'].replace('ARI', 'AZ')\n",
    "\n",
    "    dkdata['Date'] = pd.to_datetime(dkdata['Date'])\n",
    "    dkdata['Date'] = dkdata['Date'].dt.strftime('%Y-%m-%d')\n",
    "    dkdata = dkdata.set_index(\"Date\")\n",
    "    dkdata = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\", \"SP\"]]\n",
    "\n",
    "    return(dkdata)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:46:03.915544Z",
     "start_time": "2024-11-18T22:46:03.870211Z"
    }
   },
   "source": [
    "Train3 = pd.read_csv(\"~/Desktop/Desktop - Cameron MacBook Pro/Random-Projects/MLB/Data/DailyPitcherModelTrainingData.csv\")\n",
    "Train3 = Train3.drop(Train3.columns[0], axis=1)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DF where it only loads in the stats of starting pitchers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:46:03.919573Z",
     "start_time": "2024-11-18T22:46:03.916535Z"
    }
   },
   "source": [
    "# Group by game and team identifiers\n",
    "groupby_cols = ['game_date', 'BatterTeam', 'away_team', 'home_team']\n",
    "\n",
    "# Function to keep only the starter's data\n",
    "def keep_starter(group):\n",
    "    starter_name = group['player_name'].iloc[0]\n",
    "    return group[group['player_name'] == starter_name]\n",
    "\n",
    "def count_outs(x):\n",
    "    single_outs = ['other_out', 'strikeout', 'field_out', \"force_out\", 'fielders_choice', 'fielders_choice_out', \"sac_fly\", \"sac_bunt\", \"caught_stealing_2b\", \"caught_stealing_3b\", \"caught_stealing_home\", \"pickoff_caught_stealing_2b\",  \"pickoff_caught_stealing_3b\",  \"pickoff_caught_stealing_home\"]\n",
    "    double_outs = ['double_play', 'strikeout_double_play', 'grounded_into_double_play', \"sac_fly_double_play\"]\n",
    "    triple_outs = ['triple_play']\n",
    "    \n",
    "    outs = (x.isin(single_outs)).sum() + 2 * (x.isin(double_outs)).sum() + 3 * (x.isin(triple_outs)).sum()\n",
    "    return outs"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in today's data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:46:04.277599Z",
     "start_time": "2024-11-18T22:46:03.920102Z"
    }
   },
   "source": [
    "TodaysData = getDKData2024()\n",
    "TodaysData"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Team'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_56556/42820160.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mTodaysData\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetDKData2024\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mTodaysData\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_56556/2850615655.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0mthisdf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"Team\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mroadteam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Opp\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mhometeam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"RoadTeam\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mroadteam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"HomeTeam\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mhometeam\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mthisdf2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"Team\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mhometeam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Opp\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mroadteam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"RoadTeam\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mroadteam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"HomeTeam\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mhometeam\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0mmatchupsdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mthisdf1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mthisdf2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m     \u001B[0moppdict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTeam\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOpp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m     \u001B[0mhometeamdict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTeam\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mHomeTeam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0mroadteamdict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTeam\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmatchupsdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRoadTeam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/AirQualityIndex_Analysis/lib/python3.12/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   6295\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6296\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6297\u001B[0m         \u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6298\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6299\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'Team'"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
    "savant2024 = statcast(start_dt = \"2024-03-28\", end_dt = eastern_time.strftime(\"%Y-%m-%d\"))\n",
    "savant2024['game_date'] = pd.to_datetime(savant2024['game_date'])\n",
    "savant2024['game_date'] = savant2024['game_date'].dt.strftime('%Y-%m-%d')\n",
    "savant2024['BatterTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['away_team'], savant2024['home_team'])\n",
    "savant2024['PitcherTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['home_team'], savant2024['away_team'])\n",
    "savant2024 = pd.merge(savant2024, ID[[\"MLBID\", \"MLBNAME\"]], left_on = 'batter', right_on = 'MLBID', how = 'left')\n",
    "savant2024.dropna(subset=['MLBNAME'], inplace=True)\n",
    "savant2024 = savant2024.drop_duplicates(subset = [\"pitch_type\", \"game_date\", \"release_speed\", \"release_pos_x\", \"release_pos_z\", \"player_name\"], keep='first')\n",
    "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(flip_names)\n",
    "savant2024['AwayRunsScored'] = savant2024['post_away_score'] - savant2024['away_score']\n",
    "savant2024['HomeRunsScored'] = savant2024['post_home_score'] - savant2024['home_score']\n",
    "savant2024 = savant2024[[\"game_date\", \"home_team\", \"away_team\", \"inning\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\", \"pitch_type\", \"BatterTeam\", \"MLBNAME\", \"balls\", \"strikes\", \"outs_when_up\", \"events\", \"description\", \"bb_type\", \"hit_distance_sc\", \"launch_speed\", \"launch_angle\", \"estimated_ba_using_speedangle\", \"estimated_woba_using_speedangle\", \"woba_value\", \"p_throws\", \"PitcherTeam\", \"player_name\", \"delta_home_win_exp\", \"delta_run_exp\", \"away_score\", \"home_score\", \"AwayRunsScored\", \"HomeRunsScored\"]].sort_values(by = [\"game_date\", \"home_team\", \"away_team\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\"], ascending=[True, True, True, False, True, True])\n",
    "savant2024 = savant2024.groupby(groupby_cols).apply(keep_starter).reset_index(drop = True)\n",
    "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(replace_special_chars)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the same grouping as the training data at the various levels"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season1 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    Hit = ('events', lambda x: (x.isin(['single', 'double', 'triple', 'home_run'])).sum()),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season2 = Season1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"Pitches\", \"sum\"),\n",
    "    AB = (\"at_bat_number\", \"size\"),\n",
    "    PA = (\"PA\", \"sum\"),\n",
    "    Outs = (\"Outs\", \"sum\"),\n",
    "    Hits = (\"Hit\", \"sum\"),\n",
    "    FB = (\"FB\", \"sum\"),\n",
    "    HR = (\"HR\", \"sum\"),\n",
    "    HBP = (\"HBP\", \"sum\"),\n",
    "    Balls = (\"Balls\", \"sum\"),\n",
    "    BB = (\"BB\", \"sum\"),\n",
    "    CS = (\"CS\", \"sum\"),\n",
    "    Whiff = (\"Whiff\", \"sum\"),\n",
    "    Strikes = (\"Strikes\", \"sum\"),\n",
    "    K = (\"K\", \"sum\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "Season2[\"IP\"] = Season2[\"Outs\"] / 3\n",
    "Season2['RA'] = np.where((Season2['HomeRunsScored'] > 0) & (Season2['BatterTeam'] == Season2['home_team']), Season2[\"HomeRunsScored\"],\n",
    "                        np.where((Season2['AwayRunsScored'] > 0) & (Season2['BatterTeam'] == Season2['away_team']),Season2[\"AwayRunsScored\"], 0))\n",
    "Season2[\"RA/9\"] = (27 * Season2[\"RA\"] / Season2[\"Outs\"])\n",
    "Season2 = Season2.drop(columns = [\"AwayRunsScored\", \"HomeRunsScored\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lgHR = 10048\n",
    "lgFB = 58110\n",
    "\n",
    "Season2['FIP'] = (13 * Season2['HR'] + 3 * (Season2['BB'] + Season2['HBP']) - 2 * Season2['K']) / (Season2['IP']) + 3.137\n",
    "Season2['xFIP'] = (13 * (Season2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (Season2['BB'] + Season2['HBP']) - 2 * Season2['K']) / (Season2['IP']) + 3.137\n",
    "\n",
    "Season2['K%'] = round((Season2['K'] / Season2['AB']) * 100, 2)\n",
    "Season2['BB%'] = round((Season2['BB'] / Season2['AB']) * 100, 2)\n",
    "Season2['K-BB%'] = Season2[\"K%\"] - Season2[\"BB%\"]\n",
    "Season2['Ball%'] = round((Season2['Balls'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['Strike%'] = round((Season2['Strikes'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['CS%'] = round((Season2['CS'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['Whiff%'] = round((Season2['Whiff'] / Season2['Pitches']) * 100, 2)\n",
    "Season2[\"CSW\"] = Season2[\"CS\"] + Season2[\"Whiff\"]\n",
    "Season2['CSW%'] = round((Season2['CSW'] / Season2['Pitches']) * 100, 2)\n",
    "Season2 = Season2.drop(columns=[\"CSW\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "window_size5 = 5\n",
    "window_size10 = 10\n",
    "window_size20 = 20\n",
    "\n",
    "# Rolling 5 game pitch averages\n",
    "Season2['Pitches5'] = Season2.groupby('player_name')['Pitches'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2 = Season2.drop(Season2[Season2['Pitches5'] < 40].index)\n",
    "# Rolling 5 and 10 game outs averages\n",
    "Season2['Outs5'] = Season2.groupby('player_name')['Outs'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['Outs10'] = Season2.groupby('player_name')['Outs'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected batting averages\n",
    "Season2['xBA5'] = Season2.groupby('player_name')['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xBA10'] = Season2.groupby('player_name')['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Season2['xwOBA5'] = Season2.groupby('player_name')['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xwOBA10'] = Season2.groupby('player_name')['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Season2['wOBA5'] = Season2.groupby('player_name')['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['wOBA10'] = Season2.groupby('player_name')['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Season2['RA5'] = Season2.groupby('player_name')['RA/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['RA10'] = Season2.groupby('player_name')['RA/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Season2['FIP5'] = Season2.groupby('player_name')['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['FIP10'] = Season2.groupby('player_name')['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Season2['xFIP5'] = Season2.groupby('player_name')['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xFIP10'] = Season2.groupby('player_name')['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Season2['K%5'] = Season2.groupby('player_name')['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['K%10'] = Season2.groupby('player_name')['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Season2['BB%5'] = Season2.groupby('player_name')['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['BB%10'] = Season2.groupby('player_name')['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Season2['K-BB%5'] = Season2.groupby('player_name')['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['K-BB%10'] = Season2.groupby('player_name')['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Season2['Ball%5'] = Season2.groupby('player_name')['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Season2['Strike%5'] = Season2.groupby('player_name')['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Season2['CS%5'] = Season2.groupby('player_name')['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['CS%10'] = Season2.groupby('player_name')['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Season2['Whiff%5'] = Season2.groupby('player_name')['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['Whiff%10'] = Season2.groupby('player_name')['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Season2['CSW%5'] = Season2.groupby('player_name')['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['CSW%10'] = Season2.groupby('player_name')['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "Season3 = Season2.drop(columns = [\"FB\", \"Balls\", \"HBP\", \"CS\", \"Whiff\", \"Strikes\", 'Ball%', 'Strike%', 'CS%', 'Whiff%', 'CSW%', \"RA/9\"])\n",
    "Season3 = Season3.rename(columns={'away_team': 'RoadTeam', 'home_team': 'HomeTeam', \"player_name\": \"SP\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping everything to get season and rolling averages for pitchers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season4 = Season3.groupby([\"SP\", \"p_throws\"]).agg(\n",
    "    Starts = (\"IP\", \"size\"),\n",
    "    Pitches = (\"Pitches\", \"mean\"),\n",
    "    AB = (\"AB\", \"mean\"),\n",
    "    PA = (\"PA\", \"mean\"),\n",
    "    Outs = (\"Outs\", \"mean\"),\n",
    "    Hits = (\"Hits\", \"mean\"),\n",
    "    HR = (\"HR\", \"mean\"),\n",
    "    BB = (\"BB\", \"mean\"),\n",
    "    K = (\"K\", \"mean\"),\n",
    "    RA = (\"RA\", \"mean\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    FIP = (\"FIP\", \"mean\"),\n",
    "    xFIP = (\"xFIP\", \"mean\"),\n",
    "    Kpercent = (\"K%\", \"mean\"),\n",
    "    BBpercent = (\"BB%\", \"mean\"),\n",
    "    KminusBBpercent = (\"K-BB%\", \"mean\"),\n",
    "    Pitches5 =  (\"Pitches5\", \"last\"),\n",
    "    Outs5 =  (\"Outs5\", \"last\"),\n",
    "    Outs10 = (\"Outs10\", \"last\"),\n",
    "    xBA5 =  (\"xBA5\", \"last\"),\n",
    "    xBA10 = (\"xBA10\", \"last\"),\n",
    "    xwOBA5 =  (\"xwOBA5\", \"last\"),\n",
    "    xwOBA10 = (\"xwOBA10\", \"last\"),\n",
    "    wOBA5 =  (\"wOBA5\", \"last\"),\n",
    "    wOBA10 = (\"wOBA10\", \"last\"),\n",
    "    RA5 = (\"RA5\", \"last\"),\n",
    "    RA10 = (\"RA10\", \"last\"),\n",
    "    FIP5 = (\"FIP5\", \"last\"),\n",
    "    FIP10 = (\"FIP10\", \"last\"),\n",
    "    xFIP5 = (\"xFIP5\", \"last\"),\n",
    "    xFIP10 = (\"xFIP10\", \"last\"),\n",
    "    Kpercent5 = (\"K%5\", \"last\"),\n",
    "    Kpercent10 = (\"K%10\", \"last\"),\n",
    "    BBpercent5 = (\"BB%5\", \"last\"),\n",
    "    BBpercent10 = (\"BB%10\", \"last\"),\n",
    "    KminusBBpercent5 = (\"K-BB%5\", \"last\"),\n",
    "    KminusBBpercent10 = (\"K-BB%10\", \"last\"),\n",
    "    Ballpercent5 = (\"Ball%5\", \"last\"),\n",
    "    Strikepercent5 = (\"Strike%5\", \"last\"),\n",
    "    CSpercent5 = (\"CS%5\", \"last\"),\n",
    "    CSpercent10 = (\"CS%10\", \"last\"),\n",
    "    Whiffpercent5 = (\"Whiff%5\", \"last\"),\n",
    "    Whiffpercent10 = (\"Whiff%10\", \"last\"),\n",
    "    CSWpercent5 = (\"CSW%5\", \"last\"),\n",
    "    CSWpercent10 = (\"CSW%10\", \"last\")).reset_index().fillna(0)\n",
    "\n",
    "Season4.rename(columns={col: col.replace('percent', '%') for col in Season4.columns if 'percent' in col}, inplace=True)\n",
    "Season4.rename(columns={col: col.replace('minus', '-') for col in Season4.columns if 'minus' in col}, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BatterSeason1 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BatterSeason2 = BatterSeason1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"p_throws\"]).agg(\n",
    "    Pitches=(\"Pitches\", \"sum\"),\n",
    "    AB=(\"at_bat_number\", \"size\"),\n",
    "    PA=(\"PA\", \"sum\"),\n",
    "    Outs=(\"Outs\", \"sum\"),\n",
    "    FB=(\"FB\", \"sum\"),\n",
    "    HR=(\"HR\", \"sum\"),\n",
    "    HBP=(\"HBP\", \"sum\"),\n",
    "    Balls=(\"Balls\", \"sum\"),\n",
    "    BB=(\"BB\", \"sum\"),\n",
    "    CS=(\"CS\", \"sum\"),\n",
    "    Whiff=(\"Whiff\", \"sum\"),\n",
    "    Strikes=(\"Strikes\", \"sum\"),\n",
    "    K=(\"K\", \"sum\"),\n",
    "    xBA=(\"xBA\", \"mean\"),\n",
    "    xwOBA=(\"xwOBA\", \"mean\"),\n",
    "    wOBA=(\"wOBA\", \"mean\"),\n",
    "    RunExp=(\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored=(\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored=(\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "BatterSeason2['RA'] = np.where((BatterSeason2['HomeRunsScored'] > 0) & (BatterSeason2['BatterTeam'] == BatterSeason2['home_team']),\n",
    "    BatterSeason2[\"HomeRunsScored\"], np.where((BatterSeason2['AwayRunsScored'] > 0) & (BatterSeason2['BatterTeam'] == BatterSeason2['away_team']), BatterSeason2[\"AwayRunsScored\"], 0))\n",
    "BatterSeason2[\"R/9\"] = (27 * BatterSeason2[\"RA\"] / BatterSeason2[\"Outs\"])\n",
    "BatterSeason2 = BatterSeason2.drop(columns=[\"AwayRunsScored\", \"HomeRunsScored\", \"RA\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BatterSeason2['FIP'] = (13 * BatterSeason2['HR'] + 3 * (BatterSeason2['BB'] + BatterSeason2['HBP']) - 2 * BatterSeason2['K']) / (BatterSeason2['Outs'] / 3) + 3.137\n",
    "BatterSeason2['xFIP'] = (13 * (BatterSeason2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (BatterSeason2['BB'] + BatterSeason2['HBP']) - 2 * BatterSeason2['K']) / (BatterSeason2['Outs'] / 3) + 3.137\n",
    "\n",
    "BatterSeason2['K%'] = round((BatterSeason2['K'] / BatterSeason2['AB']) * 100, 2)\n",
    "BatterSeason2['BB%'] = round((BatterSeason2['BB'] / BatterSeason2['AB']) * 100, 2)\n",
    "BatterSeason2['K-BB%'] = BatterSeason2[\"K%\"] - BatterSeason2[\"BB%\"]\n",
    "BatterSeason2['Ball%'] = round((BatterSeason2['Balls'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['Strike%'] = round((BatterSeason2['Strikes'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['CS%'] = round((BatterSeason2['CS'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['Whiff%'] = round((BatterSeason2['Whiff'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2[\"CSW\"] = BatterSeason2[\"CS\"] + BatterSeason2[\"Whiff\"]\n",
    "BatterSeason2['CSW%'] = round((BatterSeason2['CSW'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2 = BatterSeason2.drop(columns = [\"CSW\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rolling 5 and 10 game expected batting averages\n",
    "Season4['bxBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Season4['bxwOBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxwOBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Season4['bwOBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bwOBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Season4['bRS5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bRS10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Season4['bFIP5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bFIP10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Season4['bxFIP5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxFIP10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Season4['bK%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bK%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Season4['bBB%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bBB%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Season4['bK-BB%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bK-BB%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Season4['bBall%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Season4['bStrike%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Season4['bCS%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bCS%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Season4['bWhiff%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bWhiff%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Season4['bCSW%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bCSW%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining both the pitcher averages and the batter rolling averages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TodaysData.dropna(subset=['SP'], inplace=True)\n",
    "TodaysData1 = pd.merge(TodaysData, Season4[['SP', 'p_throws', 'Starts', 'Pitches', 'AB', 'PA', 'Outs', \"Hits\", 'HR', 'BB',\n",
    "       'K', 'RA', 'xBA', 'xwOBA', 'wOBA', 'RunExp', 'FIP', 'xFIP', 'K%', 'BB%',\n",
    "       'K-BB%', 'Pitches5', 'Outs5', 'Outs10', 'xBA5', 'xBA10', 'xwOBA5',\n",
    "       'xwOBA10', 'wOBA5', 'wOBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5',\n",
    "       'xFIP10', 'K%5', 'K%10', 'BB%5', 'BB%10', 'K-BB%5', 'K-BB%10', 'Ball%5',\n",
    "       'Strike%5', 'CS%5', 'CS%10', 'Whiff%5', 'Whiff%10', 'CSW%5', 'CSW%10',\n",
    "       'bxBA5', 'bxBA10', 'bxwOBA5', 'bxwOBA10', 'bwOBA5', 'bwOBA10', 'bRS5',\n",
    "       'bRS10', 'bFIP5', 'bFIP10', 'bxFIP5', 'bxFIP10', 'bK%5', 'bK%10',\n",
    "       'bBB%5', 'bBB%10', 'bK-BB%5', 'bK-BB%10', 'bBall%5', 'bStrike%5',\n",
    "       'bCS%5', 'bCS%10', 'bWhiff%5', 'bWhiff%10', 'bCSW%5', 'bCSW%10']], left_on = ['SP'], right_on = ['SP'], how = 'left')\n",
    "\n",
    "# If no 2024 savant data exists then gives them the league averages from 2022-23\n",
    "TrainMeans = Train3.drop(['BatterTeam', 'RoadTeam', \"HomeTeam\", \"SP\", \"p_throws\"], axis=1).mean()\n",
    "TodaysData1 = TodaysData1.fillna(TrainMeans)\n",
    "TodaysData1 = TodaysData1.replace([float('inf'), -float('inf')], 5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Min max scaling to normalize the variables"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Train4 = Train3.copy()\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columnsTrain = Train4.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_columnsToday = TodaysData1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Fit and transform numeric columns\n",
    "Train4[numeric_columnsTrain] = scaler.fit_transform(Train4[numeric_columnsTrain])\n",
    "TodaysData1[numeric_columnsTrain] = scaler.fit_transform(TodaysData1[numeric_columnsToday])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodes the teams and players allowing to be fed into the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensure Train5 and TodaysData2 are copies of Train4 and TodaysData1 respectively\n",
    "Train5 = Train4.copy()\n",
    "TodaysData2 = TodaysData1.copy()\n",
    "\n",
    "def strip_2_from_columns(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.replace('2', '', regex=False)\n",
    "    return df\n",
    "\n",
    "# Apply the function to TodaysData2\n",
    "TodaysData2 = strip_2_from_columns(TodaysData2, ['BatterTeam', 'HomeTeam', 'RoadTeam'])\n",
    "\n",
    "# Dictionary to store the label encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode non-numeric columns in Train4\n",
    "non_numeric_columns_train = Train5.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_train:\n",
    "    label_encoder = LabelEncoder()\n",
    "    Train5[col] = label_encoder.fit_transform(Train5[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "# Ensure all non-numeric columns in Train4 are in TodaysData1\n",
    "for col in non_numeric_columns_train:\n",
    "    if col not in TodaysData2.columns:\n",
    "        print(f\"Warning: Column {col} from training data is not present in today's data.\")\n",
    "        # Adding the missing column with a default value\n",
    "        TodaysData2[col] = 536\n",
    "\n",
    "# Encode non-numeric columns in TodaysData1 using the same encoders\n",
    "non_numeric_columns_today = TodaysData2.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        unique_values = set(label_encoder.classes_)\n",
    "        encoded_values = []\n",
    "        for item in TodaysData2[col]:\n",
    "            if item in unique_values:\n",
    "                encoded_values.append(label_encoder.transform([item])[0])\n",
    "            else:\n",
    "                encoded_values.append(536)  # Using 536 as a placeholder for unknown categories\n",
    "        TodaysData2[col] = encoded_values\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} is not present in the training data.\")\n",
    "        # Fit a new label encoder for columns not present in Train4, but be cautious with this\n",
    "        label_encoder = LabelEncoder()\n",
    "        TodaysData2[col] = label_encoder.fit_transform(TodaysData2[col])\n",
    "        label_encoders[col] = label_encoder"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "kData = Train5[[\"RoadTeam\", 'HomeTeam', 'SP', 'p_throws', 'Pitches', \"PA\", 'Outs', 'Hits', 'HR', 'xBA', 'xwOBA', 'wOBA', 'RA', 'FIP', 'xFIP', 'K%', 'BB%', 'Pitches5', 'xBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5', 'K%5', 'Strike%5', 'Whiff%10', 'CSW%5', 'bxBA5', 'bxwOBA10', 'bxFIP5', 'bBB%5', 'bK-BB%10', 'bBall%5', 'bCS%10', \"K\"]]\n",
    "\n",
    "kTodaysData = TodaysData2[[\"RoadTeam\", 'HomeTeam', 'SP', 'p_throws', 'Pitches', \"PA\", 'Outs', 'Hits', 'HR', 'xBA', 'xwOBA', 'wOBA', 'RA', 'FIP', 'xFIP', 'K%', 'BB%', 'Pitches5', 'xBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5', 'K%5', 'Strike%5', 'Whiff%10', 'CSW%5', 'bxBA5', 'bxwOBA10', 'bxFIP5', 'bBB%5', 'bK-BB%10', 'bBall%5', 'bCS%10', \"K\", \"Starts\"]]\n",
    "\n",
    "kData.loc[:,\"K\"] = Train3[\"K\"]\n",
    "kTodaysData.loc[:,\"K\"] = TodaysData1[\"K\"]\n",
    "\n",
    "TrainFeatures = kData.drop(columns = [\"K\"]).values.reshape(-1, 31)\n",
    "TrainLabel = kData[\"K\"].values.ravel()\n",
    "TodayFeatures = kTodaysData.drop(columns = [\"Starts\", \"K\"]).values.reshape(-1, 31)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(31,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xK\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BB Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bbData = Train5[['RoadTeam', 'HomeTeam', 'p_throws', 'Pitches', 'AB', 'PA', 'Outs', 'Hits', 'K', 'xBA', 'xwOBA', 'wOBA', 'RunExp', 'RA', 'FIP', 'xFIP', 'BB%', 'Pitches5', 'Outs5', 'Outs10', 'xBA5', 'xBA10', 'xwOBA5', 'xwOBA10', 'wOBA5', 'RA5', 'RA10', 'FIP5', 'xFIP5', 'xFIP10', 'K%5', 'Ball%5', 'Strike%5', 'CS%5', 'CS%10', 'Whiff%10', 'bxBA10', 'bRS10', 'bFIP5', 'bxFIP5', 'bxFIP10', 'bK%5', 'bBB%10', 'bWhiff%10', 'bCSW%5', 'bCSW%10', \"BB\"]]\n",
    "\n",
    "bbTodaysData = TodaysData2[['RoadTeam', 'HomeTeam', 'p_throws', 'Pitches', \"Starts\", 'AB', 'PA', 'Outs', 'Hits', 'K', 'xBA', 'xwOBA', 'wOBA', 'RunExp', 'RA', 'FIP', 'xFIP', 'BB%', 'Pitches5', 'Outs5', 'Outs10', 'xBA5', 'xBA10', 'xwOBA5', 'xwOBA10', 'wOBA5', 'RA5', 'RA10', 'FIP5', 'xFIP5', 'xFIP10', 'K%5', 'Ball%5', 'Strike%5', 'CS%5', 'CS%10', 'Whiff%10', 'bxBA10', 'bRS10', 'bFIP5', 'bxFIP5', 'bxFIP10', 'bK%5', 'bBB%10', 'bWhiff%10', 'bCSW%5', 'bCSW%10', \"BB\", \"Starts\"]]\n",
    "\n",
    "bbData.loc[:,\"BB\"] = Train3[\"BB\"]\n",
    "bbTodaysData.loc[:,\"BB\"] = TodaysData1[\"BB\"]\n",
    "\n",
    "TrainFeatures = kData.drop(columns = [\"K\"]).values.reshape(-1, 31)\n",
    "TrainLabel = kData[\"K\"].values.ravel()\n",
    "TodayFeatures = kTodaysData.drop(columns = [\"Starts\", \"K\"]).values.reshape(-1, 31)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(31,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xBB\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hits Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"Hits\"]).values.reshape(-1, 77)\n",
    "TrainLabel = Train5[\"Hits\"].values.ravel()\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"BB\", \"xK\", \"xBB\", \"Hits\"]).values.reshape(-1, 77)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 3)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xHA\"] = RFpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RA Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"RA\"]).values.reshape(-1, 77)\n",
    "TrainLabel = Train5[\"RA\"].values.ravel()\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"BB\", \"xK\", \"xBB\", \"xHA\", \"RA\"]).values.reshape(-1, 77)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 3)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xRA\"] = RFpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"Outs\"]).values.reshape(-1, 77)\n",
    "TrainLabel = Train5[\"Outs\"].values.ravel()\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"Outs\", \"xK\", \"xBB\", \"xHA\", \"xRA\"]).values.reshape(-1, 77)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 3)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xOuts\"] = RFpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse encodes today's data so it can be understood"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        # Handling default value of 536\n",
    "        TodaysData2[col] = TodaysData2[col].apply(lambda x: label_encoder.inverse_transform([x])[0] if x != 536 else np.nan)\n",
    "\n",
    "TodaysData2['SP'] = TodaysData2['SP'].fillna(TodaysData1['SP'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_2_to_duplicates(df):\n",
    "    mask = df.duplicated(subset=['BatterTeam', 'RoadTeam', 'HomeTeam'], keep='first')\n",
    "    \n",
    "    df.loc[mask, 'BatterTeam'] += '2'\n",
    "    df.loc[mask, 'RoadTeam'] += '2'\n",
    "    df.loc[mask, 'HomeTeam'] += '2'\n",
    "    \n",
    "    return df\n",
    "\n",
    "TodaysData2 = add_2_to_duplicates(TodaysData2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates simple dataset to see the expected stats of all the predicted metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Performs a two \"sample\" z test to see the likelihood of a quality start occurring\n",
    "def row_z_score(row):\n",
    "    x_bar1 = row[\"xRA\"]\n",
    "    x_bar2 = row[\"xOuts\"]\n",
    "    mu1 = 3\n",
    "    mu2 = 18\n",
    "    sigma1 = Train3[\"RA\"].std()\n",
    "    sigma2 = Train3[\"Outs\"].std()\n",
    "    n1 = len(TodaysData2)\n",
    "    n2 = n1\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_score_xRA = (x_bar1 - mu1) / (sigma1 / np.sqrt(n1))\n",
    "    z_score_xOuts = (x_bar2 - mu2) / (sigma2 / np.sqrt(n2))\n",
    "    \n",
    "    # Calculate probabilities, want less than\n",
    "    prob_xRA_less_than_mu1 = 1 - stats.norm.cdf(z_score_xRA)\n",
    "    prob_xOuts_greater_than_mu2 = stats.norm.cdf(z_score_xOuts)\n",
    "\n",
    "    # Combine probabilities by multiplying it\n",
    "    combined_prob = prob_xRA_less_than_mu1 * prob_xOuts_greater_than_mu2\n",
    "    return combined_prob\n",
    "\n",
    "# Calculate the chance of a quality start occurring and finds the xQS points\n",
    "percent = TodaysData2.apply(row_z_score, axis=1)\n",
    "xQS = percent * 5\n",
    "\n",
    "# Adds the xQS to the xFS\n",
    "TodaysData2.loc[:, \"xFS\"] = (xQS + TodaysData2[\"xK\"] * 3 + TodaysData2[\"xOuts\"] - TodaysData2[\"xRA\"] * 3)\n",
    "TodaysData3 = TodaysData2[[\"BatterTeam\", \"SP\", \"Starts\", \"xK\", \"xBB\", \"xHA\", \"xRA\", \"xOuts\", \"xFS\"]].round(2)\n",
    "TodaysData3.sort_values(\"xFS\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def calculate_adjusted_odds_for_over(target_line, expected_total, original_odds = -136.6, std_dev=15):\n",
    "    def american_to_decimal(american_odds):\n",
    "        if american_odds > 0:\n",
    "            return (american_odds / 100) + 1\n",
    "        else:\n",
    "            return (100 / abs(american_odds)) + 1\n",
    "\n",
    "    def decimal_to_american(decimal_odds):\n",
    "        if decimal_odds >= 2:\n",
    "            return f\"+{round((decimal_odds - 1) * 100)}\"\n",
    "        else:\n",
    "            return f\"-{round(100 / (decimal_odds - 1))}\"\n",
    "\n",
    "    # Calculate the z-score\n",
    "    z_score = (target_line - expected_total) / std_dev\n",
    "    \n",
    "    # Calculate the probability of going over\n",
    "    over_probability = 1 - (0.5 + 0.5 * math.erf(z_score / math.sqrt(2)))\n",
    "    \n",
    "    if original_odds is None:\n",
    "        # If no original odds provided, calculate implied odds\n",
    "        if over_probability > 0.5:\n",
    "            american_odds = -100 / (over_probability - 1)\n",
    "        else:\n",
    "            american_odds = (1 / over_probability - 1) * 100\n",
    "    else:\n",
    "        # If original odds provided, adjust them\n",
    "        original_decimal = american_to_decimal(original_odds)\n",
    "        fair_decimal = 1 / over_probability\n",
    "        adjusted_decimal = original_decimal * fair_decimal\n",
    "        american_odds = adjusted_decimal\n",
    "    \n",
    "    return decimal_to_american(american_odds)\n",
    "\n",
    "# Example usage\n",
    "print(f\"Implied odds for over 8 when expected is 7.5: {calculate_adjusted_odds_for_over(8, 7.5)}\")\n",
    "print(f\"Implied odds for over 8 when expected is 15: {calculate_adjusted_odds_for_over(8, 15)}\")\n",
    "print(f\"Adjusted odds for over 53.5 when expected is 46.5, original odds -120: {calculate_adjusted_odds_for_over(35.5, 46.5, -120)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_adjusted_odds_for_over(target_line, expected_total, original_odds = -137, std_dev=15):\n",
    "    def american_to_decimal(american_odds):\n",
    "        if american_odds > 0:\n",
    "            return (american_odds / 100) + 1\n",
    "        else:\n",
    "            return (100 / abs(american_odds)) + 1\n",
    "\n",
    "    def decimal_to_american(decimal_odds):\n",
    "        if decimal_odds >= 2:\n",
    "            return f\"+{round((decimal_odds - 1) * 100)}\"\n",
    "        else:\n",
    "            return f\"-{round(100 / (decimal_odds - 1))}\"\n",
    "\n",
    "    # Calculate the z-score\n",
    "    z_score = (target_line - expected_total) / std_dev\n",
    "    \n",
    "    # Calculate the probability of going over using normal CDF\n",
    "    over_probability = 1 - stats.norm.cdf(z_score)\n",
    "    \n",
    "    if original_odds is None:\n",
    "        # If no original odds provided, calculate implied odds\n",
    "        if over_probability > 0.5:\n",
    "            american_odds = -100 / (over_probability - 1)\n",
    "        else:\n",
    "            american_odds = (1 / over_probability - 1) * 100\n",
    "    else:\n",
    "        # Adjust original odds based on the probability\n",
    "        original_decimal = american_to_decimal(original_odds)\n",
    "        \n",
    "        # Fair decimal based on probability\n",
    "        fair_decimal = 1 / over_probability\n",
    "        \n",
    "        # Adjust original odds proportionally to probability\n",
    "        adjusted_decimal = original_decimal * fair_decimal\n",
    "        \n",
    "        # Convert back to American odds\n",
    "        american_odds = adjusted_decimal\n",
    "    \n",
    "    return decimal_to_american(american_odds)\n",
    "\n",
    "# Example usage\n",
    "print(f\"Implied odds for over 8 when expected is 7.5: {calculate_adjusted_odds_for_over(8, 7.5)}\")\n",
    "print(f\"Implied odds for over 8 when expected is 15: {calculate_adjusted_odds_for_over(8, 15)}\")\n",
    "print(f\"Adjusted odds for over 53.5 when expected is 46.5, original odds -120: {calculate_adjusted_odds_for_over(55.5, 46.5, -120)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def calculate_edge(estimated_probability, sportsbook_odds):\n",
    "    def american_to_decimal(american_odds):\n",
    "        if american_odds > 0:\n",
    "            return (american_odds / 100) + 1\n",
    "        else:\n",
    "            return (100 / abs(american_odds)) + 1\n",
    "    \n",
    "    def american_to_probability(american_odds):\n",
    "        decimal_odds = american_to_decimal(american_odds)\n",
    "        return 1 / decimal_odds\n",
    "    \n",
    "    # Convert sportsbook odds to decimal\n",
    "    sportsbook_decimal = american_to_decimal(sportsbook_odds)\n",
    "    \n",
    "    # Calculate sportsbook implied probability\n",
    "    sportsbook_probability = american_to_probability(sportsbook_odds)\n",
    "    \n",
    "    # Calculate edge\n",
    "    edge = (estimated_probability * sportsbook_decimal) - 1\n",
    "    \n",
    "    return edge * 100  # Convert to percentage\n",
    "\n",
    "# Example usage:\n",
    "estimated_prob = 0.60  # 60% estimated probability\n",
    "sportsbook_odds = -120  # -120 American odds\n",
    "\n",
    "edge = calculate_edge(estimated_prob, sportsbook_odds)\n",
    "print(f\"The calculated edge is: {edge:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prizepicks API to load in data to see lines to find edge"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def call_endpoint(url, max_level=3, include_new_player_attributes=False):\n",
    "    '''\n",
    "    takes: \n",
    "        - url (str): the API endpoint to call\n",
    "        - max_level (int): level of json normalizing to apply\n",
    "        - include_player_attributes (bool): whether to include player object attributes in the returned dataframe\n",
    "    returns:\n",
    "        - df (pd.DataFrame): a dataframe of the call response content\n",
    "    '''\n",
    "    resp = requests.get(url).json()\n",
    "    data = pd.json_normalize(resp['data'], max_level=max_level)\n",
    "    included = pd.json_normalize(resp['included'], max_level=max_level)\n",
    "    if include_new_player_attributes:\n",
    "        inc_cop = included[included['type'] == 'new_player'].copy().dropna(axis=1)\n",
    "        data = pd.merge(data\n",
    "                        , inc_cop\n",
    "                        , how='left'\n",
    "                        , left_on=['relationships.new_player.data.id'\n",
    "                                   ,'relationships.new_player.data.type']\n",
    "                        , right_on=['id', 'type']\n",
    "                        , suffixes=('', '_new_player'))\n",
    "    return data\n",
    "\n",
    "url = 'https://partner-api.prizepicks.com/projections?league_id=2&per_page=1000'\n",
    "df = call_endpoint(url, include_new_player_attributes=True)\n",
    "\n",
    "prizepicks1 = df[[\"attributes.description\", \"attributes.line_score\", \"attributes.odds_type\", \"attributes.stat_type\", \"attributes.name\", \"attributes.position\", \"attributes.team\"]]\n",
    "prizepicks1 = prizepicks1[(prizepicks1[\"attributes.position\"] == \"P\") &\n",
    "                          ((prizepicks1[\"attributes.odds_type\"] == \"standard\") |\n",
    "                           (prizepicks1[\"attributes.odds_type\"] == \"goblin\") |\n",
    "                           (prizepicks1[\"attributes.odds_type\"] == \"demon\"))].drop(columns = \"attributes.position\")\n",
    "prizepicks2 = prizepicks1.rename(columns={'attributes.name': 'SP', 'attributes.description': 'BatterTeam', 'attributes.team': 'PitcherTeam',  \"attributes.line_score\": \"Line\", \"attributes.stat_type\": \"Stat\", \"attributes.odds_type\": \"Type\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strikeouts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "StrikeoutLine = prizepicks2[(prizepicks2[\"Stat\"] == \"Pitcher Strikeouts\") & (prizepicks2[\"Type\"] == \"standard\")]\n",
    "Strikeouts1 = TodaysData3[[\"BatterTeam\", \"SP\", \"Starts\", \"xK\"]]\n",
    "Strikeouts2 = pd.merge(Strikeouts1, StrikeoutLine[[\"SP\", \"Line\", \"Stat\", \"Type\"]], left_on = ['SP'], right_on = ['SP'], how = 'left').dropna()\n",
    "# Strikeouts2[\"Edge\"] = Strikeouts2[\"xK\"] - Strikeouts2[\"Line\"]\n",
    "# Strikeouts2[\"Edge%\"] = abs(Strikeouts2[\"Edge\"] / Strikeouts2[\"Line\"]) * 100\n",
    "# Strikeouts2.sort_values(\"Edge%\", ascending = False).round(2)\n",
    "\n",
    "Strikeouts2['Edge'] = Strikeouts2.apply(lambda row: calculate_equivalent_odds(row['Line'], row['xK'], original_odds = -136.6, std_dev=2), axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "WalkLine = prizepicks2[(prizepicks2[\"Stat\"] == \"Walks Allowed\") & (prizepicks2[\"Type\"] == \"standard\")]\n",
    "Walks1 = TodaysData3[[\"BatterTeam\", \"SP\", \"Starts\", \"xBB\"]]\n",
    "Walks2 = pd.merge(Walks1, WalkLine[[\"SP\", \"Line\", \"Stat\", \"Type\"]], left_on = ['SP'], right_on = ['SP'], how = 'left').dropna()\n",
    "Walks2[\"Edge\"] = Walks2[\"xBB\"] - Walks2[\"Line\"]\n",
    "Walks2[\"Edge%\"] = abs(Walks2[\"Edge\"] / Walks2[\"Line\"]) * 100\n",
    "Walks2.sort_values(\"Edge%\").round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hits Allowed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "HitLine = prizepicks2[(prizepicks2[\"Stat\"] == \"Hits Allowed\") & ((prizepicks2[\"Type\"] == \"standard\") | (prizepicks2[\"Type\"] == \"demon\"))]\n",
    "Hits1 = TodaysData3[[\"BatterTeam\", \"SP\", \"Starts\", \"xHA\"]]\n",
    "Hits2 = pd.merge(Hits1, HitLine[[\"SP\", \"Line\", \"Stat\", \"Type\"]], left_on = ['SP'], right_on = ['SP'], how = 'left').dropna()\n",
    "Hits2[\"Edge\"] = Hits2[\"xHA\"] - Hits2[\"Line\"]\n",
    "Hits2 = Hits2[~((Hits2[\"Type\"] == \"demon\") | (Hits2[\"Type\"] == \"goblin\") & (Hits2[\"Edge\"] < 0))]\n",
    "Hits2[\"Edge%\"] = abs(Hits2[\"Edge\"] / Hits2[\"Line\"]) * 100\n",
    "Hits2.sort_values(\"Edge%\").round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Allowed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "RunLine = prizepicks2[(prizepicks2[\"Stat\"] == \"Earned Runs Allowed\") & ((prizepicks2[\"Type\"] == \"standard\") | (prizepicks2[\"Type\"] == \"demon\"))]\n",
    "Runs1 = TodaysData3[[\"BatterTeam\", \"SP\", \"Starts\", \"xRA\"]]\n",
    "Runs2 = pd.merge(Runs1, RunLine[[\"SP\", \"Line\", \"Stat\", \"Type\"]], left_on = ['SP'], right_on = ['SP'], how = 'left').dropna()\n",
    "Runs2[\"Edge\"] = Runs2[\"xRA\"] - Runs2[\"Line\"]\n",
    "Runs2 = Runs2[~((Runs2[\"Type\"] == \"demon\") | (Runs2[\"Type\"] == \"goblin\") & (Runs2[\"Edge\"] < 0))]\n",
    "Runs2[\"Edge%\"] = abs(Runs2[\"Edge\"] / Runs2[\"Line\"]) * 100\n",
    "Runs2.sort_values(\"Edge%\").round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitching Outs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "OutLine = prizepicks2[prizepicks2[\"Stat\"] == \"Pitching Outs\"]\n",
    "Outs1 = TodaysData3[[\"BatterTeam\", \"SP\", \"Starts\", \"xOuts\"]]\n",
    "Outs2 = pd.merge(Outs1, OutLine[[\"SP\", \"Line\", \"Stat\", \"Type\"]], left_on = ['SP'], right_on = ['SP'], how = 'left').dropna()\n",
    "Outs2[\"Edge\"] = Outs2[\"xOuts\"] - Outs2[\"Line\"]\n",
    "Outs2 = Outs2[~((Outs2[\"Type\"] == \"demon\") | (Outs2[\"Type\"] == \"goblin\") & (Outs2[\"Edge\"] < 0))]\n",
    "Outs2[\"Edge%\"] = abs(Outs2[\"Edge\"] / Outs2[\"Line\"]) * 100\n",
    "Outs2.sort_values(\"Edge%\").round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fantasy Score"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "FSLine = prizepicks2[prizepicks2[\"Stat\"] == \"Pitcher Fantasy Score\"]\n",
    "FS1 = TodaysData3[[\"BatterTeam\", \"SP\", \"Starts\", \"xFS\"]]\n",
    "FS2 = pd.merge(FS1, FSLine[[\"SP\", \"Line\", \"Stat\"]], left_on = ['SP'], right_on = ['SP'], how = 'left').dropna()\n",
    "FS2[\"Edge\"] = FS2[\"xFS\"] - FS2[\"Line\"]\n",
    "FS2[\"Edge%\"] = abs(FS2[\"Edge\"] / FS2[\"Line\"]) * 100\n",
    "FS2.sort_values(\"Edge%\").round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Props1 = pd.concat([Strikeouts2, Hits2, Runs2, Outs2], ignore_index = True)\n",
    "Props2 = Props1[(Props1[\"Edge%\"] > 15) & (Props1[\"Starts\"] > 3)]\n",
    "Props2 = Props2[[\"BatterTeam\", \"SP\", \"Starts\", \"Stat\", \"Type\", \"Line\", \"Edge\", \"Edge%\"]].sort_values(\"Edge%\", ascending = False).round(2)\n",
    "Props2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "excel_file = 'Pitcher-Tracker.xlsx'\n",
    "\n",
    "# If deleting the mode and engine it rewrites the whole file\n",
    "#with pd.ExcelWriter(excel_file, mode='a', engine='openpyxl') as writer:\n",
    "    Props2.reset_index().to_excel(writer, index=False, sheet_name = eastern_time.strftime(\"%m-%d-%y\"))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
