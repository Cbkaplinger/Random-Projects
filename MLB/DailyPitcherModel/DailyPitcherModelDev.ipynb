{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T21:17:11.845739Z",
     "start_time": "2025-06-22T21:17:11.835386Z"
    }
   },
   "source": [
    "import datetime\n",
    "import io\n",
    "import sys\n",
    "import unicodedata\n",
    "from datetime import timezone\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pybaseball\n",
    "import requests\n",
    "import scipy.stats as stats\n",
    "from bs4 import BeautifulSoup\n",
    "from pybaseball import statcast\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybaseball\n",
    "import requests\n",
    "import scipy.stats as stats\n",
    "from bs4 import BeautifulSoup\n",
    "from pybaseball import statcast\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "pybaseball.cache.enable()\n",
    "\n",
    "# Load in my own 40 man Roster Scraper\n",
    "directory = '/Users/cbkaplinger/Desktop/Desktop - Cameron MacBook Pro/Random-Projects/MLB/RosterScraper'\n",
    "sys.path.append(directory)\n",
    "from RosterScraper import RosterScraper"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in StatCast ID so batter names show in the Statcast data and loads in a scraped DF with every 40 man roster"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T21:17:31.307772Z",
     "start_time": "2025-06-22T21:17:15.624173Z"
    }
   },
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/1JgczhD5VDQ1EiXqVG-blttZcVwbZd5_Ne_mefUGwJnk/pub?output=csv'\n",
    "res = requests.get(url)\n",
    "ID = pl.read_csv(io.BytesIO(res.content))\n",
    "ID = ID.drop_nulls(subset=['MLBID'])\n",
    "ID = ID.with_columns([pl.col('MLBID').cast(pl.Int64)])\n",
    "\n",
    "Rosters = RosterScraper()\n",
    "BID = Rosters[Rosters[\"Position\"] == \"Batter\"]\n",
    "PID = Rosters[Rosters[\"Position\"] == \"Pitcher\"]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating functions for data manipulation so they can match when joining separate datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T01:38:15.585802Z",
     "start_time": "2025-06-23T01:38:15.541664Z"
    }
   },
   "source": [
    "def convert_name(name):\n",
    "    if name == 'Rockies':\n",
    "        return 'COL'\n",
    "    elif name == 'Reds':\n",
    "        return 'CIN'\n",
    "    elif name == 'Mariners':\n",
    "        return 'SEA'\n",
    "    elif name == 'Nationals':\n",
    "        return 'WSH'\n",
    "    elif name == 'Yankees':\n",
    "        return 'NYY'\n",
    "    elif name == 'Astros':\n",
    "        return 'HOU'\n",
    "    elif name == 'Red Sox':\n",
    "        return 'BOS'\n",
    "    elif name == 'Athletics':\n",
    "        return 'OAK'\n",
    "    elif name == 'Mets':\n",
    "        return 'NYM'\n",
    "    elif name == 'Braves':\n",
    "        return 'ATL'\n",
    "    elif name == 'Giants':\n",
    "        return 'SF'\n",
    "    elif name == 'Brewers':\n",
    "        return 'MIL'\n",
    "    elif name == 'Rays':\n",
    "        return 'TB'\n",
    "    elif name == 'Royals':\n",
    "        return 'KC'\n",
    "    elif name == 'White Sox':\n",
    "        return 'CWS'\n",
    "    elif name == 'Cubs':\n",
    "        return 'CHC'\n",
    "    elif name == 'Angels':\n",
    "        return 'LAA'\n",
    "    elif name == 'Tigers':\n",
    "        return 'DET'\n",
    "    elif name == 'Diamondbacks':\n",
    "        return 'ARI'\n",
    "    elif name == 'Guardians':\n",
    "        return 'CLE'\n",
    "    elif name == 'Orioles':\n",
    "        return 'BAL'\n",
    "    elif name == 'Twins':\n",
    "        return 'MIN'\n",
    "    elif name == 'Marlins':\n",
    "        return 'MIA'\n",
    "    elif name == 'Phillies':\n",
    "        return 'PHI'\n",
    "    elif name == 'Rangers':\n",
    "        return 'TEX'\n",
    "    elif name == 'Dodgers':\n",
    "        return 'LAD'\n",
    "    elif name == 'Padres':\n",
    "        return 'SD'\n",
    "    elif name == 'Pirates':\n",
    "        return 'PIT'\n",
    "    elif name == 'Blue Jays':\n",
    "        return 'TOR'\n",
    "    elif name == 'Cardinals':\n",
    "        return 'STL'\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def flip_names(name):\n",
    "    first_name, last_name = name.split(\", \")\n",
    "    return f\"{last_name} {first_name}\"\n",
    "\n",
    "def replace_special_chars(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "def append_suffix_to_duplicates(df, column):\n",
    "        seen = {}\n",
    "        for idx, value in enumerate(df[column]):\n",
    "            if value in seen:\n",
    "                seen[value] += 1\n",
    "                df.at[idx, column] = f\"{value}2\"\n",
    "            else:\n",
    "                seen[value] = 1"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the RotoGrinders website for daily pitchers and lineups"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T01:38:16.560094Z",
     "start_time": "2025-06-23T01:38:16.521881Z"
    }
   },
   "source": [
    "def getDKData2024():\n",
    "    eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
    "    todaysdate = eastern_time.strftime(\"%m-%d-%Y\")\n",
    "    url = 'https://rotogrinders.com/lineups/mlb?site=draftkings'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    gamelist = []\n",
    "    gamecards = soup.findAll(\"div\", {\"class\": \"game-card-teams\"})\n",
    "    for x in gamecards:\n",
    "        twoteams = x.findAll(\"span\", {\"class\": \"team-nameplate-mascot\"})\n",
    "        roadteam = convert_name(twoteams[0].text)\n",
    "        hometeam = convert_name(twoteams[1].text)\n",
    "        gamekey = \"{}@{}\".format(roadteam,hometeam)\n",
    "        gamelist.append(gamekey)\n",
    "\n",
    "    matchupsdf = pd.DataFrame()\n",
    "    for game in gamelist:\n",
    "        roadteam = game.split(\"@\")[0]\n",
    "        hometeam = game.split(\"@\")[1]\n",
    "        thisdf1 = pd.DataFrame({\"Team\": roadteam, \"Opp\": hometeam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
    "        thisdf2 = pd.DataFrame({\"Team\": hometeam, \"Opp\": roadteam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
    "        matchupsdf = pd.concat([matchupsdf,thisdf1,thisdf2])\n",
    "        \n",
    "    oppdict = dict(zip(matchupsdf.Team,matchupsdf.Opp))\n",
    "    hometeamdict = dict(zip(matchupsdf.Team,matchupsdf.HomeTeam))\n",
    "    roadteamdict = dict(zip(matchupsdf.Team,matchupsdf.RoadTeam))\n",
    "\n",
    "    disabled_span_list = []\n",
    "    for span in soup.findAll(\"span\", {\"class\": \"player-nameplate disabled\"}):\n",
    "        for a in span.findAll(\"a\"):\n",
    "            disabled_span_list.append(a.text)\n",
    "\n",
    "    spdata = pd.DataFrame()\n",
    "    for div in soup.findAll(\"span\", {\"class\": \"player-nameplate\", \"data-position\": \"SP\"}):\n",
    "        if \"TBD\" in str(div):\n",
    "            playername = \"TBD\"\n",
    "            pos = \"SP\"\n",
    "            sal = 0\n",
    "        else:\n",
    "            for a in div.findAll('a', {'class': 'player-nameplate-name'}):\n",
    "                playername = a.text.strip()\n",
    "\n",
    "            strdiv = str(div)\n",
    "            pos = strdiv[strdiv.find(\"data-position\")+15:strdiv.find(\"data-salary\")-2]\n",
    "            sal = strdiv[strdiv.find(\"data-salary\")+13:strdiv.find(\"<div class = 'player-nameplate-info'>\")-3]\n",
    "        try:\n",
    "            ownership = strdiv[strdiv.find('<span class=\"small muted\" data-auth=\"502\">') + 42:strdiv.find('%')]\n",
    "            ownership = ownership.replace(\"</span>\", \"\")\n",
    "            ownership = ownership.replace(\"</span\", \"\")\n",
    "            ownership = ownership.replace(\"</div>\", \"\")\n",
    "            ownership = ownership.replace(\" \", \"\")\n",
    "        except:\n",
    "            ownership = np.nan\n",
    "\n",
    "        thisspdata = pd.DataFrame([[playername, sal, ownership]], columns = [\"Player\", \"Salary\", \"Ownership\"])\n",
    "        spdata = pd.concat([spdata, thisspdata])\n",
    "\n",
    "    spdata['Player'] = spdata['Player'].replace('Luis Ortiz', 'Luis L. Ortiz')\n",
    "    spdata['Player'] = spdata['Player'].replace('Mike King', 'Michael King')\n",
    "    spdata['Player'] = spdata['Player'].replace('Robert Zastryzny', 'Rob Zastryzny')\n",
    "\n",
    "    spdata2 = pd.merge(spdata, PID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"PitcherTeam\"})\n",
    "    spdata3 = pd.merge(spdata2, matchupsdf[[\"Team\", \"Opp\"]], left_on = [\"PitcherTeam\"], right_on = [\"Team\"], how = \"left\").drop(columns = [\"Team\"])\n",
    "\n",
    "    append_suffix_to_duplicates(spdata3, 'PitcherTeam')\n",
    "    append_suffix_to_duplicates(spdata3, 'Opp')\n",
    "\n",
    "    opp_spname_dict = dict(zip(spdata3.Opp, spdata3.Player))\n",
    "    opp_spsal_dict = dict(zip(spdata3.Opp, spdata.Salary))\n",
    "    opp_spown_dict = dict(zip(spdata3.Opp, spdata3.Ownership))\n",
    "\n",
    "    ludf = pd.DataFrame()\n",
    "    \n",
    "    for li in soup.findAll(\"li\", {\"class\": \"lineup-card-player\"}):\n",
    "        for a in li.findAll(\"a\", {\"class\": [\"player-nameplate-name\", \"player-nameplate disabled\"]}):\n",
    "            playername = a.text\n",
    "\n",
    "        listring = str(li)\n",
    "        for span in li.find(\"span\", {\"class\": \"small\"}):\n",
    "            luspot = span.text\n",
    "            luspot = luspot.replace(\"\\n\", \"\")\n",
    "            luspot = luspot.strip()\n",
    "            luspot = int(luspot)\n",
    "        pos = listring[listring.find(\"data-position\")+15:listring.find(\"data-salary\")-2]\n",
    "        sal = listring[listring.find(\"data-salary\")+13:listring.find(\"<span class='small'>\")-3]\n",
    "        ownership = ownership.replace(\"</span>\", \"\")\n",
    "        ownership = ownership.replace(\"</span\", \"\")\n",
    "        ownership = ownership.replace(\"</li\", \"\")\n",
    "        ownership = ownership.replace(\"</div>\", \"\")\n",
    "        ownership = ownership.replace(\" \", \"\")\n",
    "\n",
    "        try:\n",
    "            sal = int(sal)\n",
    "        except:\n",
    "            sal = 0\n",
    "        thisludf = pd.DataFrame([[playername, luspot, sal, ownership]], columns = [\"Player\", \"Spot\", \"Sal\", \"Ownership\"])\n",
    "        ludf = pd.concat([ludf, thisludf])\n",
    "\n",
    "    ludf2 = pd.merge(ludf, BID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"BatterTeam\"})\n",
    "    ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
    "    ludf2['HomeTeam'] = ludf2['BatterTeam'].map(hometeamdict)\n",
    "    ludf2['RoadTeam'] = ludf2['BatterTeam'].map(roadteamdict)\n",
    "\n",
    "    ludf2_teamlist = list(ludf2[\"BatterTeam\"])\n",
    "\n",
    "    dhteams = []\n",
    "    for x in ludf2_teamlist:\n",
    "        if ludf2_teamlist.count(x) > 11:\n",
    "            if x in dhteams:\n",
    "                pass\n",
    "            else:\n",
    "                dhteams.append(x)\n",
    "\n",
    "    extract_dh = ludf2[ludf2[\"BatterTeam\"].isin(dhteams)]\n",
    "    new_ludf2 = ludf2[~ludf2[\"BatterTeam\"].isin(dhteams)]\n",
    "\n",
    "    new_team_list = []\n",
    "    new_home_list = []\n",
    "    new_road_list = []\n",
    "    runcounter = 0\n",
    "\n",
    "    for x, home, road in zip(extract_dh[\"BatterTeam\"].astype(str), \n",
    "                         extract_dh[\"HomeTeam\"].astype(str), \n",
    "                         extract_dh[\"RoadTeam\"].astype(str)):\n",
    "        if runcounter < 18:\n",
    "            new_team_list.append(x)\n",
    "            new_home_list.append(home)\n",
    "            new_road_list.append(road)\n",
    "            runcounter += 1\n",
    "        else:\n",
    "            new_team_list.append(x + \"2\")\n",
    "            new_home_list.append(home + \"2\")\n",
    "            new_road_list.append(road + \"2\")\n",
    "            runcounter += 1\n",
    "\n",
    "    extract_dh[\"BatterTeam\"] = new_team_list\n",
    "    extract_dh[\"HomeTeam\"] = new_home_list\n",
    "    extract_dh[\"RoadTeam\"] = new_road_list\n",
    "\n",
    "    ludf2 = pd.concat([extract_dh, new_ludf2])\n",
    "    ludf2[\"Opp\"] = ludf2[\"BatterTeam\"].map(oppdict)\n",
    "    ludf2['SP'] = ludf2['BatterTeam'].map(opp_spname_dict)\n",
    "    ludf2['SPSal'] = ludf2['BatterTeam'].map(opp_spsal_dict)\n",
    "    ludf2['SPOwnership'] = ludf2['BatterTeam'].map(opp_spown_dict)\n",
    "    ludf2['Date'] = todaysdate\n",
    "    ludf2['Time'] = np.nan\n",
    "\n",
    "    ludf3 = ludf2[['BatterTeam','RoadTeam','HomeTeam','Time','Spot','Player','Sal','Ownership','Date', \"SP\"]]\n",
    "\n",
    "    dkdata = ludf3.copy()\n",
    "\n",
    "    try:\n",
    "        checknan = dkdata[[\"BatterTeam\", \"SP\"]]\n",
    "        getnans = checknan[[\"SP\"].isna()]\n",
    "        if len(getnans) == 0:\n",
    "            nonans = 1\n",
    "            nanmapdict = {}\n",
    "        else:\n",
    "            nonans = 0\n",
    "            getnans[\"SP\"] = disabled_span_list\n",
    "            nanmapdict = dict(zip(getnans.Team, getnans.SP))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        dkdata[\"SP\"] = np.where(dkdata[\"SP\"].isna(), dkdata[\"BatterTeam\"].map(nanmapdict), dkdata[\"SP\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(1, len(dkdata) - 1):\n",
    "        if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i-1, 'BatterTeam']:\n",
    "            if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i+1, 'BatterTeam']:\n",
    "                dkdata.loc[i, 'BatterTeam'] = np.nan\n",
    "                dkdata.loc[i, 'HomeTeam'] = np.nan\n",
    "                dkdata.loc[i, 'RoadTeam'] = np.nan\n",
    "                dkdata.loc[i, 'SP'] = np.nan\n",
    "\n",
    "    \n",
    "    dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n",
    "    dkdata = dkdata.drop_duplicates(subset = [\"BatterTeam\", \"SP\"], keep = \"first\")\n",
    "    dkdata = dkdata.drop(columns = [\"Time\", \"Sal\", \"Ownership\"])\n",
    "\n",
    "    dkdata['BatterTeam'] = dkdata['BatterTeam'].replace('ARI', 'AZ')\n",
    "    dkdata['RoadTeam'] = dkdata['RoadTeam'].replace('ARI', 'AZ')\n",
    "    dkdata['HomeTeam'] = dkdata['HomeTeam'].replace('ARI', 'AZ')\n",
    "\n",
    "    dkdata['Date'] = pd.to_datetime(dkdata['Date'])\n",
    "    dkdata['Date'] = dkdata['Date'].dt.strftime('%Y-%m-%d')\n",
    "    dkdata = dkdata.set_index(\"Date\")\n",
    "    dkdata = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\", \"SP\"]]\n",
    "\n",
    "    return(dkdata)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Loads regular season data from 2021-23 to train on"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T01:38:19.375038Z",
     "start_time": "2025-06-23T01:38:17.674389Z"
    }
   },
   "source": [
    "#statcast(start_dt = \"2021-04-01\", end_dt = \"2021-10-03\")\n",
    "#statcast(start_dt = \"2022-04-07\", end_dt = \"2022-10-02\")\n",
    "#statcast(start_dt = \"2023-03-30\", end_dt = \"2023-10-01\")\n",
    "\n",
    "savant2021 = pl.read_parquet(\"~/Desktop/Desktop - Cameron MacBook Pro/Random-Projects/MLB/Data/savant2021.parquet\")\n",
    "savant2022 = pl.read_parquet(\"~/Desktop/Desktop - Cameron MacBook Pro/Random-Projects/MLB/Data/savant2022.parquet\")\n",
    "savant2023 = pl.read_parquet(\"~/Desktop/Desktop - Cameron MacBook Pro/Random-Projects/MLB/Data/savant2023.parquet\")"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T01:38:24.371891Z",
     "start_time": "2025-06-23T01:38:19.380691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate DataFrames\n",
    "combined1 = pl.concat([savant2021, savant2022, savant2023])\n",
    "\n",
    "# Convert game_date using flexible datetime parsing\n",
    "combined1 = combined1.with_columns(pl.col('game_date').str.to_datetime().alias('game_date'))\n",
    "\n",
    "# Create BatterTeam and PitcherTeam columns using conditional logic\n",
    "combined1 = combined1.with_columns([pl.when(pl.col('inning_topbot') == 'Top').then(pl.col('away_team')).otherwise(pl.col('home_team')).alias('BatterTeam'),\n",
    "    pl.when(pl.col('inning_topbot') == 'Top').then(pl.col('home_team')).otherwise(pl.col('away_team')).alias('PitcherTeam')])\n",
    "\n",
    "# Calculate runs scored\n",
    "combined1 = combined1.with_columns([\n",
    "    (pl.col('post_away_score') - pl.col('away_score')).alias('AwayRunsScored'),\n",
    "    (pl.col('post_home_score') - pl.col('home_score')).alias('HomeRunsScored')])\n",
    "\n",
    "# Apply custom functions to player_name\n",
    "combined1 = combined1.with_columns(pl.col('player_name').map_elements(flip_names, return_dtype=pl.Utf8).alias('player_name'))\n",
    "combined1 = combined1.with_columns(pl.col('player_name').map_elements(replace_special_chars, return_dtype=pl.Utf8).alias('player_name'))"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DF where it only loads in the stats of starting pitchers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T01:51:03.561073Z",
     "start_time": "2025-06-23T01:50:59.357463Z"
    }
   },
   "source": [
    "# Define groupby columns\n",
    "groupby_cols = ['game_date', 'BatterTeam', 'away_team', 'home_team']\n",
    "\n",
    "# Select and sort columns (equivalent to your combined2 creation)\n",
    "combined2 = combined1.select([\n",
    "    'game_date', 'home_team', 'away_team', 'inning', 'inning_topbot', 'at_bat_number', 'pitch_number',\n",
    "    'BatterTeam', 'MLBNAME', 'events', 'description', 'bb_type', 'estimated_ba_using_speedangle',\n",
    "    'estimated_woba_using_speedangle', 'woba_value', 'p_throws', 'PitcherTeam', 'player_name',\n",
    "    'delta_run_exp', 'AwayRunsScored', 'HomeRunsScored']).sort([\n",
    "    'game_date', 'home_team', 'away_team', 'inning_topbot', 'at_bat_number', 'pitch_number'], descending=[False, False, False, True, False, False])\n",
    "\n",
    "# Get the first (starter) player_name for each group\n",
    "starter_names = combined2.group_by(groupby_cols).agg(pl.col('player_name').first().alias('starter_name'))\n",
    "\n",
    "# Join back to combined2 to get starter information\n",
    "joined = combined2.join(starter_names, on=groupby_cols, how='left')\n",
    "\n",
    "# Filter to keep only rows where player_name matches the starter\n",
    "df_starters_only = joined.filter(pl.col('player_name') == pl.col('starter_name')).drop('starter_name')\n",
    "\n",
    "# Define count_outs function for Polars (if needed later)\n",
    "def count_outs(events_column):\n",
    "    single_outs = ['other_out', 'strikeout', 'field_out', 'force_out', 'fielders_choice', \n",
    "                   'fielders_choice_out', 'sac_fly', 'sac_bunt', 'caught_stealing_2b', \n",
    "                   'caught_stealing_3b', 'caught_stealing_home', 'pickoff_caught_stealing_2b',  \n",
    "                   'pickoff_caught_stealing_3b', 'pickoff_caught_stealing_home']\n",
    "    double_outs = ['double_play', 'strikeout_double_play', 'grounded_into_double_play', 'sac_fly_double_play']\n",
    "    triple_outs = ['triple_play']\n",
    "    \n",
    "    return (events_column.is_in(single_outs).sum() + \n",
    "        2 * events_column.is_in(double_outs).sum() + \n",
    "        3 * events_column.is_in(triple_outs).sum())"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on a pitch level for pitchers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T01:52:58.569351Z",
     "start_time": "2025-06-23T01:52:17.275589Z"
    }
   },
   "source": [
    "# Perform the groupby aggregation in Polars\n",
    "Train1 = df_starters_only.group_by([\n",
    "    \"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg([pl.count(\"pitch_number\").alias(\"Pitches\"),pl.col(\"events\").filter(pl.col(\"events\").is_in(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error',                          'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).count().alias(\"PA\"),\n",
    "    pl.col(\"events\").map_elements(count_outs, return_dtype=pl.Int64).alias(\"Outs\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\").is_in(['single', 'double', 'triple', 'home_run'])).count().alias(\"Hit\"),\n",
    "    pl.col(\"bb_type\").filter(pl.col(\"bb_type\") == 'fly_ball').count().alias(\"FB\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'home_run').count().alias(\"HR\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'hit_by_pitch').count().alias(\"HBP\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\").is_in([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).count().alias(\"Balls\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'walk').count().alias(\"BB\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\") == 'called_strike').count().alias(\"CS\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\").is_in([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).count().alias(\"Whiff\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\").is_in([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).count().alias(\"Strikes\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'strikeout').count().alias(\"K\"),\n",
    "    pl.col(\"estimated_ba_using_speedangle\").mean().alias(\"xBA\"),\n",
    "    pl.col(\"estimated_woba_using_speedangle\").mean().alias(\"xwOBA\"),\n",
    "    pl.col(\"woba_value\").mean().alias(\"wOBA\"),\n",
    "    pl.col(\"delta_run_exp\").mean().alias(\"RunExp\"),\n",
    "    pl.col(\"AwayRunsScored\").sum().alias(\"AwayRunsScored\"),\n",
    "    pl.col(\"HomeRunsScored\").sum().alias(\"HomeRunsScored\")]).fill_null(0)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on an at bat level"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T02:22:04.823240Z",
     "start_time": "2025-06-23T02:22:04.727091Z"
    }
   },
   "source": [
    "# Group by and aggregate\n",
    "Train2 = Train1.group_by([\n",
    "    \"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg([\n",
    "    pl.col(\"Pitches\").sum().alias(\"Pitches\"),\n",
    "    pl.count(\"at_bat_number\").alias(\"AB\"),\n",
    "    pl.col(\"PA\").sum().alias(\"PA\"),\n",
    "    pl.col(\"Outs\").sum().alias(\"Outs\"),\n",
    "    pl.col(\"Hit\").sum().alias(\"Hits\"),\n",
    "    pl.col(\"FB\").sum().alias(\"FB\"),\n",
    "    pl.col(\"HR\").sum().alias(\"HR\"),\n",
    "    pl.col(\"HBP\").sum().alias(\"HBP\"),\n",
    "    pl.col(\"Balls\").sum().alias(\"Balls\"),\n",
    "    pl.col(\"BB\").sum().alias(\"BB\"),\n",
    "    pl.col(\"CS\").sum().alias(\"CS\"),\n",
    "    pl.col(\"Whiff\").sum().alias(\"Whiff\"),\n",
    "    pl.col(\"Strikes\").sum().alias(\"Strikes\"),\n",
    "    pl.col(\"K\").sum().alias(\"K\"),\n",
    "    pl.col(\"xBA\").mean().alias(\"xBA\"),\n",
    "    pl.col(\"xwOBA\").mean().alias(\"xwOBA\"),\n",
    "    pl.col(\"wOBA\").mean().alias(\"wOBA\"),\n",
    "    pl.col(\"RunExp\").mean().alias(\"RunExp\"),\n",
    "    pl.col(\"AwayRunsScored\").sum().alias(\"AwayRunsScored\"),\n",
    "    pl.col(\"HomeRunsScored\").sum().alias(\"HomeRunsScored\")]).fill_null(0)\n",
    "\n",
    "# Create the RA column using conditional logic\n",
    "Train2 = Train2.with_columns(\n",
    "    pl.when((pl.col('HomeRunsScored') > 0) & (pl.col('BatterTeam') == pl.col('home_team')))\n",
    "      .then(pl.col('HomeRunsScored'))\n",
    "      .when((pl.col('AwayRunsScored') > 0) & (pl.col('BatterTeam') == pl.col('away_team')))\n",
    "      .then(pl.col('AwayRunsScored'))\n",
    "      .otherwise(0)\n",
    "      .alias('RA'))\n",
    "\n",
    "# Create RA/9 column\n",
    "Train2 = Train2.with_columns((27 * pl.col('RA') / pl.col('Outs')).alias('RA/9'))\n",
    "\n",
    "# Drop AwayRunsScored and HomeRunsScored columns\n",
    "Train2 = Train2.drop(['AwayRunsScored', 'HomeRunsScored'])"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating loads of pitcher rate stats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T02:22:14.228346Z",
     "start_time": "2025-06-23T02:22:05.365576Z"
    }
   },
   "source": [
    "# Calculate league-wide statistics\n",
    "lgHR = combined1.filter(pl.col(\"events\") == \"home_run\").height\n",
    "lgFB = combined1.filter(pl.col(\"bb_type\") == \"fly_ball\").height\n",
    "\n",
    "# Add calculated columns to Train2\n",
    "Train2 = Train2.with_columns([\n",
    "    # FIP calculation\n",
    "    ((13 * pl.col('HR') + 3 * (pl.col('BB') + pl.col('HBP')) - 2 * pl.col('K')) / (pl.col('Outs') / 3) + 3.137).alias('FIP'),\n",
    "    \n",
    "    # xFIP calculation\n",
    "    ((13 * (pl.col('FB') * (lgHR / lgFB * 0.58)) + 3 * (pl.col('BB') + pl.col('HBP')) - 2 * pl.col('K')) / (pl.col('Outs') / 3) + 3.137).alias('xFIP'),\n",
    "    \n",
    "    # Percentage calculations\n",
    "    (100 * (pl.col('K') / pl.col('AB'))).round(2).alias('K%'),\n",
    "    (100 * (pl.col('BB') / pl.col('AB'))).round(2).alias('BB%'),\n",
    "    (100 * (pl.col('Balls') / pl.col('Pitches'))).round(2).alias('Ball%'),\n",
    "    (100 * (pl.col('Strikes') / pl.col('Pitches'))).round(2).alias('Strike%'),\n",
    "    (100 * (pl.col('CS') / pl.col('Pitches'))).round(2).alias('CS%'),\n",
    "    (100 * (pl.col('Whiff') / pl.col('Pitches'))).round(2).alias('Whiff%'),\n",
    "    \n",
    "    # CSW calculation\n",
    "    (pl.col('CS') + pl.col('Whiff')).alias('CSW')])\n",
    "\n",
    "# Add K-BB% and CSW% calculations\n",
    "Train2 = Train2.with_columns([\n",
    "    (pl.col('K%') - pl.col('BB%')).alias('K-BB%'),\n",
    "    (100 * (pl.col('CSW') / pl.col('Pitches'))).round(2).alias('CSW%')])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "Train2 = Train2.drop(['CSW'])"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding rolling averages for the past 5 and 10 games"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T02:22:28.901850Z",
     "start_time": "2025-06-23T02:22:28.854589Z"
    }
   },
   "source": [
    "window_size5 = 5\n",
    "window_size10 = 10\n",
    "window_size20 = 20\n",
    "\n",
    "# Sort Train2 by player_name and game_date for rolling\n",
    "Train2 = Train2.sort(['player_name', 'game_date'])\n",
    "\n",
    "# Rolling calculations using .rolling_mean(window, min_samples=1).over('player_name')\n",
    "Train2 = Train2.with_columns([\n",
    "    pl.col('Pitches').rolling_mean(window_size5, min_samples=1).over('player_name').alias('Pitches5'),\n",
    "    pl.col('Outs').rolling_mean(window_size5, min_samples=1).over('player_name').alias('Outs5'),\n",
    "    pl.col('Outs').rolling_mean(window_size10, min_samples=1).over('player_name').alias('Outs10'),\n",
    "    pl.col('xBA').rolling_mean(window_size5, min_samples=1).over('player_name').alias('xBA5'),\n",
    "    pl.col('xBA').rolling_mean(window_size10, min_samples=1).over('player_name').alias('xBA10'),\n",
    "    pl.col('xwOBA').rolling_mean(window_size5, min_samples=1).over('player_name').alias('xwOBA5'),\n",
    "    pl.col('xwOBA').rolling_mean(window_size10, min_samples=1).over('player_name').alias('xwOBA10'),\n",
    "    pl.col('wOBA').rolling_mean(window_size5, min_samples=1).over('player_name').alias('wOBA5'),\n",
    "    pl.col('wOBA').rolling_mean(window_size10, min_samples=1).over('player_name').alias('wOBA10'),\n",
    "    pl.col('RA/9').rolling_mean(window_size5, min_samples=1).over('player_name').alias('RA5'),\n",
    "    pl.col('RA/9').rolling_mean(window_size10, min_samples=1).over('player_name').alias('RA10'),\n",
    "    pl.col('FIP').rolling_mean(window_size5, min_samples=1).over('player_name').alias('FIP5'),\n",
    "    pl.col('FIP').rolling_mean(window_size10, min_samples=1).over('player_name').alias('FIP10'),\n",
    "    pl.col('xFIP').rolling_mean(window_size5, min_samples=1).over('player_name').alias('xFIP5'),\n",
    "    pl.col('xFIP').rolling_mean(window_size10, min_samples=1).over('player_name').alias('xFIP10'),\n",
    "    pl.col('K%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('K%5'),\n",
    "    pl.col('K%').rolling_mean(window_size10, min_samples=1).over('player_name').alias('K%10'),\n",
    "    pl.col('BB%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('BB%5'),\n",
    "    pl.col('BB%').rolling_mean(window_size10, min_samples=1).over('player_name').alias('BB%10'),\n",
    "    pl.col('K-BB%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('K-BB%5'),\n",
    "    pl.col('K-BB%').rolling_mean(window_size10, min_samples=1).over('player_name').alias('K-BB%10'),\n",
    "    pl.col('Ball%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('Ball%5'),\n",
    "    pl.col('Strike%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('Strike%5'),\n",
    "    pl.col('CS%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('CS%5'),\n",
    "    pl.col('CS%').rolling_mean(window_size10, min_samples=1).over('player_name').alias('CS%10'),\n",
    "    pl.col('Whiff%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('Whiff%5'),\n",
    "    pl.col('Whiff%').rolling_mean(window_size10, min_samples=1).over('player_name').alias('Whiff%10'),\n",
    "    pl.col('CSW%').rolling_mean(window_size5, min_samples=1).over('player_name').alias('CSW%5'),\n",
    "    pl.col('CSW%').rolling_mean(window_size10, min_samples=1).over('player_name').alias('CSW%10')])\n",
    "\n",
    "# Filter out rows where Pitches5 < 40\n",
    "Train2 = Train2.filter(pl.col('Pitches5') >= 40)\n",
    "\n",
    "# Drop specified columns\n",
    "Train3 = Train2.drop([\n",
    "    \"FB\", \"Balls\", \"HBP\", \"CS\", \"Whiff\", \"Strikes\", \n",
    "    'Ball%', 'Strike%', 'CS%', 'Whiff%', 'CSW%', \"RA/9\"])\n",
    "\n",
    "# Rename columns\n",
    "Train3 = Train3.rename({\n",
    "    'away_team': 'RoadTeam', \n",
    "    'home_team': 'HomeTeam', \n",
    "    \"player_name\": \"SP\"})"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on a pitch level for batters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:12:47.263411Z",
     "start_time": "2025-06-23T03:12:46.722901Z"
    }
   },
   "source": [
    "# Define the count_outs function for out events\n",
    "out_events = ['other_out', 'field_out', 'field_error', 'fielders_choice', 'fielders_choice_out', 'double_play', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play']\n",
    "\n",
    "# Polars groupby aggregation\n",
    "BatterTrain1 = combined2.group_by([\n",
    "    \"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg([\n",
    "    pl.col(\"pitch_number\").len().alias(\"Pitches\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\").is_in(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).len().alias(\"PA\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\").is_in(out_events)).len().alias(\"Outs\"),\n",
    "    pl.col(\"bb_type\").filter(pl.col(\"bb_type\") == 'fly_ball').len().alias(\"FB\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'home_run').len().alias(\"HR\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'hit_by_pitch').len().alias(\"HBP\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\").is_in([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).len().alias(\"Balls\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'walk').len().alias(\"BB\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\") == 'called_strike').len().alias(\"CS\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\").is_in([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).len().alias(\"Whiff\"),\n",
    "    pl.col(\"description\").filter(pl.col(\"description\").is_in([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).len().alias(\"Strikes\"),\n",
    "    pl.col(\"events\").filter(pl.col(\"events\") == 'strikeout').len().alias(\"K\"),\n",
    "    pl.col(\"estimated_ba_using_speedangle\").mean().alias(\"xBA\"),\n",
    "    pl.col(\"estimated_woba_using_speedangle\").mean().alias(\"xwOBA\"),\n",
    "    pl.col(\"woba_value\").mean().alias(\"wOBA\"),\n",
    "    pl.col(\"delta_run_exp\").mean().alias(\"RunExp\"),\n",
    "    pl.col(\"AwayRunsScored\").sum().alias(\"AwayRunsScored\"),\n",
    "    pl.col(\"HomeRunsScored\").sum().alias(\"HomeRunsScored\")]).fill_null(0)"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on an at bat level"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:21:11.575836Z",
     "start_time": "2025-06-23T03:21:11.387811Z"
    }
   },
   "source": [
    "# First groupby aggregation\n",
    "BatterTrain2 = BatterTrain1.group_by([\n",
    "    \"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"p_throws\"]).agg([\n",
    "    pl.col(\"Pitches\").sum().alias(\"Pitches\"),\n",
    "    pl.col(\"at_bat_number\").len().alias(\"AB\"),\n",
    "    pl.col(\"PA\").sum().alias(\"PA\"),\n",
    "    pl.col(\"Outs\").sum().alias(\"Outs\"),\n",
    "    pl.col(\"FB\").sum().alias(\"FB\"),\n",
    "    pl.col(\"HR\").sum().alias(\"HR\"),\n",
    "    pl.col(\"HBP\").sum().alias(\"HBP\"),\n",
    "    pl.col(\"Balls\").sum().alias(\"Balls\"),\n",
    "    pl.col(\"BB\").sum().alias(\"BB\"),\n",
    "    pl.col(\"CS\").sum().alias(\"CS\"),\n",
    "    pl.col(\"Whiff\").sum().alias(\"Whiff\"),\n",
    "    pl.col(\"Strikes\").sum().alias(\"Strikes\"),\n",
    "    pl.col(\"K\").sum().alias(\"K\"),\n",
    "    pl.col(\"xBA\").mean().alias(\"xBA\"),\n",
    "    pl.col(\"xwOBA\").mean().alias(\"xwOBA\"),\n",
    "    pl.col(\"wOBA\").mean().alias(\"wOBA\"),\n",
    "    pl.col(\"RunExp\").mean().alias(\"RunExp\"),\n",
    "    pl.col(\"AwayRunsScored\").sum().alias(\"AwayRunsScored\"),\n",
    "    pl.col(\"HomeRunsScored\").sum().alias(\"HomeRunsScored\")]).fill_null(0)\n",
    "\n",
    "# Add calculated columns and drop unwanted columns\n",
    "BatterTrain2 = BatterTrain2.with_columns([\n",
    "    # Create RA column using conditional logic\n",
    "    pl.when((pl.col(\"HomeRunsScored\") > 0) & (pl.col(\"BatterTeam\") == pl.col(\"home_team\"))).then(pl.col(\"HomeRunsScored\")).when(\n",
    "        (pl.col(\"AwayRunsScored\") > 0) & (pl.col(\"BatterTeam\") == pl.col(\"away_team\"))).then(pl.col(\"AwayRunsScored\")).otherwise(0).alias(\"RA\"),]).with_columns([\n",
    "    # Create R/9 column\n",
    "    (27 * pl.col(\"RA\") / pl.col(\"Outs\")).alias(\"R/9\")]).drop([\"AwayRunsScored\", \"HomeRunsScored\", \"RA\"])"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:21:11.773268Z",
     "start_time": "2025-06-23T03:21:11.763277Z"
    }
   },
   "source": [
    "# Add calculated columns using with_columns\n",
    "BatterTrain2 = BatterTrain2.with_columns([\n",
    "    # FIP calculation\n",
    "    ((13 * pl.col('HR') + 3 * (pl.col('BB') + pl.col('HBP')) - 2 * pl.col('K')) / \n",
    "     (pl.col('Outs') / 3) + 3.137).alias('FIP'),\n",
    "    \n",
    "    # xFIP calculation (assuming lgHR and lgFB are defined variables)\n",
    "    ((13 * (pl.col('FB') * (lgHR/lgFB * 0.58)) + 3 * (pl.col('BB') + pl.col('HBP')) - 2 * pl.col('K')) / \n",
    "     (pl.col('Outs') / 3) + 3.137).alias('xFIP'),\n",
    "    \n",
    "    # Percentage calculations with rounding\n",
    "    ((pl.col('K') / pl.col('AB')) * 100).round(2).alias('K%'),\n",
    "    ((pl.col('BB') / pl.col('AB')) * 100).round(2).alias('BB%'),\n",
    "    ((pl.col('Balls') / pl.col('Pitches')) * 100).round(2).alias('Ball%'),\n",
    "    ((pl.col('Strikes') / pl.col('Pitches')) * 100).round(2).alias('Strike%'),\n",
    "    ((pl.col('CS') / pl.col('Pitches')) * 100).round(2).alias('CS%'),\n",
    "    ((pl.col('Whiff') / pl.col('Pitches')) * 100).round(2).alias('Whiff%'),\n",
    "    \n",
    "    # CSW calculation (temporary column)\n",
    "    (pl.col('CS') + pl.col('Whiff')).alias('CSW')]).with_columns([\n",
    "    # K-BB% calculation (depends on K% and BB% from previous step)\n",
    "    (pl.col('K%') - pl.col('BB%')).alias('K-BB%'),\n",
    "    \n",
    "    # CSW% calculation\n",
    "    ((pl.col('CSW') / pl.col('Pitches')) * 100).round(2).alias('CSW%')]).drop(['CSW'])"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:21:30.972690Z",
     "start_time": "2025-06-23T03:21:30.925169Z"
    }
   },
   "source": [
    "Train3 = BatterTrain2.with_columns([\n",
    "    # Rolling 5 and 10 game expected batting averages\n",
    "    pl.col(\"xBA\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bxBA5\"),\n",
    "    pl.col(\"xBA\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bxBA10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game expected wOBA averages\n",
    "    pl.col(\"xwOBA\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bxwOBA5\"),\n",
    "    pl.col(\"xwOBA\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bxwOBA10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game wOBA averages\n",
    "    pl.col(\"wOBA\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bwOBA5\"),\n",
    "    pl.col(\"wOBA\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bwOBA10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game RA averages\n",
    "    pl.col(\"R/9\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bRS5\"),\n",
    "    pl.col(\"R/9\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bRS10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game FIP averages\n",
    "    pl.col(\"FIP\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bFIP5\"),\n",
    "    pl.col(\"FIP\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bFIP10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game xFIP averages\n",
    "    pl.col(\"xFIP\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bxFIP5\"),\n",
    "    pl.col(\"xFIP\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bxFIP10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game K% averages\n",
    "    pl.col(\"K%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bK%5\"),\n",
    "    pl.col(\"K%\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bK%10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game BB% averages\n",
    "    pl.col(\"BB%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bBB%5\"),\n",
    "    pl.col(\"BB%\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bBB%10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game K-BB% averages\n",
    "    pl.col(\"K-BB%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bK-BB%5\"),\n",
    "    pl.col(\"K-BB%\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bK-BB%10\"),\n",
    "    \n",
    "    # Rolling 5 game Ball% averages\n",
    "    pl.col(\"Ball%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bBall%5\"),\n",
    "    \n",
    "    # Rolling 5 game Strike% averages\n",
    "    pl.col(\"Strike%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bStrike%5\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game Called Strike% averages\n",
    "    pl.col(\"CS%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bCS%5\"),\n",
    "    pl.col(\"CS%\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bCS%10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game Whiff% averages\n",
    "    pl.col(\"Whiff%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bWhiff%5\"),\n",
    "    pl.col(\"Whiff%\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bWhiff%10\"),\n",
    "    \n",
    "    # Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "    pl.col(\"CSW%\").rolling_mean(window_size=window_size5, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bCSW%5\"),\n",
    "    pl.col(\"CSW%\").rolling_mean(window_size=window_size10, min_samples=1).over([\"BatterTeam\", \"p_throws\"]).alias(\"bCSW%10\")\n",
    "])\n",
    "\n",
    "# Replace infinite values with 5\n",
    "Train3 = Train3.with_columns([\n",
    "    pl.when(pl.col(col).is_infinite())\n",
    "    .then(5)\n",
    "    .otherwise(pl.col(col))\n",
    "    .alias(col)\n",
    "    for col in Train3.columns if col.startswith('b')])"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in today's data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T03:21:52.225438Z",
     "start_time": "2025-06-23T03:21:50.713705Z"
    }
   },
   "source": [
    "TodaysData = getDKData2024()\n",
    "TodaysData"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_65307/2850615655.py:101: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_65307/2850615655.py:180: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           BatterTeam RoadTeam HomeTeam                 SP\n",
       "Date                                                      \n",
       "2025-06-22        BAL      BAL      NYY        Will Warren\n",
       "2025-06-22        NYY      BAL      NYY        Dean Kremer\n",
       "2025-06-22        DET      DET       TB       Zack Littell\n",
       "2025-06-22         TB      DET       TB         Casey Mize\n",
       "2025-06-22        TEX      TEX      PIT      Bailey Falter\n",
       "2025-06-22        PIT      TEX      PIT        Jack Leiter\n",
       "2025-06-22        CWS      CWS      TOR      Chris Bassitt\n",
       "2025-06-22        TOR      CWS      TOR      Adrian Houser\n",
       "2025-06-22        ATL      ATL      MIA    Sandy Alcantara\n",
       "2025-06-22        MIA      ATL      MIA        Bryce Elder\n",
       "2025-06-22        MIL      MIL      MIN     Danny Coulombe\n",
       "2025-06-22        MIN      MIL      MIN     Quinn Priester\n",
       "2025-06-22        CIN      CIN      STL      Miles Mikolas\n",
       "2025-06-22        STL      CIN      STL      Andrew Abbott\n",
       "2025-06-22        SEA      SEA      CHC          Colin Rea\n",
       "2025-06-22        CHC      SEA      CHC      Logan Gilbert\n",
       "2025-06-22         AZ       AZ      COL  Antonio Senzatela\n",
       "2025-06-22        COL       AZ      COL     Brandon Pfaadt\n",
       "2025-06-22        CLE      CLE      OAK           JP Sears\n",
       "2025-06-22        OAK      CLE      OAK      Slade Cecconi\n",
       "2025-06-22        BOS      BOS       SF         Robbie Ray\n",
       "2025-06-22         SF      BOS       SF      Lucas Giolito\n",
       "2025-06-22        HOU      HOU      LAA     Kyle Hendricks\n",
       "2025-06-22        LAA      HOU      LAA         Ryan Gusto\n",
       "2025-06-22        WSH      WSH      LAD                NaN\n",
       "2025-06-22        LAD      WSH      LAD                NaN\n",
       "2025-06-22         KC       KC       SD      Randy Vasquez\n",
       "2025-06-22         SD       KC       SD          Seth Lugo\n",
       "2025-06-22        NYM      NYM      PHI      Jesus Luzardo\n",
       "2025-06-22        PHI      NYM      PHI     David Peterson"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatterTeam</th>\n",
       "      <th>RoadTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>BAL</td>\n",
       "      <td>BAL</td>\n",
       "      <td>NYY</td>\n",
       "      <td>Will Warren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>NYY</td>\n",
       "      <td>BAL</td>\n",
       "      <td>NYY</td>\n",
       "      <td>Dean Kremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>TB</td>\n",
       "      <td>Zack Littell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>TB</td>\n",
       "      <td>DET</td>\n",
       "      <td>TB</td>\n",
       "      <td>Casey Mize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>TEX</td>\n",
       "      <td>TEX</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Bailey Falter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>PIT</td>\n",
       "      <td>TEX</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Jack Leiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>CWS</td>\n",
       "      <td>CWS</td>\n",
       "      <td>TOR</td>\n",
       "      <td>Chris Bassitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>TOR</td>\n",
       "      <td>CWS</td>\n",
       "      <td>TOR</td>\n",
       "      <td>Adrian Houser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Sandy Alcantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>MIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Bryce Elder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>MIL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Danny Coulombe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>MIN</td>\n",
       "      <td>MIL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Quinn Priester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>CIN</td>\n",
       "      <td>CIN</td>\n",
       "      <td>STL</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>STL</td>\n",
       "      <td>CIN</td>\n",
       "      <td>STL</td>\n",
       "      <td>Andrew Abbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>SEA</td>\n",
       "      <td>SEA</td>\n",
       "      <td>CHC</td>\n",
       "      <td>Colin Rea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>CHC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>CHC</td>\n",
       "      <td>Logan Gilbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>COL</td>\n",
       "      <td>Antonio Senzatela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>COL</td>\n",
       "      <td>AZ</td>\n",
       "      <td>COL</td>\n",
       "      <td>Brandon Pfaadt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>CLE</td>\n",
       "      <td>CLE</td>\n",
       "      <td>OAK</td>\n",
       "      <td>JP Sears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>OAK</td>\n",
       "      <td>CLE</td>\n",
       "      <td>OAK</td>\n",
       "      <td>Slade Cecconi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS</td>\n",
       "      <td>SF</td>\n",
       "      <td>Robbie Ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>SF</td>\n",
       "      <td>BOS</td>\n",
       "      <td>SF</td>\n",
       "      <td>Lucas Giolito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>HOU</td>\n",
       "      <td>HOU</td>\n",
       "      <td>LAA</td>\n",
       "      <td>Kyle Hendricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>LAA</td>\n",
       "      <td>HOU</td>\n",
       "      <td>LAA</td>\n",
       "      <td>Ryan Gusto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>WSH</td>\n",
       "      <td>WSH</td>\n",
       "      <td>LAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>LAD</td>\n",
       "      <td>WSH</td>\n",
       "      <td>LAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>KC</td>\n",
       "      <td>KC</td>\n",
       "      <td>SD</td>\n",
       "      <td>Randy Vasquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>SD</td>\n",
       "      <td>KC</td>\n",
       "      <td>SD</td>\n",
       "      <td>Seth Lugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>NYM</td>\n",
       "      <td>NYM</td>\n",
       "      <td>PHI</td>\n",
       "      <td>Jesus Luzardo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>PHI</td>\n",
       "      <td>NYM</td>\n",
       "      <td>PHI</td>\n",
       "      <td>David Peterson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
    "savant2024 = statcast(start_dt = \"2024-03-28\", end_dt = eastern_time.strftime(\"%Y-%m-%d\"))\n",
    "savant2024['game_date'] = pd.to_datetime(savant2024['game_date'])\n",
    "savant2024['game_date'] = savant2024['game_date'].dt.strftime('%Y-%m-%d')\n",
    "savant2024['BatterTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['away_team'], savant2024['home_team'])\n",
    "savant2024['PitcherTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['home_team'], savant2024['away_team'])\n",
    "savant2024 = pd.merge(savant2024, ID[[\"MLBID\", \"MLBNAME\"]], left_on = 'batter', right_on = 'MLBID', how = 'left')\n",
    "savant2024.dropna(subset=['MLBNAME'], inplace=True)\n",
    "savant2024 = savant2024.drop_duplicates(subset = [\"pitch_type\", \"game_date\", \"release_speed\", \"release_pos_x\", \"release_pos_z\", \"player_name\"], keep='first')\n",
    "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(flip_names)\n",
    "savant2024['AwayRunsScored'] = savant2024['post_away_score'] - savant2024['away_score']\n",
    "savant2024['HomeRunsScored'] = savant2024['post_home_score'] - savant2024['home_score']\n",
    "savant2024 = savant2024[[\"game_date\", \"home_team\", \"away_team\", \"inning\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\", \"pitch_type\", \"BatterTeam\", \"MLBNAME\", \"balls\", \"strikes\", \"outs_when_up\", \"events\", \"description\", \"bb_type\", \"hit_distance_sc\", \"launch_speed\", \"launch_angle\", \"estimated_ba_using_speedangle\", \"estimated_woba_using_speedangle\", \"woba_value\", \"p_throws\", \"PitcherTeam\", \"player_name\", \"delta_home_win_exp\", \"delta_run_exp\", \"away_score\", \"home_score\", \"AwayRunsScored\", \"HomeRunsScored\"]].sort_values(by = [\"game_date\", \"home_team\", \"away_team\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\"], ascending=[True, True, True, False, True, True])\n",
    "savant2024 = savant2024.groupby(groupby_cols).apply(keep_starter).reset_index(drop = True)\n",
    "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(replace_special_chars)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the same grouping as the training data at the various levels"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season1 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    Hit = ('events', lambda x: (x.isin(['single', 'double', 'triple', 'home_run'])).sum()),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season2 = Season1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"Pitches\", \"sum\"),\n",
    "    AB = (\"at_bat_number\", \"size\"),\n",
    "    PA = (\"PA\", \"sum\"),\n",
    "    Outs = (\"Outs\", \"sum\"),\n",
    "    Hits = (\"Hit\", \"sum\"),\n",
    "    FB = (\"FB\", \"sum\"),\n",
    "    HR = (\"HR\", \"sum\"),\n",
    "    HBP = (\"HBP\", \"sum\"),\n",
    "    Balls = (\"Balls\", \"sum\"),\n",
    "    BB = (\"BB\", \"sum\"),\n",
    "    CS = (\"CS\", \"sum\"),\n",
    "    Whiff = (\"Whiff\", \"sum\"),\n",
    "    Strikes = (\"Strikes\", \"sum\"),\n",
    "    K = (\"K\", \"sum\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "Season2[\"IP\"] = Season2[\"Outs\"] / 3\n",
    "Season2['RA'] = np.where((Season2['HomeRunsScored'] > 0) & (Season2['BatterTeam'] == Season2['home_team']), Season2[\"HomeRunsScored\"],\n",
    "                        np.where((Season2['AwayRunsScored'] > 0) & (Season2['BatterTeam'] == Season2['away_team']),Season2[\"AwayRunsScored\"], 0))\n",
    "Season2[\"RA/9\"] = (27 * Season2[\"RA\"] / Season2[\"Outs\"])\n",
    "Season2 = Season2.drop(columns = [\"AwayRunsScored\", \"HomeRunsScored\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season2['FIP'] = (13 * Season2['HR'] + 3 * (Season2['BB'] + Season2['HBP']) - 2 * Season2['K']) / (Season2['IP']) + 3.137\n",
    "Season2['xFIP'] = (13 * (Season2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (Season2['BB'] + Season2['HBP']) - 2 * Season2['K']) / (Season2['IP']) + 3.137\n",
    "\n",
    "Season2['K%'] = round((Season2['K'] / Season2['AB']) * 100, 2)\n",
    "Season2['BB%'] = round((Season2['BB'] / Season2['AB']) * 100, 2)\n",
    "Season2['K-BB%'] = Season2[\"K%\"] - Season2[\"BB%\"]\n",
    "Season2['Ball%'] = round((Season2['Balls'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['Strike%'] = round((Season2['Strikes'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['CS%'] = round((Season2['CS'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['Whiff%'] = round((Season2['Whiff'] / Season2['Pitches']) * 100, 2)\n",
    "Season2[\"CSW\"] = Season2[\"CS\"] + Season2[\"Whiff\"]\n",
    "Season2['CSW%'] = round((Season2['CSW'] / Season2['Pitches']) * 100, 2)\n",
    "Season2 = Season2.drop(columns=[\"CSW\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rolling 5 game pitch averages\n",
    "Season2['Pitches5'] = Season2.groupby('player_name')['Pitches'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2 = Season2.drop(Season2[Season2['Pitches5'] < 40].index)\n",
    "# Rolling 5 and 10 game outs averages\n",
    "Season2['Outs5'] = Season2.groupby('player_name')['Outs'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['Outs10'] = Season2.groupby('player_name')['Outs'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected batting averages\n",
    "Season2['xBA5'] = Season2.groupby('player_name')['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xBA10'] = Season2.groupby('player_name')['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Season2['xwOBA5'] = Season2.groupby('player_name')['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xwOBA10'] = Season2.groupby('player_name')['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Season2['wOBA5'] = Season2.groupby('player_name')['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['wOBA10'] = Season2.groupby('player_name')['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Season2['RA5'] = Season2.groupby('player_name')['RA/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['RA10'] = Season2.groupby('player_name')['RA/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Season2['FIP5'] = Season2.groupby('player_name')['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['FIP10'] = Season2.groupby('player_name')['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Season2['xFIP5'] = Season2.groupby('player_name')['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xFIP10'] = Season2.groupby('player_name')['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Season2['K%5'] = Season2.groupby('player_name')['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['K%10'] = Season2.groupby('player_name')['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Season2['BB%5'] = Season2.groupby('player_name')['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['BB%10'] = Season2.groupby('player_name')['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Season2['K-BB%5'] = Season2.groupby('player_name')['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['K-BB%10'] = Season2.groupby('player_name')['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Season2['Ball%5'] = Season2.groupby('player_name')['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Season2['Strike%5'] = Season2.groupby('player_name')['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Season2['CS%5'] = Season2.groupby('player_name')['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['CS%10'] = Season2.groupby('player_name')['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Season2['Whiff%5'] = Season2.groupby('player_name')['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['Whiff%10'] = Season2.groupby('player_name')['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Season2['CSW%5'] = Season2.groupby('player_name')['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['CSW%10'] = Season2.groupby('player_name')['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "Season3 = Season2.drop(columns = [\"FB\", \"Balls\", \"HBP\", \"CS\", \"Whiff\", \"Strikes\", 'Ball%', 'Strike%', 'CS%', 'Whiff%', 'CSW%', \"RA/9\"])\n",
    "Season3 = Season3.rename(columns={'away_team': 'RoadTeam', 'home_team': 'HomeTeam', \"player_name\": \"SP\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping everything to get season and rolling averages for pitchers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Season4 = Season3.groupby([\"SP\", \"p_throws\"]).agg(\n",
    "    Starts = (\"IP\", \"size\"),\n",
    "    Pitches = (\"Pitches\", \"mean\"),\n",
    "    AB = (\"AB\", \"mean\"),\n",
    "    PA = (\"PA\", \"mean\"),\n",
    "    Outs = (\"Outs\", \"mean\"),\n",
    "    Hits = (\"Hits\", \"mean\"),\n",
    "    HR = (\"HR\", \"mean\"),\n",
    "    BB = (\"BB\", \"mean\"),\n",
    "    K = (\"K\", \"mean\"),\n",
    "    RA = (\"RA\", \"mean\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    FIP = (\"FIP\", \"mean\"),\n",
    "    xFIP = (\"xFIP\", \"mean\"),\n",
    "    Kpercent = (\"K%\", \"mean\"),\n",
    "    BBpercent = (\"BB%\", \"mean\"),\n",
    "    KminusBBpercent = (\"K-BB%\", \"mean\"),\n",
    "    Pitches5 =  (\"Pitches5\", \"last\"),\n",
    "    Outs5 =  (\"Outs5\", \"last\"),\n",
    "    Outs10 = (\"Outs10\", \"last\"),\n",
    "    xBA5 =  (\"xBA5\", \"last\"),\n",
    "    xBA10 = (\"xBA10\", \"last\"),\n",
    "    xwOBA5 =  (\"xwOBA5\", \"last\"),\n",
    "    xwOBA10 = (\"xwOBA10\", \"last\"),\n",
    "    wOBA5 =  (\"wOBA5\", \"last\"),\n",
    "    wOBA10 = (\"wOBA10\", \"last\"),\n",
    "    RA5 = (\"RA5\", \"last\"),\n",
    "    RA10 = (\"RA10\", \"last\"),\n",
    "    FIP5 = (\"FIP5\", \"last\"),\n",
    "    FIP10 = (\"FIP10\", \"last\"),\n",
    "    xFIP5 = (\"xFIP5\", \"last\"),\n",
    "    xFIP10 = (\"xFIP10\", \"last\"),\n",
    "    Kpercent5 = (\"K%5\", \"last\"),\n",
    "    Kpercent10 = (\"K%10\", \"last\"),\n",
    "    BBpercent5 = (\"BB%5\", \"last\"),\n",
    "    BBpercent10 = (\"BB%10\", \"last\"),\n",
    "    KminusBBpercent5 = (\"K-BB%5\", \"last\"),\n",
    "    KminusBBpercent10 = (\"K-BB%10\", \"last\"),\n",
    "    Ballpercent5 = (\"Ball%5\", \"last\"),\n",
    "    Strikepercent5 = (\"Strike%5\", \"last\"),\n",
    "    CSpercent5 = (\"CS%5\", \"last\"),\n",
    "    CSpercent10 = (\"CS%10\", \"last\"),\n",
    "    Whiffpercent5 = (\"Whiff%5\", \"last\"),\n",
    "    Whiffpercent10 = (\"Whiff%10\", \"last\"),\n",
    "    CSWpercent5 = (\"CSW%5\", \"last\"),\n",
    "    CSWpercent10 = (\"CSW%10\", \"last\")).reset_index().fillna(0)\n",
    "\n",
    "Season4.rename(columns={col: col.replace('percent', '%') for col in Season4.columns if 'percent' in col}, inplace=True)\n",
    "Season4.rename(columns={col: col.replace('minus', '-') for col in Season4.columns if 'minus' in col}, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BatterSeason1 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BatterSeason2 = BatterSeason1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"p_throws\"]).agg(\n",
    "    Pitches=(\"Pitches\", \"sum\"),\n",
    "    AB=(\"at_bat_number\", \"size\"),\n",
    "    PA=(\"PA\", \"sum\"),\n",
    "    Outs=(\"Outs\", \"sum\"),\n",
    "    FB=(\"FB\", \"sum\"),\n",
    "    HR=(\"HR\", \"sum\"),\n",
    "    HBP=(\"HBP\", \"sum\"),\n",
    "    Balls=(\"Balls\", \"sum\"),\n",
    "    BB=(\"BB\", \"sum\"),\n",
    "    CS=(\"CS\", \"sum\"),\n",
    "    Whiff=(\"Whiff\", \"sum\"),\n",
    "    Strikes=(\"Strikes\", \"sum\"),\n",
    "    K=(\"K\", \"sum\"),\n",
    "    xBA=(\"xBA\", \"mean\"),\n",
    "    xwOBA=(\"xwOBA\", \"mean\"),\n",
    "    wOBA=(\"wOBA\", \"mean\"),\n",
    "    RunExp=(\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored=(\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored=(\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "BatterSeason2['RA'] = np.where((BatterSeason2['HomeRunsScored'] > 0) & (BatterSeason2['BatterTeam'] == BatterSeason2['home_team']),\n",
    "    BatterSeason2[\"HomeRunsScored\"], np.where((BatterSeason2['AwayRunsScored'] > 0) & (BatterSeason2['BatterTeam'] == BatterSeason2['away_team']), BatterSeason2[\"AwayRunsScored\"], 0))\n",
    "BatterSeason2[\"R/9\"] = (27 * BatterSeason2[\"RA\"] / BatterSeason2[\"Outs\"])\n",
    "BatterSeason2 = BatterSeason2.drop(columns=[\"AwayRunsScored\", \"HomeRunsScored\", \"RA\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BatterSeason2['FIP'] = (13 * BatterSeason2['HR'] + 3 * (BatterSeason2['BB'] + BatterSeason2['HBP']) - 2 * BatterSeason2['K']) / (BatterSeason2['Outs'] / 3) + 3.137\n",
    "BatterSeason2['xFIP'] = (13 * (BatterSeason2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (BatterSeason2['BB'] + BatterSeason2['HBP']) - 2 * BatterSeason2['K']) / (BatterSeason2['Outs'] / 3) + 3.137\n",
    "\n",
    "BatterSeason2['K%'] = round((BatterSeason2['K'] / BatterSeason2['AB']) * 100, 2)\n",
    "BatterSeason2['BB%'] = round((BatterSeason2['BB'] / BatterSeason2['AB']) * 100, 2)\n",
    "BatterSeason2['K-BB%'] = BatterSeason2[\"K%\"] - BatterSeason2[\"BB%\"]\n",
    "BatterSeason2['Ball%'] = round((BatterSeason2['Balls'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['Strike%'] = round((BatterSeason2['Strikes'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['CS%'] = round((BatterSeason2['CS'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['Whiff%'] = round((BatterSeason2['Whiff'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2[\"CSW\"] = BatterSeason2[\"CS\"] + BatterSeason2[\"Whiff\"]\n",
    "BatterSeason2['CSW%'] = round((BatterSeason2['CSW'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2 = BatterSeason2.drop(columns = [\"CSW\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rolling 5 and 10 game expected batting averages\n",
    "Season4['bxBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Season4['bxwOBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxwOBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Season4['bwOBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bwOBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Season4['bRS5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bRS10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Season4['bFIP5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bFIP10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Season4['bxFIP5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxFIP10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Season4['bK%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bK%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Season4['bBB%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bBB%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Season4['bK-BB%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bK-BB%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Season4['bBall%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Season4['bStrike%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Season4['bCS%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bCS%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Season4['bWhiff%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bWhiff%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Season4['bCSW%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bCSW%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining both the pitcher averages and the batter rolling averages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TodaysData.dropna(subset=['SP'], inplace=True)\n",
    "TodaysData1 = pd.merge(TodaysData, Season4[['SP', 'p_throws', 'Starts', 'Pitches', 'AB', 'PA', 'Outs', \"Hits\", 'HR', 'BB',\n",
    "       'K', 'RA', 'xBA', 'xwOBA', 'wOBA', 'RunExp', 'FIP', 'xFIP', 'K%', 'BB%',\n",
    "       'K-BB%', 'Pitches5', 'Outs5', 'Outs10', 'xBA5', 'xBA10', 'xwOBA5',\n",
    "       'xwOBA10', 'wOBA5', 'wOBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5',\n",
    "       'xFIP10', 'K%5', 'K%10', 'BB%5', 'BB%10', 'K-BB%5', 'K-BB%10', 'Ball%5',\n",
    "       'Strike%5', 'CS%5', 'CS%10', 'Whiff%5', 'Whiff%10', 'CSW%5', 'CSW%10',\n",
    "       'bxBA5', 'bxBA10', 'bxwOBA5', 'bxwOBA10', 'bwOBA5', 'bwOBA10', 'bRS5',\n",
    "       'bRS10', 'bFIP5', 'bFIP10', 'bxFIP5', 'bxFIP10', 'bK%5', 'bK%10',\n",
    "       'bBB%5', 'bBB%10', 'bK-BB%5', 'bK-BB%10', 'bBall%5', 'bStrike%5',\n",
    "       'bCS%5', 'bCS%10', 'bWhiff%5', 'bWhiff%10', 'bCSW%5', 'bCSW%10']], left_on = ['SP'], right_on = ['SP'], how = 'left')\n",
    "\n",
    "# If no 2024 savant data exists then gives them the league averages from 2022-23\n",
    "TrainMeans = Train3.drop(['BatterTeam', 'RoadTeam', \"HomeTeam\", \"SP\", \"p_throws\"], axis=1).mean()\n",
    "TodaysData1 = TodaysData1.fillna(TrainMeans)\n",
    "TodaysData1 = TodaysData1.replace([float('inf'), -float('inf')], 5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min max scaling to normalize the variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Train4 = Train3.copy()\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columnsTrain = Train4.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_columnsToday = TodaysData1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Fit and transform numeric columns\n",
    "Train4[numeric_columnsTrain] = scaler.fit_transform(Train4[numeric_columnsTrain])\n",
    "TodaysData1[numeric_columnsTrain] = scaler.fit_transform(TodaysData1[numeric_columnsToday])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodes the teams and players allowing to be fed into the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensure Train5 and TodaysData2 are copies of Train4 and TodaysData1 respectively\n",
    "Train5 = Train4.copy()\n",
    "TodaysData2 = TodaysData1.copy()\n",
    "\n",
    "def strip_2_from_columns(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.replace('2', '', regex=False)\n",
    "    return df\n",
    "\n",
    "# Apply the function to TodaysData2\n",
    "TodaysData2 = strip_2_from_columns(TodaysData2, ['BatterTeam', 'HomeTeam', 'RoadTeam'])\n",
    "\n",
    "# Dictionary to store the label encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode non-numeric columns in Train4\n",
    "non_numeric_columns_train = Train5.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_train:\n",
    "    label_encoder = LabelEncoder()\n",
    "    Train5[col] = label_encoder.fit_transform(Train5[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "# Ensure all non-numeric columns in Train4 are in TodaysData1\n",
    "for col in non_numeric_columns_train:\n",
    "    if col not in TodaysData2.columns:\n",
    "        print(f\"Warning: Column {col} from training data is not present in today's data.\")\n",
    "        # Adding the missing column with a default value\n",
    "        TodaysData2[col] = 536\n",
    "\n",
    "# Encode non-numeric columns in TodaysData1 using the same encoders\n",
    "non_numeric_columns_today = TodaysData2.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        unique_values = set(label_encoder.classes_)\n",
    "        encoded_values = []\n",
    "        for item in TodaysData2[col]:\n",
    "            if item in unique_values:\n",
    "                encoded_values.append(label_encoder.transform([item])[0])\n",
    "            else:\n",
    "                encoded_values.append(536)  # Using 536 as a placeholder for unknown categories\n",
    "        TodaysData2[col] = encoded_values\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} is not present in the training data.\")\n",
    "        # Fit a new label encoder for columns not present in Train4, but be cautious with this\n",
    "        label_encoder = LabelEncoder()\n",
    "        TodaysData2[col] = label_encoder.fit_transform(TodaysData2[col])\n",
    "        label_encoders[col] = label_encoder"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used Lasso Regression to find optimal features for each model used\n",
    "- Also looked at the VIF to get rid of features that had high multicollinearity\n",
    "- Repeated this process until satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "kData = Train5[[\"RoadTeam\", 'HomeTeam', 'SP', 'p_throws', 'Pitches', \"PA\", 'Outs', 'Hits', 'HR', 'xBA', 'xwOBA', 'wOBA', 'RA', 'FIP', 'xFIP', 'K%', 'BB%', 'Pitches5', 'xBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5', 'K%5', 'Strike%5', 'Whiff%10', 'CSW%5', 'bxBA5', 'bxwOBA10', 'bxFIP5', 'bBB%5', 'bK-BB%10', 'bBall%5', 'bCS%10', \"K\"]]\n",
    "\n",
    "kTodaysData = TodaysData2[[\"RoadTeam\", 'HomeTeam', 'SP', 'p_throws', 'Pitches', \"PA\", 'Outs', 'Hits', 'HR', 'xBA', 'xwOBA', 'wOBA', 'RA', 'FIP', 'xFIP', 'K%', 'BB%', 'Pitches5', 'xBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5', 'K%5', 'Strike%5', 'Whiff%10', 'CSW%5', 'bxBA5', 'bxwOBA10', 'bxFIP5', 'bBB%5', 'bK-BB%10', 'bBall%5', 'bCS%10', \"K\", \"Starts\"]]\n",
    "\n",
    "kData.loc[:,\"K\"] = Train3[\"K\"]\n",
    "kTodaysData.loc[:,\"K\"] = TodaysData1[\"K\"]\n",
    "\n",
    "TrainFeatures = kData.drop(columns = [\"K\"]).values.reshape(-1, 31)\n",
    "TrainLabel = kData[\"K\"].values.ravel()\n",
    "TodayFeatures = kTodaysData.drop(columns = [\"Starts\", \"K\"]).values.reshape(-1, 31)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(31,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xK\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BB Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bbData = Train5[['RoadTeam', 'HomeTeam', 'p_throws', 'Pitches', 'PA', 'Outs', 'Hits', 'K', 'xBA', 'xwOBA', 'RA', 'xFIP', 'BB%', 'Pitches5', 'Outs5', 'xBA10', 'xwOBA5', 'K%5', 'Ball%5', 'Strike%5', 'bxBA10', 'bxFIP10', 'bWhiff%10', 'bCSW%5', \"BB\"]]\n",
    "\n",
    "bbTodaysData = TodaysData2[['RoadTeam', 'HomeTeam', 'p_throws', 'Pitches', 'PA', 'Outs', 'Hits', 'K', 'xBA', 'xwOBA', 'RA', 'xFIP', 'BB%', 'Pitches5', 'Outs5', 'xBA10', 'xwOBA5', 'K%5', 'Ball%5', 'Strike%5', 'bxBA10', 'bxFIP10', 'bWhiff%10', 'bCSW%5', \"BB\", \"Starts\"]]\n",
    "\n",
    "bbData.loc[:,\"BB\"] = Train3[\"BB\"]\n",
    "bbTodaysData.loc[:,\"BB\"] = TodaysData1[\"BB\"]\n",
    "\n",
    "TrainFeatures = kData.drop(columns = [\"K\"]).values.reshape(-1, 24)\n",
    "TrainLabel = kData[\"K\"].values.ravel()\n",
    "TodayFeatures = kTodaysData.drop(columns = [\"Starts\", \"K\"]).values.reshape(-1, 24)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(24,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xBB\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hits Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "hitsData = Train5[['SP', 'p_throws', 'Pitches', 'PA', 'Outs', 'HR', 'BB', 'K', 'RA', 'xBA', 'xwOBA', 'wOBA', 'FIP', 'xFIP', 'Pitches5', 'RA5', 'Ball%5', 'Strike%5', \"Hits\"]]\n",
    "\n",
    "hitsTodaysData = TodaysData2[['SP', 'p_throws', 'Pitches', 'PA', 'Outs', 'HR', 'BB', 'K', 'RA', 'xBA', 'xwOBA', 'wOBA', 'FIP', 'xFIP', 'Pitches5', 'RA5', 'Ball%5', 'Strike%5', \"Hits\", \"Starts\"]]\n",
    "\n",
    "hitsData.loc[:,\"Hits\"] = Train3[\"Hits\"]\n",
    "hitsTodaysData.loc[:,\"Hits\"] = TodaysData1[\"Hits\"]\n",
    "\n",
    "TrainFeatures = hitsData.drop(columns = [\"Hits\"]).values.reshape(-1, 18)\n",
    "TrainLabel = hitsData[\"Hits\"].values.ravel()\n",
    "TodayFeatures = hitsTodaysData.drop(columns = [\"Starts\", \"Hits\"]).values.reshape(-1, 18)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(18,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xHits\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model has an error of about 1, just hard to predict from"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "raData = Train5[['SP', 'p_throws', 'AB', 'Outs', 'Hits', 'HR', 'BB', 'K', 'xBA', 'RunExp', 'Pitches5', 'Outs5', 'xBA5', 'wOBA5', 'RA5', \"RA\"]]\n",
    "\n",
    "raTodaysData = TodaysData2[['SP', 'p_throws', 'AB', 'Outs', 'Hits', 'HR', 'BB', 'K', 'xBA', 'RunExp', 'Pitches5', 'Outs5', 'xBA5', 'wOBA5', 'RA5', \"RA\", \"Starts\"]]\n",
    "\n",
    "raData.loc[:,\"RA\"] = Train3[\"RA\"]\n",
    "raTodaysData.loc[:,\"RA\"] = TodaysData1[\"RA\"]\n",
    "\n",
    "TrainFeatures = raData.drop(columns = [\"RA\"]).values.reshape(-1, 15)\n",
    "TrainLabel = raData[\"RA\"].values.ravel()\n",
    "TodayFeatures = raTodaysData.drop(columns = [\"Starts\", \"RA\"]).values.reshape(-1, 15)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(15,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xRA\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "outsData = Train5[['SP', 'AB', 'PA', 'Hits', 'BB', 'RA', 'wOBA', 'Outs5', \"Outs\"]]\n",
    "\n",
    "outsTodaysData = TodaysData2[['SP', 'AB', 'PA', 'Hits', 'BB', 'RA', 'wOBA', 'Outs5', \"Outs\", \"Starts\"]]\n",
    "\n",
    "outsData.loc[:,\"Outs\"] = Train3[\"Outs\"]\n",
    "outsTodaysData.loc[:,\"Outs\"] = TodaysData1[\"Outs\"]\n",
    "\n",
    "TrainFeatures = outsData.drop(columns = [\"Outs\"]).values.reshape(-1, 8)\n",
    "TrainLabel = outsData[\"Outs\"].values.ravel()\n",
    "TodayFeatures = outsTodaysData.drop(columns = [\"Starts\", \"Outs\"]).values.reshape(-1, 8)\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(8,))  # Adjusted to match the number of features\n",
    "x = Dense(units=160, activation='relu', kernel_regularizer=l2(0.0001119799781856557))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.0025661817326560264))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0021599950963650445), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(TrainFeatures, TrainLabel, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "NNpred = model.predict(TodayFeatures).flatten()\n",
    "TodaysData2[\"xOuts\"] = NNpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse encodes today's data so it can be understood"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensure Train5 and TodaysData2 are copies of Train4 and TodaysData1 respectively\n",
    "Train5 = Train3.copy()\n",
    "TodaysData2 = TodaysData1.copy()\n",
    "\n",
    "def strip_2_from_columns(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.replace('2', '', regex=False)\n",
    "    return df\n",
    "\n",
    "# Apply the function to TodaysData2\n",
    "TodaysData2 = strip_2_from_columns(TodaysData2, ['BatterTeam', 'HomeTeam', 'RoadTeam'])\n",
    "\n",
    "# Dictionary to store the label encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode non-numeric columns in Train4\n",
    "non_numeric_columns_train = Train5.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_train:\n",
    "    label_encoder = LabelEncoder()\n",
    "    Train5[col] = label_encoder.fit_transform(Train5[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "# Ensure all non-numeric columns in Train4 are in TodaysData1\n",
    "for col in non_numeric_columns_train:\n",
    "    if col not in TodaysData2.columns:\n",
    "        print(f\"Warning: Column {col} from training data is not present in today's data.\")\n",
    "        # Adding the missing column with a default value\n",
    "        # There are 535 unique starting pitchers in the training set\n",
    "        TodaysData2[col] = 536\n",
    "\n",
    "# Encode non-numeric columns in TodaysData1 using the same encoders\n",
    "non_numeric_columns_today = TodaysData2.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        unique_values = set(label_encoder.classes_)\n",
    "        encoded_values = []\n",
    "        for item in TodaysData2[col]:\n",
    "            if item in unique_values:\n",
    "                encoded_values.append(label_encoder.transform([item])[0])\n",
    "            else:\n",
    "                encoded_values.append(536)  # Using 536 as a placeholder for unknown categories\n",
    "        TodaysData2[col] = encoded_values\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} is not present in the training data.\")\n",
    "        # Fit a new label encoder for columns not present in Train4, but be cautious with this\n",
    "        label_encoder = LabelEncoder()\n",
    "        TodaysData2[col] = label_encoder.fit_transform(TodaysData2[col])\n",
    "        label_encoders[col] = label_encoder"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to mess with Neural Networks and see if their results are better"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Assuming TrainFeatures and TrainLabel are your prepared datasets\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "TrainFeatures = scaler.fit_transform(Train5.drop(columns=[\"K\"]).values.reshape(-1, 77))\n",
    "TrainLabel = Train5[\"K\"].values\n",
    "TodayFeatures = scaler.transform(TodaysData2.drop(columns=[\"Starts\", \"K\"]).values.reshape(-1, 77))\n",
    "\n",
    "# Define the model with adjustments\n",
    "input_layer = Input(shape=(77,))\n",
    "x = Dense(units=128, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(units=64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(units=32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "output_layer = Dense(units=1, activation = \"softplus\")(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.1), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(TrainFeatures, TrainLabel, epochs=20, batch_size=64, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "RFpred = model.predict(TodayFeatures)\n",
    "TodaysData2[\"xK\"] = RFpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        # Handling default value of 536\n",
    "        TodaysData2[col] = TodaysData2[col].apply(lambda x: label_encoder.inverse_transform([x])[0] if x != 536 else np.nan)\n",
    "\n",
    "TodaysData2['SP'] = TodaysData2['SP'].fillna(TodaysData1['SP'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_2_to_duplicates(df):\n",
    "    mask = df.duplicated(subset=['BatterTeam', 'RoadTeam', 'HomeTeam'], keep='first')\n",
    "    \n",
    "    df.loc[mask, 'BatterTeam'] += '2'\n",
    "    df.loc[mask, 'RoadTeam'] += '2'\n",
    "    df.loc[mask, 'HomeTeam'] += '2'\n",
    "    \n",
    "    return df\n",
    "\n",
    "TodaysData2 = add_2_to_duplicates(TodaysData2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TodaysData2[[\"BatterTeam\", \"SP\", \"Starts\", \"K\", \"xK\"]].sort_values(\"xK\", ascending = True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates simple dataset to see the expected stats of all the predicted metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Performs a two \"sample\" z test to see the likelihood of a quality start occurring\n",
    "def row_z_score(row):\n",
    "    x_bar1 = row[\"xRA\"]\n",
    "    x_bar2 = row[\"xOuts\"]\n",
    "    mu1 = 3\n",
    "    mu2 = 18\n",
    "    sigma1 = Train2[\"RA\"].std()\n",
    "    sigma2 = Train2[\"Outs\"].std()\n",
    "    n1 = len(TodaysData2)\n",
    "    n2 = n1\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_score_xRA = (x_bar1 - mu1) / (sigma1 / np.sqrt(n1))\n",
    "    z_score_xOuts = (x_bar2 - mu2) / (sigma2 / np.sqrt(n2))\n",
    "    \n",
    "    # Calculate probabilities, want less than\n",
    "    prob_xRA_less_than_mu1 = 1 - stats.norm.cdf(z_score_xRA)\n",
    "    prob_xOuts_greater_than_mu2 = stats.norm.cdf(z_score_xOuts)\n",
    "\n",
    "    # Combine probabilities by multiplying it\n",
    "    combined_prob = prob_xRA_less_than_mu1 * prob_xOuts_greater_than_mu2\n",
    "    return combined_prob\n",
    "\n",
    "# Calculate the chance of a quality start occurring and finds the xQS points\n",
    "percent = TodaysData2.apply(row_z_score, axis=1)\n",
    "xQS = percent * 5\n",
    "\n",
    "# Adds the xQS to the xFS\n",
    "TodaysData2.loc[:, \"xFS\"] = (xQS + TodaysData2[\"xK\"] * 3 + TodaysData2[\"xOuts\"] - TodaysData2[\"xRA\"] * 3)\n",
    "TodaysData3 = TodaysData2[[\"BatterTeam\", \"SP\", \"Starts\", \"xK\", \"xBB\", \"xHA\", \"xRA\", \"xOuts\", \"xFS\"]].round(2)\n",
    "TodaysData3.sort_values(\"xFS\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
