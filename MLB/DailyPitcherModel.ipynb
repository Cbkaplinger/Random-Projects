{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybaseball\n",
    "from pybaseball import statcast\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import requests\n",
    "import unicodedata\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "pybaseball.cache.enable()\n",
    "\n",
    "from RosterScraper import RosterScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in StatCast ID so batter names show in the Statcast data and loads in a scraped DF with every 40 man roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/1JgczhD5VDQ1EiXqVG-blttZcVwbZd5_Ne_mefUGwJnk/pub?output=csv'\n",
    "res = requests.get(url)\n",
    "ID = pd.read_csv(io.BytesIO(res.content), sep=',')\n",
    "ID.dropna(subset=['MLBID'], inplace=True)\n",
    "ID['MLBID'] = ID['MLBID'].astype(int)\n",
    "\n",
    "Rosters = RosterScraper()\n",
    "BID = Rosters[Rosters[\"Position\"] == \"Batter\"]\n",
    "PID = Rosters[Rosters[\"Position\"] == \"Pitcher\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating functions for data manipulation so they can match when joining separate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_name(name):\n",
    "    if name == 'Rockies':\n",
    "        return 'COL'\n",
    "    elif name == 'Reds':\n",
    "        return 'CIN'\n",
    "    elif name == 'Mariners':\n",
    "        return 'SEA'\n",
    "    elif name == 'Nationals':\n",
    "        return 'WSH'\n",
    "    elif name == 'Yankees':\n",
    "        return 'NYY'\n",
    "    elif name == 'Astros':\n",
    "        return 'HOU'\n",
    "    elif name == 'Red Sox':\n",
    "        return 'BOS'\n",
    "    elif name == 'Athletics':\n",
    "        return 'OAK'\n",
    "    elif name == 'Mets':\n",
    "        return 'NYM'\n",
    "    elif name == 'Braves':\n",
    "        return 'ATL'\n",
    "    elif name == 'Giants':\n",
    "        return 'SF'\n",
    "    elif name == 'Brewers':\n",
    "        return 'MIL'\n",
    "    elif name == 'Rays':\n",
    "        return 'TB'\n",
    "    elif name == 'Royals':\n",
    "        return 'KC'\n",
    "    elif name == 'White Sox':\n",
    "        return 'CWS'\n",
    "    elif name == 'Cubs':\n",
    "        return 'CHC'\n",
    "    elif name == 'Angels':\n",
    "        return 'LAA'\n",
    "    elif name == 'Tigers':\n",
    "        return 'DET'\n",
    "    elif name == 'Diamondbacks':\n",
    "        return 'ARI'\n",
    "    elif name == 'Guardians':\n",
    "        return 'CLE'\n",
    "    elif name == 'Orioles':\n",
    "        return 'BAL'\n",
    "    elif name == 'Twins':\n",
    "        return 'MIN'\n",
    "    elif name == 'Marlins':\n",
    "        return 'MIA'\n",
    "    elif name == 'Phillies':\n",
    "        return 'PHI'\n",
    "    elif name == 'Rangers':\n",
    "        return 'TEX'\n",
    "    elif name == 'Dodgers':\n",
    "        return 'LAD'\n",
    "    elif name == 'Padres':\n",
    "        return 'SD'\n",
    "    elif name == 'Pirates':\n",
    "        return 'PIT'\n",
    "    elif name == 'Blue Jays':\n",
    "        return 'TOR'\n",
    "    elif name == 'Cardinals':\n",
    "        return 'STL'\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def flip_names(name):\n",
    "    first_name, last_name = name.split(\", \")\n",
    "    return f\"{last_name} {first_name}\"\n",
    "\n",
    "def replace_special_chars(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "def append_suffix_to_duplicates(df, column):\n",
    "        seen = {}\n",
    "        for idx, value in enumerate(df[column]):\n",
    "            if value in seen:\n",
    "                seen[value] += 1\n",
    "                df.at[idx, column] = f\"{value}2\"\n",
    "            else:\n",
    "                seen[value] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the RotoGrinders website for daily pitchers and lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDKData2024():\n",
    "    eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
    "    todaysdate = eastern_time.strftime(\"%m-%d-%Y\")\n",
    "    url = 'https://rotogrinders.com/lineups/mlb?site=draftkings'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    gamelist = []\n",
    "    gamecards = soup.findAll(\"div\", {\"class\": \"game-card-teams\"})\n",
    "    for x in gamecards:\n",
    "        twoteams = x.findAll(\"span\", {\"class\": \"team-nameplate-mascot\"})\n",
    "        roadteam = convert_name(twoteams[0].text)\n",
    "        hometeam = convert_name(twoteams[1].text)\n",
    "        gamekey = \"{}@{}\".format(roadteam,hometeam)\n",
    "        gamelist.append(gamekey)\n",
    "\n",
    "    matchupsdf = pd.DataFrame()\n",
    "    for game in gamelist:\n",
    "        roadteam = game.split(\"@\")[0]\n",
    "        hometeam = game.split(\"@\")[1]\n",
    "        thisdf1 = pd.DataFrame({\"Team\": roadteam, \"Opp\": hometeam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
    "        thisdf2 = pd.DataFrame({\"Team\": hometeam, \"Opp\": roadteam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
    "        matchupsdf = pd.concat([matchupsdf,thisdf1,thisdf2])\n",
    "        \n",
    "    oppdict = dict(zip(matchupsdf.Team,matchupsdf.Opp))\n",
    "    hometeamdict = dict(zip(matchupsdf.Team,matchupsdf.HomeTeam))\n",
    "    roadteamdict = dict(zip(matchupsdf.Team,matchupsdf.RoadTeam))\n",
    "\n",
    "    disabled_span_list = []\n",
    "    for span in soup.findAll(\"span\", {\"class\": \"player-nameplate disabled\"}):\n",
    "        for a in span.findAll(\"a\"):\n",
    "            disabled_span_list.append(a.text)\n",
    "\n",
    "    spdata = pd.DataFrame()\n",
    "    for div in soup.findAll(\"span\", {\"class\": \"player-nameplate\", \"data-position\": \"SP\"}):\n",
    "        if \"TBD\" in str(div):\n",
    "            playername = \"TBD\"\n",
    "            pos = \"SP\"\n",
    "            sal = 0\n",
    "        else:\n",
    "            for a in div.findAll('a', {'class': 'player-nameplate-name'}):\n",
    "                playername = a.text.strip()\n",
    "\n",
    "            strdiv = str(div)\n",
    "            pos = strdiv[strdiv.find(\"data-position\")+15:strdiv.find(\"data-salary\")-2]\n",
    "            sal = strdiv[strdiv.find(\"data-salary\")+13:strdiv.find(\"<div class = 'player-nameplate-info'>\")-3]\n",
    "        try:\n",
    "            ownership = strdiv[strdiv.find('<span class=\"small muted\" data-auth=\"502\">') + 42:strdiv.find('%')]\n",
    "            ownership = ownership.replace(\"</span>\", \"\")\n",
    "            ownership = ownership.replace(\"</span\", \"\")\n",
    "            ownership = ownership.replace(\"</div>\", \"\")\n",
    "            ownership = ownership.replace(\" \", \"\")\n",
    "        except:\n",
    "            ownership = np.nan\n",
    "\n",
    "        thisspdata = pd.DataFrame([[playername, sal, ownership]], columns = [\"Player\", \"Salary\", \"Ownership\"])\n",
    "        spdata = pd.concat([spdata, thisspdata])\n",
    "\n",
    "    spdata['Player'] = spdata['Player'].replace('Luis Ortiz', 'Luis L. Ortiz')\n",
    "    spdata['Player'] = spdata['Player'].replace('Mike King', 'Michael King')\n",
    "    spdata['Player'] = spdata['Player'].replace('Robert Zastryzny', 'Rob Zastryzny')\n",
    "\n",
    "    spdata2 = pd.merge(spdata, PID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"PitcherTeam\"})\n",
    "    spdata3 = pd.merge(spdata2, matchupsdf[[\"Team\", \"Opp\"]], left_on = [\"PitcherTeam\"], right_on = [\"Team\"], how = \"left\").drop(columns = [\"Team\"])\n",
    "\n",
    "    append_suffix_to_duplicates(spdata3, 'PitcherTeam')\n",
    "    append_suffix_to_duplicates(spdata3, 'Opp')\n",
    "\n",
    "    opp_spname_dict = dict(zip(spdata3.Opp, spdata3.Player))\n",
    "    opp_spsal_dict = dict(zip(spdata3.Opp, spdata.Salary))\n",
    "    opp_spown_dict = dict(zip(spdata3.Opp, spdata3.Ownership))\n",
    "\n",
    "    ludf = pd.DataFrame()\n",
    "    \n",
    "    for li in soup.findAll(\"li\", {\"class\": \"lineup-card-player\"}):\n",
    "        for a in li.findAll(\"a\", {\"class\": [\"player-nameplate-name\", \"player-nameplate disabled\"]}):\n",
    "            playername = a.text\n",
    "\n",
    "        listring = str(li)\n",
    "        for span in li.find(\"span\", {\"class\": \"small\"}):\n",
    "            luspot = span.text\n",
    "            luspot = luspot.replace(\"\\n\", \"\")\n",
    "            luspot = luspot.strip()\n",
    "            luspot = int(luspot)\n",
    "        pos = listring[listring.find(\"data-position\")+15:listring.find(\"data-salary\")-2]\n",
    "        sal = listring[listring.find(\"data-salary\")+13:listring.find(\"<span class='small'>\")-3]\n",
    "        ownership = ownership.replace(\"</span>\", \"\")\n",
    "        ownership = ownership.replace(\"</span\", \"\")\n",
    "        ownership = ownership.replace(\"</li\", \"\")\n",
    "        ownership = ownership.replace(\"</div>\", \"\")\n",
    "        ownership = ownership.replace(\" \", \"\")\n",
    "\n",
    "        try:\n",
    "            sal = int(sal)\n",
    "        except:\n",
    "            sal = 0\n",
    "        thisludf = pd.DataFrame([[playername, luspot, sal, ownership]], columns = [\"Player\", \"Spot\", \"Sal\", \"Ownership\"])\n",
    "        ludf = pd.concat([ludf, thisludf])\n",
    "\n",
    "    ludf2 = pd.merge(ludf, BID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"BatterTeam\"})\n",
    "    ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
    "    ludf2['HomeTeam'] = ludf2['BatterTeam'].map(hometeamdict)\n",
    "    ludf2['RoadTeam'] = ludf2['BatterTeam'].map(roadteamdict)\n",
    "\n",
    "    ludf2_teamlist = list(ludf2[\"BatterTeam\"])\n",
    "\n",
    "    dhteams = []\n",
    "    for x in ludf2_teamlist:\n",
    "        if ludf2_teamlist.count(x) > 11:\n",
    "            if x in dhteams:\n",
    "                pass\n",
    "            else:\n",
    "                dhteams.append(x)\n",
    "\n",
    "    extract_dh = ludf2[ludf2[\"BatterTeam\"].isin(dhteams)]\n",
    "    new_ludf2 = ludf2[~ludf2[\"BatterTeam\"].isin(dhteams)]\n",
    "\n",
    "    new_team_list = []\n",
    "    new_home_list = []\n",
    "    new_road_list = []\n",
    "    runcounter = 0\n",
    "\n",
    "    for x, home, road in zip(extract_dh[\"BatterTeam\"].astype(str), \n",
    "                         extract_dh[\"HomeTeam\"].astype(str), \n",
    "                         extract_dh[\"RoadTeam\"].astype(str)):\n",
    "        if runcounter < 18:\n",
    "            new_team_list.append(x)\n",
    "            new_home_list.append(home)\n",
    "            new_road_list.append(road)\n",
    "            runcounter += 1\n",
    "        else:\n",
    "            new_team_list.append(x + \"2\")\n",
    "            new_home_list.append(home + \"2\")\n",
    "            new_road_list.append(road + \"2\")\n",
    "            runcounter += 1\n",
    "\n",
    "    extract_dh[\"BatterTeam\"] = new_team_list\n",
    "    extract_dh[\"HomeTeam\"] = new_home_list\n",
    "    extract_dh[\"RoadTeam\"] = new_road_list\n",
    "\n",
    "    ludf2 = pd.concat([extract_dh, new_ludf2])\n",
    "    ludf2[\"Opp\"] = ludf2[\"BatterTeam\"].map(oppdict)\n",
    "    ludf2['SP'] = ludf2['BatterTeam'].map(opp_spname_dict)\n",
    "    ludf2['SPSal'] = ludf2['BatterTeam'].map(opp_spsal_dict)\n",
    "    ludf2['SPOwnership'] = ludf2['BatterTeam'].map(opp_spown_dict)\n",
    "    ludf2['Date'] = todaysdate\n",
    "    ludf2['Time'] = np.nan\n",
    "\n",
    "    ludf3 = ludf2[['BatterTeam','RoadTeam','HomeTeam','Time','Spot','Player','Sal','Ownership','Date', \"SP\"]]\n",
    "\n",
    "    dkdata = ludf3.copy()\n",
    "\n",
    "    try:\n",
    "        checknan = dkdata[[\"BatterTeam\", \"SP\"]]\n",
    "        getnans = checknan[[\"SP\"].isna()]\n",
    "        if len(getnans) == 0:\n",
    "            nonans = 1\n",
    "            nanmapdict = {}\n",
    "        else:\n",
    "            nonans = 0\n",
    "            getnans[\"SP\"] = disabled_span_list\n",
    "            nanmapdict = dict(zip(getnans.Team, getnans.SP))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        dkdata[\"SP\"] = np.where(dkdata[\"SP\"].isna(), dkdata[\"BatterTeam\"].map(nanmapdict), dkdata[\"SP\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(1, len(dkdata) - 1):\n",
    "        if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i-1, 'BatterTeam']:\n",
    "            if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i+1, 'BatterTeam']:\n",
    "                dkdata.loc[i, 'BatterTeam'] = np.nan\n",
    "                dkdata.loc[i, 'HomeTeam'] = np.nan\n",
    "                dkdata.loc[i, 'RoadTeam'] = np.nan\n",
    "                dkdata.loc[i, 'SP'] = np.nan\n",
    "\n",
    "    \n",
    "    dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n",
    "    dkdata = dkdata.drop_duplicates(subset = [\"BatterTeam\", \"SP\"], keep = \"first\")\n",
    "    dkdata = dkdata.drop(columns = [\"Time\", \"Sal\", \"Ownership\"])\n",
    "\n",
    "    dkdata['BatterTeam'] = dkdata['BatterTeam'].replace('ARI', 'AZ')\n",
    "    dkdata['RoadTeam'] = dkdata['RoadTeam'].replace('ARI', 'AZ')\n",
    "    dkdata['HomeTeam'] = dkdata['HomeTeam'].replace('ARI', 'AZ')\n",
    "\n",
    "    dkdata['Date'] = pd.to_datetime(dkdata['Date'])\n",
    "    dkdata['Date'] = dkdata['Date'].dt.strftime('%Y-%m-%d')\n",
    "    dkdata = dkdata.set_index(\"Date\")\n",
    "    dkdata = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\", \"SP\"]]\n",
    "\n",
    "    return(dkdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads regular season data from 2022-23 to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statcast(start_dt = \"2022-04-07\", end_dt = \"2022-10-05\")\n",
    "#statcast(start_dt = \"2023-03-30\", end_dt = \"2023-10-01\")\n",
    "savant2022 = pd.read_csv(\"~/Desktop/Random-Projects/MLB/savant2022.csv\")\n",
    "savant2023 = pd.read_csv(\"~/Desktop/Random-Projects/MLB/savant2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "combined1 = pd.concat([savant2022, savant2023])\n",
    "combined1['game_date'] = pd.to_datetime(combined1['game_date'])\n",
    "combined1['game_date'] = pd.to_datetime(combined1['game_date'].dt.strftime('%Y-%m-%d'))\n",
    "combined1['BatterTeam'] = np.where(combined1['inning_topbot'] == 'Top', combined1['away_team'], combined1['home_team'])\n",
    "combined1['PitcherTeam'] = np.where(combined1['inning_topbot'] == 'Top', combined1['home_team'], combined1['away_team'])\n",
    "combined1['AwayRunsScored'] = combined1['post_away_score'] - combined1['away_score']\n",
    "combined1['HomeRunsScored'] = combined1['post_home_score'] - combined1['home_score']\n",
    "combined1[\"player_name\"] = combined1[\"player_name\"].apply(flip_names)\n",
    "combined1[\"player_name\"] = combined1[\"player_name\"].apply(replace_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DF where it only loads in the stats of starting pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_10987/1591267697.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_starters_only = combined2.groupby(groupby_cols).apply(keep_starter).reset_index(drop = True)\n"
     ]
    }
   ],
   "source": [
    "# Group by game and team identifiers\n",
    "groupby_cols = ['game_date', 'BatterTeam', 'away_team', 'home_team']\n",
    "\n",
    "# Function to keep only the starter's data\n",
    "def keep_starter(group):\n",
    "    starter_name = group['player_name'].iloc[0]\n",
    "    return group[group['player_name'] == starter_name]\n",
    "\n",
    "def count_outs(x):\n",
    "    single_outs = ['other_out', 'strikeout', 'field_out', \"force_out\", 'fielders_choice', 'fielders_choice_out', \"sac_fly\", \"sac_bunt\", \"caught_stealing_2b\", \"caught_stealing_3b\", \"caught_stealing_home\", \"pickoff_caught_stealing_2b\",  \"pickoff_caught_stealing_3b\",  \"pickoff_caught_stealing_home\"]\n",
    "    double_outs = ['double_play', 'strikeout_double_play', 'grounded_into_double_play', \"sac_fly_double_play\"]\n",
    "    triple_outs = ['triple_play']\n",
    "    \n",
    "    outs = (x.isin(single_outs)).sum() + 2 * (x.isin(double_outs)).sum() + 3 * (x.isin(triple_outs)).sum()\n",
    "    return outs\n",
    "\n",
    "# Apply the function to each group\n",
    "combined2 = combined1[[\"game_date\", \"home_team\", \"away_team\", \"inning\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\", \"BatterTeam\", \"MLBNAME\", \"events\", \"description\", \"bb_type\", \"estimated_ba_using_speedangle\", \"estimated_woba_using_speedangle\", \"woba_value\", \"p_throws\", \"PitcherTeam\", \"player_name\", \"delta_run_exp\", \"AwayRunsScored\", \"HomeRunsScored\"]].sort_values(by = [\"game_date\", \"home_team\", \"away_team\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\"], ascending=[True, True, True, False, True, True])\n",
    "df_starters_only = combined2.groupby(groupby_cols).apply(keep_starter).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on a pitch level for pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train1 = df_starters_only.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on an at bat level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train2 = Train1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"Pitches\", \"sum\"),\n",
    "    AB = (\"at_bat_number\", \"size\"),\n",
    "    PA = (\"PA\", \"sum\"),\n",
    "    Outs = (\"Outs\", \"sum\"),\n",
    "    FB = (\"FB\", \"sum\"),\n",
    "    HR = (\"HR\", \"sum\"),\n",
    "    HBP = (\"HBP\", \"sum\"),\n",
    "    Balls = (\"Balls\", \"sum\"),\n",
    "    BB = (\"BB\", \"sum\"),\n",
    "    CS = (\"CS\", \"sum\"),\n",
    "    Whiff = (\"Whiff\", \"sum\"),\n",
    "    Strikes = (\"Strikes\", \"sum\"),\n",
    "    K = (\"K\", \"sum\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "Train2['RA'] = np.where((Train2['HomeRunsScored'] > 0) & (Train2['BatterTeam'] == Train2['home_team']), Train2[\"HomeRunsScored\"],\n",
    "                        np.where((Train2['AwayRunsScored'] > 0) & (Train2['BatterTeam'] == Train2['away_team']), Train2[\"AwayRunsScored\"], 0))\n",
    "Train2[\"RA/9\"] = (27 * Train2[\"RA\"] / Train2[\"Outs\"])\n",
    "Train2 = Train2.drop(columns = [\"AwayRunsScored\", \"HomeRunsScored\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating loads of pitcher rate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgHR = len(combined1[combined1[\"events\"] == \"home_run\"])\n",
    "lgFB = len(combined1[combined1[\"bb_type\"] == \"fly_ball\"])\n",
    "\n",
    "Train2['FIP'] = (13 * Train2['HR'] + 3 * (Train2['BB'] + Train2['HBP']) - 2 * Train2['K']) / (Train2['Outs'] / 3) + 3.137\n",
    "Train2['xFIP'] = (13 * (Train2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (Train2['BB'] + Train2['HBP']) - 2 * Train2['K']) / (Train2['Outs'] / 3) + 3.137\n",
    "\n",
    "Train2['K%'] = round((Train2['K'] / Train2['AB']) * 100, 2)\n",
    "Train2['BB%'] = round((Train2['BB'] / Train2['AB']) * 100, 2)\n",
    "Train2['K-BB%'] = Train2[\"K%\"] - Train2[\"BB%\"]\n",
    "Train2['Ball%'] = round((Train2['Balls'] / Train2['Pitches']) * 100, 2)\n",
    "Train2['Strike%'] = round((Train2['Strikes'] / Train2['Pitches']) * 100, 2)\n",
    "Train2['CS%'] = round((Train2['CS'] / Train2['Pitches']) * 100, 2)\n",
    "Train2['Whiff%'] = round((Train2['Whiff'] / Train2['Pitches']) * 100, 2)\n",
    "Train2[\"CSW\"] = Train2[\"CS\"] + Train2[\"Whiff\"]\n",
    "Train2['CSW%'] = round((Train2['CSW'] / Train2['Pitches']) * 100, 2)\n",
    "Train2 = Train2.drop(columns = [\"game_date\", \"CSW\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding rolling averages for the past 5 and 10 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size5 = 5\n",
    "window_size10 = 10\n",
    "window_size20 = 20\n",
    "\n",
    "# Rolling 5 game pitch averages\n",
    "Train2['Pitches5'] = Train2.groupby('player_name')['Pitches'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2 = Train2.drop(Train2[Train2['Pitches5'] < 40].index)\n",
    "# Rolling 5 and 10 game outs averages\n",
    "Train2['Outs5'] = Train2.groupby('player_name')['Outs'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['Outs10'] = Train2.groupby('player_name')['Outs'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected batting averages\n",
    "Train2['xBA5'] = Train2.groupby('player_name')['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['xBA10'] = Train2.groupby('player_name')['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Train2['xwOBA5'] = Train2.groupby('player_name')['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['xwOBA10'] = Train2.groupby('player_name')['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Train2['wOBA5'] = Train2.groupby('player_name')['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['wOBA10'] = Train2.groupby('player_name')['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Train2['RA5'] = Train2.groupby('player_name')['RA/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['RA10'] = Train2.groupby('player_name')['RA/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Train2['FIP5'] = Train2.groupby('player_name')['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['FIP10'] = Train2.groupby('player_name')['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Train2['xFIP5'] = Train2.groupby('player_name')['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['xFIP10'] = Train2.groupby('player_name')['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Train2['K%5'] = Train2.groupby('player_name')['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['K%10'] = Train2.groupby('player_name')['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Train2['BB%5'] = Train2.groupby('player_name')['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['BB%10'] = Train2.groupby('player_name')['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Train2['K-BB%5'] = Train2.groupby('player_name')['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['K-BB%10'] = Train2.groupby('player_name')['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Train2['Ball%5'] = Train2.groupby('player_name')['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Train2['Strike%5'] = Train2.groupby('player_name')['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Train2['CS%5'] = Train2.groupby('player_name')['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['CS%10'] = Train2.groupby('player_name')['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Train2['Whiff%5'] = Train2.groupby('player_name')['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['Whiff%10'] = Train2.groupby('player_name')['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Train2['CSW%5'] = Train2.groupby('player_name')['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Train2['CSW%10'] = Train2.groupby('player_name')['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "Train3 = Train2.drop(columns = [\"FB\", \"Balls\", \"HBP\", \"CS\", \"Whiff\", \"Strikes\", 'Ball%', 'Strike%', 'CS%', 'Whiff%', 'CSW%', \"RA/9\"])\n",
    "Train3 = Train3.rename(columns={'away_team': 'RoadTeam', 'home_team': 'HomeTeam', \"player_name\": \"SP\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on a pitch level for pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatterTrain1 = combined2.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on an at bat level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatterTrain2 = BatterTrain1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"Pitches\", \"sum\"),\n",
    "    AB = (\"at_bat_number\", \"size\"),\n",
    "    PA = (\"PA\", \"sum\"),\n",
    "    Outs = (\"Outs\", \"sum\"),\n",
    "    FB = (\"FB\", \"sum\"),\n",
    "    HR = (\"HR\", \"sum\"),\n",
    "    HBP = (\"HBP\", \"sum\"),\n",
    "    Balls = (\"Balls\", \"sum\"),\n",
    "    BB = (\"BB\", \"sum\"),\n",
    "    CS = (\"CS\", \"sum\"),\n",
    "    Whiff = (\"Whiff\", \"sum\"),\n",
    "    Strikes = (\"Strikes\", \"sum\"),\n",
    "    K = (\"K\", \"sum\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "BatterTrain2['RA'] = np.where((BatterTrain2['HomeRunsScored'] > 0) & (BatterTrain2['BatterTeam'] == BatterTrain2['home_team']), BatterTrain2[\"HomeRunsScored\"],\n",
    "                        np.where((BatterTrain2['AwayRunsScored'] > 0) & (BatterTrain2['BatterTeam'] == BatterTrain2['away_team']), BatterTrain2[\"AwayRunsScored\"], 0))\n",
    "BatterTrain2[\"R/9\"] = (27 * BatterTrain2[\"RA\"] / BatterTrain2[\"Outs\"])\n",
    "BatterTrain2 = BatterTrain2.drop(columns = [\"AwayRunsScored\", \"HomeRunsScored\", \"RA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatterTrain2['FIP'] = (13 * BatterTrain2['HR'] + 3 * (BatterTrain2['BB'] + BatterTrain2['HBP']) - 2 * BatterTrain2['K']) / (BatterTrain2['Outs'] / 3) + 3.137\n",
    "BatterTrain2['xFIP'] = (13 * (BatterTrain2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (BatterTrain2['BB'] + BatterTrain2['HBP']) - 2 * BatterTrain2['K']) / (BatterTrain2['Outs'] / 3) + 3.137\n",
    "\n",
    "BatterTrain2['K%'] = round((BatterTrain2['K'] / BatterTrain2['AB']) * 100, 2)\n",
    "BatterTrain2['BB%'] = round((BatterTrain2['BB'] / BatterTrain2['AB']) * 100, 2)\n",
    "BatterTrain2['K-BB%'] = BatterTrain2[\"K%\"] - BatterTrain2[\"BB%\"]\n",
    "BatterTrain2['Ball%'] = round((BatterTrain2['Balls'] / BatterTrain2['Pitches']) * 100, 2)\n",
    "BatterTrain2['Strike%'] = round((BatterTrain2['Strikes'] / BatterTrain2['Pitches']) * 100, 2)\n",
    "BatterTrain2['CS%'] = round((BatterTrain2['CS'] / BatterTrain2['Pitches']) * 100, 2)\n",
    "BatterTrain2['Whiff%'] = round((BatterTrain2['Whiff'] / BatterTrain2['Pitches']) * 100, 2)\n",
    "BatterTrain2[\"CSW\"] = BatterTrain2[\"CS\"] + BatterTrain2[\"Whiff\"]\n",
    "BatterTrain2['CSW%'] = round((BatterTrain2['CSW'] / BatterTrain2['Pitches']) * 100, 2)\n",
    "BatterTrain2 = BatterTrain2.drop(columns = [\"CSW\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling 5 and 10 game expected batting averages\n",
    "Train3['bxBA5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bxBA10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Train3['bxwOBA5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bxwOBA10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Train3['bwOBA5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bwOBA10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Train3['bRS5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bRS10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Train3['bFIP5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bFIP10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Train3['bxFIP5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bxFIP10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Train3['bK%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bK%10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Train3['bBB%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bBB%10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Train3['bK-BB%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bK-BB%10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Train3['bBall%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Train3['bStrike%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Train3['bCS%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bCS%10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Train3['bWhiff%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bWhiff%10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Train3['bCSW%5'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Train3['bCSW%10'] = BatterTrain2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "\n",
    "Train3 = Train3.replace([float('inf'), -float('inf')], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads in today's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_10987/367461806.py:101: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_10987/367461806.py:180: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatterTeam</th>\n",
       "      <th>RoadTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>SD</td>\n",
       "      <td>SD</td>\n",
       "      <td>WSH</td>\n",
       "      <td>Patrick Corbin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>WSH</td>\n",
       "      <td>SD</td>\n",
       "      <td>WSH</td>\n",
       "      <td>Dylan Cease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>BAL</td>\n",
       "      <td>BAL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Roddery Munoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>MIA</td>\n",
       "      <td>BAL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Corbin Burnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Gavin Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>CLE</td>\n",
       "      <td>DET</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Tyler Holton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>CWS</td>\n",
       "      <td>CWS</td>\n",
       "      <td>TEX</td>\n",
       "      <td>Max Scherzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>TEX</td>\n",
       "      <td>CWS</td>\n",
       "      <td>TEX</td>\n",
       "      <td>Jonathan Cannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>TOR</td>\n",
       "      <td>Chris Bassitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>TOR</td>\n",
       "      <td>TB</td>\n",
       "      <td>TOR</td>\n",
       "      <td>Taj Bradley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>SF</td>\n",
       "      <td>SF</td>\n",
       "      <td>LAD</td>\n",
       "      <td>Clayton Kershaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>LAD</td>\n",
       "      <td>SF</td>\n",
       "      <td>LAD</td>\n",
       "      <td>Logan Webb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NYM</td>\n",
       "      <td>Luis Severino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>NYM</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NYM</td>\n",
       "      <td>Chris Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>OAK</td>\n",
       "      <td>OAK</td>\n",
       "      <td>LAA</td>\n",
       "      <td>Kenny Rosenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-25</th>\n",
       "      <td>LAA</td>\n",
       "      <td>OAK</td>\n",
       "      <td>LAA</td>\n",
       "      <td>Ross Stripling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BatterTeam RoadTeam HomeTeam               SP\n",
       "Date                                                    \n",
       "2024-07-25         SD       SD      WSH   Patrick Corbin\n",
       "2024-07-25        WSH       SD      WSH      Dylan Cease\n",
       "2024-07-25        BAL      BAL      MIA    Roddery Munoz\n",
       "2024-07-25        MIA      BAL      MIA    Corbin Burnes\n",
       "2024-07-25        DET      DET      CLE   Gavin Williams\n",
       "2024-07-25        CLE      DET      CLE     Tyler Holton\n",
       "2024-07-25        CWS      CWS      TEX     Max Scherzer\n",
       "2024-07-25        TEX      CWS      TEX  Jonathan Cannon\n",
       "2024-07-25         TB       TB      TOR    Chris Bassitt\n",
       "2024-07-25        TOR       TB      TOR      Taj Bradley\n",
       "2024-07-25         SF       SF      LAD  Clayton Kershaw\n",
       "2024-07-25        LAD       SF      LAD       Logan Webb\n",
       "2024-07-25        ATL      ATL      NYM    Luis Severino\n",
       "2024-07-25        NYM      ATL      NYM       Chris Sale\n",
       "2024-07-25        OAK      OAK      LAA  Kenny Rosenberg\n",
       "2024-07-25        LAA      OAK      LAA   Ross Stripling"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TodaysData = getDKData2024()\n",
    "TodaysData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:06<00:00,  1.81it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n",
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_10987/3996349122.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  savant2024 = savant2024.groupby(groupby_cols).apply(keep_starter).reset_index(drop = True)\n"
     ]
    }
   ],
   "source": [
    "eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
    "savant2024 = statcast(start_dt = \"2024-03-28\", end_dt = eastern_time.strftime(\"%Y-%m-%d\"))\n",
    "savant2024['game_date'] = pd.to_datetime(savant2024['game_date'])\n",
    "savant2024['game_date'] = savant2024['game_date'].dt.strftime('%Y-%m-%d')\n",
    "savant2024['BatterTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['away_team'], savant2024['home_team'])\n",
    "savant2024['PitcherTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['home_team'], savant2024['away_team'])\n",
    "savant2024 = pd.merge(savant2024, ID[[\"MLBID\", \"MLBNAME\"]], left_on = 'batter', right_on = 'MLBID', how = 'left')\n",
    "savant2024.dropna(subset=['MLBNAME'], inplace=True)\n",
    "savant2024 = savant2024.drop_duplicates(subset = [\"pitch_type\", \"game_date\", \"release_speed\", \"release_pos_x\", \"release_pos_z\", \"player_name\"], keep='first')\n",
    "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(flip_names)\n",
    "savant2024['AwayRunsScored'] = savant2024['post_away_score'] - savant2024['away_score']\n",
    "savant2024['HomeRunsScored'] = savant2024['post_home_score'] - savant2024['home_score']\n",
    "savant2024 = savant2024[[\"game_date\", \"home_team\", \"away_team\", \"inning\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\", \"pitch_type\", \"BatterTeam\", \"MLBNAME\", \"balls\", \"strikes\", \"outs_when_up\", \"events\", \"description\", \"bb_type\", \"hit_distance_sc\", \"launch_speed\", \"launch_angle\", \"estimated_ba_using_speedangle\", \"estimated_woba_using_speedangle\", \"woba_value\", \"p_throws\", \"PitcherTeam\", \"player_name\", \"delta_home_win_exp\", \"delta_run_exp\", \"away_score\", \"home_score\", \"AwayRunsScored\", \"HomeRunsScored\"]].sort_values(by = [\"game_date\", \"home_team\", \"away_team\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\"], ascending=[True, True, True, False, True, True])\n",
    "savant2024 = savant2024.groupby(groupby_cols).apply(keep_starter).reset_index(drop = True)\n",
    "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(replace_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the same grouping as the training data at the various levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season1 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season2 = Season1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"Pitches\", \"sum\"),\n",
    "    AB = (\"at_bat_number\", \"size\"),\n",
    "    PA = (\"PA\", \"sum\"),\n",
    "    Outs = (\"Outs\", \"sum\"),\n",
    "    FB = (\"FB\", \"sum\"),\n",
    "    HR = (\"HR\", \"sum\"),\n",
    "    HBP = (\"HBP\", \"sum\"),\n",
    "    Balls = (\"Balls\", \"sum\"),\n",
    "    BB = (\"BB\", \"sum\"),\n",
    "    CS = (\"CS\", \"sum\"),\n",
    "    Whiff = (\"Whiff\", \"sum\"),\n",
    "    Strikes = (\"Strikes\", \"sum\"),\n",
    "    K = (\"K\", \"sum\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "Season2[\"IP\"] = Season2[\"Outs\"] / 3\n",
    "Season2['RA'] = np.where((Season2['HomeRunsScored'] > 0) & (Season2['BatterTeam'] == Season2['home_team']), Season2[\"HomeRunsScored\"],\n",
    "                        np.where((Season2['AwayRunsScored'] > 0) & (Season2['BatterTeam'] == Season2['away_team']),Season2[\"AwayRunsScored\"], 0))\n",
    "Season2[\"RA/9\"] = (27 * Season2[\"RA\"] / Season2[\"Outs\"])\n",
    "Season2 = Season2.drop(columns = [\"AwayRunsScored\", \"HomeRunsScored\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season2['FIP'] = (13 * Season2['HR'] + 3 * (Season2['BB'] + Season2['HBP']) - 2 * Season2['K']) / (Season2['IP']) + 3.137\n",
    "Season2['xFIP'] = (13 * (Season2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (Season2['BB'] + Season2['HBP']) - 2 * Season2['K']) / (Season2['IP']) + 3.137\n",
    "\n",
    "Season2['K%'] = round((Season2['K'] / Season2['AB']) * 100, 2)\n",
    "Season2['BB%'] = round((Season2['BB'] / Season2['AB']) * 100, 2)\n",
    "Season2['K-BB%'] = Season2[\"K%\"] - Season2[\"BB%\"]\n",
    "Season2['Ball%'] = round((Season2['Balls'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['Strike%'] = round((Season2['Strikes'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['CS%'] = round((Season2['CS'] / Season2['Pitches']) * 100, 2)\n",
    "Season2['Whiff%'] = round((Season2['Whiff'] / Season2['Pitches']) * 100, 2)\n",
    "Season2[\"CSW\"] = Season2[\"CS\"] + Season2[\"Whiff\"]\n",
    "Season2['CSW%'] = round((Season2['CSW'] / Season2['Pitches']) * 100, 2)\n",
    "Season2 = Season2.drop(columns=[\"CSW\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling 5 game pitch averages\n",
    "Season2['Pitches5'] = Season2.groupby('player_name')['Pitches'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2 = Season2.drop(Season2[Season2['Pitches5'] < 40].index)\n",
    "# Rolling 5 and 10 game outs averages\n",
    "Season2['Outs5'] = Season2.groupby('player_name')['Outs'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['Outs10'] = Season2.groupby('player_name')['Outs'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected batting averages\n",
    "Season2['xBA5'] = Season2.groupby('player_name')['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xBA10'] = Season2.groupby('player_name')['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Season2['xwOBA5'] = Season2.groupby('player_name')['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xwOBA10'] = Season2.groupby('player_name')['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Season2['wOBA5'] = Season2.groupby('player_name')['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['wOBA10'] = Season2.groupby('player_name')['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Season2['RA5'] = Season2.groupby('player_name')['RA/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['RA10'] = Season2.groupby('player_name')['RA/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Season2['FIP5'] = Season2.groupby('player_name')['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['FIP10'] = Season2.groupby('player_name')['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Season2['xFIP5'] = Season2.groupby('player_name')['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['xFIP10'] = Season2.groupby('player_name')['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Season2['K%5'] = Season2.groupby('player_name')['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['K%10'] = Season2.groupby('player_name')['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Season2['BB%5'] = Season2.groupby('player_name')['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['BB%10'] = Season2.groupby('player_name')['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Season2['K-BB%5'] = Season2.groupby('player_name')['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['K-BB%10'] = Season2.groupby('player_name')['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Season2['Ball%5'] = Season2.groupby('player_name')['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Season2['Strike%5'] = Season2.groupby('player_name')['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Season2['CS%5'] = Season2.groupby('player_name')['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['CS%10'] = Season2.groupby('player_name')['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Season2['Whiff%5'] = Season2.groupby('player_name')['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['Whiff%10'] = Season2.groupby('player_name')['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Season2['CSW%5'] = Season2.groupby('player_name')['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "Season2['CSW%10'] = Season2.groupby('player_name')['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "Season3 = Season2.drop(columns = [\"FB\", \"Balls\", \"HBP\", \"CS\", \"Whiff\", \"Strikes\", 'Ball%', 'Strike%', 'CS%', 'Whiff%', 'CSW%', \"RA/9\"])\n",
    "Season3 = Season3.rename(columns={'away_team': 'RoadTeam', 'home_team': 'HomeTeam', \"player_name\": \"SP\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping everything to get season and rolling averages for pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season4 = Season3.groupby([\"SP\", \"p_throws\"]).agg(\n",
    "    Starts = (\"IP\", \"size\"),\n",
    "    Pitches = (\"Pitches\", \"mean\"),\n",
    "    AB = (\"AB\", \"mean\"),\n",
    "    PA = (\"PA\", \"mean\"),\n",
    "    Outs = (\"Outs\", \"mean\"),\n",
    "    HR = (\"HR\", \"mean\"),\n",
    "    BB = (\"BB\", \"mean\"),\n",
    "    K = (\"K\", \"mean\"),\n",
    "    RA = (\"RA\", \"mean\"),\n",
    "    xBA = (\"xBA\", \"mean\"),\n",
    "    xwOBA = (\"xwOBA\", \"mean\"),\n",
    "    wOBA = (\"wOBA\", \"mean\"),\n",
    "    RunExp = (\"RunExp\", \"mean\"),\n",
    "    FIP = (\"FIP\", \"mean\"),\n",
    "    xFIP = (\"xFIP\", \"mean\"),\n",
    "    Kpercent = (\"K%\", \"mean\"),\n",
    "    BBpercent = (\"BB%\", \"mean\"),\n",
    "    KminusBBpercent = (\"K-BB%\", \"mean\"),\n",
    "    Pitches5 =  (\"Pitches5\", \"last\"),\n",
    "    Outs5 =  (\"Outs5\", \"last\"),\n",
    "    Outs10 = (\"Outs10\", \"last\"),\n",
    "    xBA5 =  (\"xBA5\", \"last\"),\n",
    "    xBA10 = (\"xBA10\", \"last\"),\n",
    "    xwOBA5 =  (\"xwOBA5\", \"last\"),\n",
    "    xwOBA10 = (\"xwOBA10\", \"last\"),\n",
    "    wOBA5 =  (\"wOBA5\", \"last\"),\n",
    "    wOBA10 = (\"wOBA10\", \"last\"),\n",
    "    RA5 = (\"RA5\", \"last\"),\n",
    "    RA10 = (\"RA10\", \"last\"),\n",
    "    FIP5 = (\"FIP5\", \"last\"),\n",
    "    FIP10 = (\"FIP10\", \"last\"),\n",
    "    xFIP5 = (\"xFIP5\", \"last\"),\n",
    "    xFIP10 = (\"xFIP10\", \"last\"),\n",
    "    Kpercent5 = (\"K%5\", \"last\"),\n",
    "    Kpercent10 = (\"K%10\", \"last\"),\n",
    "    BBpercent5 = (\"BB%5\", \"last\"),\n",
    "    BBpercent10 = (\"BB%10\", \"last\"),\n",
    "    KminusBBpercent5 = (\"K-BB%5\", \"last\"),\n",
    "    KminusBBpercent10 = (\"K-BB%10\", \"last\"),\n",
    "    Ballpercent5 = (\"Ball%5\", \"last\"),\n",
    "    Strikepercent5 = (\"Strike%5\", \"last\"),\n",
    "    CSpercent5 = (\"CS%5\", \"last\"),\n",
    "    CSpercent10 = (\"CS%10\", \"last\"),\n",
    "    Whiffpercent5 = (\"Whiff%5\", \"last\"),\n",
    "    Whiffpercent10 = (\"Whiff%10\", \"last\"),\n",
    "    CSWpercent5 = (\"CSW%5\", \"last\"),\n",
    "    CSWpercent10 = (\"CSW%10\", \"last\")).reset_index().fillna(0)\n",
    "\n",
    "Season4.rename(columns={col: col.replace('percent', '%') for col in Season4.columns if 'percent' in col}, inplace=True)\n",
    "Season4.rename(columns={col: col.replace('minus', '-') for col in Season4.columns if 'minus' in col}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatterSeason1 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"inning\", \"at_bat_number\", \"MLBNAME\", \"player_name\", \"p_throws\"]).agg(\n",
    "    Pitches = (\"pitch_number\", \"size\"),\n",
    "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
    "    Outs = ('events', count_outs),\n",
    "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
    "    HR = ('events', lambda x: (x == 'home_run').sum()),\n",
    "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
    "    Balls = ('description', lambda x: (x.isin([\"ball\", \"hit_by_pitch\", \"blocked_ball\"])).sum()),\n",
    "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
    "    CS = ('description', lambda x: (x == 'called_strike').sum()),\n",
    "    Whiff = ('description', lambda x: (x.isin([\"swinging_strike\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    Strikes = ('description', lambda x: (x.isin([\"called_strike\", \"swinging_strike\", \"foul\", \"swinging_strike_blocked\", \"foul_tip\"])).sum()),\n",
    "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
    "    xBA = (\"estimated_ba_using_speedangle\", \"mean\"),\n",
    "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
    "    wOBA = (\"woba_value\", \"mean\"),\n",
    "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
    "    AwayRunsScored = (\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored = (\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatterSeason2 = BatterSeason1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"p_throws\"]).agg(\n",
    "    Pitches=(\"Pitches\", \"sum\"),\n",
    "    AB=(\"at_bat_number\", \"size\"),\n",
    "    PA=(\"PA\", \"sum\"),\n",
    "    Outs=(\"Outs\", \"sum\"),\n",
    "    FB=(\"FB\", \"sum\"),\n",
    "    HR=(\"HR\", \"sum\"),\n",
    "    HBP=(\"HBP\", \"sum\"),\n",
    "    Balls=(\"Balls\", \"sum\"),\n",
    "    BB=(\"BB\", \"sum\"),\n",
    "    CS=(\"CS\", \"sum\"),\n",
    "    Whiff=(\"Whiff\", \"sum\"),\n",
    "    Strikes=(\"Strikes\", \"sum\"),\n",
    "    K=(\"K\", \"sum\"),\n",
    "    xBA=(\"xBA\", \"mean\"),\n",
    "    xwOBA=(\"xwOBA\", \"mean\"),\n",
    "    wOBA=(\"wOBA\", \"mean\"),\n",
    "    RunExp=(\"RunExp\", \"mean\"),\n",
    "    AwayRunsScored=(\"AwayRunsScored\", \"sum\"),\n",
    "    HomeRunsScored=(\"HomeRunsScored\", \"sum\")).reset_index().fillna(0)\n",
    "\n",
    "BatterSeason2['RA'] = np.where((BatterSeason2['HomeRunsScored'] > 0) & (BatterSeason2['BatterTeam'] == BatterSeason2['home_team']),\n",
    "    BatterSeason2[\"HomeRunsScored\"], np.where((BatterSeason2['AwayRunsScored'] > 0) & (BatterSeason2['BatterTeam'] == BatterSeason2['away_team']), BatterSeason2[\"AwayRunsScored\"], 0))\n",
    "BatterSeason2[\"R/9\"] = (27 * BatterSeason2[\"RA\"] / BatterSeason2[\"Outs\"])\n",
    "BatterSeason2 = BatterSeason2.drop(columns=[\"AwayRunsScored\", \"HomeRunsScored\", \"RA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatterSeason2['FIP'] = (13 * BatterSeason2['HR'] + 3 * (BatterSeason2['BB'] + BatterSeason2['HBP']) - 2 * BatterSeason2['K']) / (BatterSeason2['Outs'] / 3) + 3.137\n",
    "BatterSeason2['xFIP'] = (13 * (BatterSeason2['FB'] * (lgHR/lgFB * 0.58)) + 3 * (BatterSeason2['BB'] + BatterSeason2['HBP']) - 2 * BatterSeason2['K']) / (BatterSeason2['Outs'] / 3) + 3.137\n",
    "\n",
    "BatterSeason2['K%'] = round((BatterSeason2['K'] / BatterSeason2['AB']) * 100, 2)\n",
    "BatterSeason2['BB%'] = round((BatterSeason2['BB'] / BatterSeason2['AB']) * 100, 2)\n",
    "BatterSeason2['K-BB%'] = BatterSeason2[\"K%\"] - BatterSeason2[\"BB%\"]\n",
    "BatterSeason2['Ball%'] = round((BatterSeason2['Balls'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['Strike%'] = round((BatterSeason2['Strikes'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['CS%'] = round((BatterSeason2['CS'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2['Whiff%'] = round((BatterSeason2['Whiff'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2[\"CSW\"] = BatterSeason2[\"CS\"] + BatterSeason2[\"Whiff\"]\n",
    "BatterSeason2['CSW%'] = round((BatterSeason2['CSW'] / BatterSeason2['Pitches']) * 100, 2)\n",
    "BatterSeason2 = BatterSeason2.drop(columns = [\"CSW\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling 5 and 10 game expected batting averages\n",
    "Season4['bxBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game expected wOBA averages\n",
    "Season4['bxwOBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxwOBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game wOBA averages\n",
    "Season4['bwOBA5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bwOBA10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['wOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game RA averages\n",
    "Season4['bRS5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bRS10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['R/9'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game FIP averages\n",
    "Season4['bFIP5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bFIP10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['FIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game xFIP averages\n",
    "Season4['bxFIP5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bxFIP10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['xFIP'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K% averages\n",
    "Season4['bK%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bK%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game BB% averages\n",
    "Season4['bBB%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bBB%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game K-BB% averages\n",
    "Season4['bK-BB%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bK-BB%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['K-BB%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Ball% averages\n",
    "Season4['bBall%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Ball%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 game Strike% averages\n",
    "Season4['bStrike%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Strike%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike% averages\n",
    "Season4['bCS%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bCS%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CS%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Whiff% averages\n",
    "Season4['bWhiff%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bWhiff%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['Whiff%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "# Rolling 5 and 10 game Called Strike plus Whiff% averages\n",
    "Season4['bCSW%5'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "Season4['bCSW%10'] = BatterSeason2.groupby(['BatterTeam', \"p_throws\"])['CSW%'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining both the pitcher averages and the batter rolling averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TodaysData.dropna(subset=['SP'], inplace=True)\n",
    "TodaysData1 = pd.merge(TodaysData, Season4[['SP', 'p_throws', 'Starts', 'Pitches', 'AB', 'PA', 'Outs', 'HR', 'BB',\n",
    "       'K', 'RA', 'xBA', 'xwOBA', 'wOBA', 'RunExp', 'FIP', 'xFIP', 'K%', 'BB%',\n",
    "       'K-BB%', 'Pitches5', 'Outs5', 'Outs10', 'xBA5', 'xBA10', 'xwOBA5',\n",
    "       'xwOBA10', 'wOBA5', 'wOBA10', 'RA5', 'RA10', 'FIP5', 'FIP10', 'xFIP5',\n",
    "       'xFIP10', 'K%5', 'K%10', 'BB%5', 'BB%10', 'K-BB%5', 'K-BB%10', 'Ball%5',\n",
    "       'Strike%5', 'CS%5', 'CS%10', 'Whiff%5', 'Whiff%10', 'CSW%5', 'CSW%10',\n",
    "       'bxBA5', 'bxBA10', 'bxwOBA5', 'bxwOBA10', 'bwOBA5', 'bwOBA10', 'bRS5',\n",
    "       'bRS10', 'bFIP5', 'bFIP10', 'bxFIP5', 'bxFIP10', 'bK%5', 'bK%10',\n",
    "       'bBB%5', 'bBB%10', 'bK-BB%5', 'bK-BB%10', 'bBall%5', 'bStrike%5',\n",
    "       'bCS%5', 'bCS%10', 'bWhiff%5', 'bWhiff%10', 'bCSW%5', 'bCSW%10']], left_on = ['SP'], right_on = ['SP'], how = 'left')\n",
    "\n",
    "# If no 2024 savant data exists then gives them the league averages from 2022-23\n",
    "TrainMeans = Train3.drop(['BatterTeam', 'RoadTeam', \"HomeTeam\", \"SP\", \"p_throws\"], axis=1).mean()\n",
    "TodaysData1 = TodaysData1.fillna(TrainMeans)\n",
    "TodaysData1 = TodaysData1.replace([float('inf'), -float('inf')], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodes the teams and players allowing to be fed into the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Train5 and TodaysData2 are copies of Train4 and TodaysData1 respectively\n",
    "Train5 = Train3.copy()\n",
    "TodaysData2 = TodaysData1.copy()\n",
    "\n",
    "# Dictionary to store the label encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode non-numeric columns in Train4\n",
    "non_numeric_columns_train = Train5.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_train:\n",
    "    label_encoder = LabelEncoder()\n",
    "    Train5[col] = label_encoder.fit_transform(Train5[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "# Ensure all non-numeric columns in Train4 are in TodaysData1\n",
    "for col in non_numeric_columns_train:\n",
    "    if col not in TodaysData2.columns:\n",
    "        print(f\"Warning: Column {col} from training data is not present in today's data.\")\n",
    "        # Adding the missing column with a default value\n",
    "        TodaysData2[col] = 536\n",
    "\n",
    "# Encode non-numeric columns in TodaysData1 using the same encoders\n",
    "non_numeric_columns_today = TodaysData2.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        unique_values = set(label_encoder.classes_)\n",
    "        encoded_values = []\n",
    "        for item in TodaysData2[col]:\n",
    "            if item in unique_values:\n",
    "                encoded_values.append(label_encoder.transform([item])[0])\n",
    "            else:\n",
    "                encoded_values.append(536)  # Using 536 as a placeholder for unknown categories\n",
    "        TodaysData2[col] = encoded_values\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} is not present in the training data.\")\n",
    "        # Fit a new label encoder for columns not present in Train4, but be cautious with this\n",
    "        label_encoder = LabelEncoder()\n",
    "        TodaysData2[col] = label_encoder.fit_transform(TodaysData2[col])\n",
    "        label_encoders[col] = label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"K\"]).values.reshape(-1, 76)\n",
    "TrainLabel = Train5[\"K\"].values.reshape(-1, 1)\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"K\"]).values.reshape(-1, 76)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 4)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xK\"] = RFpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"BB\"]).values.reshape(-1, 76)\n",
    "TrainLabel = Train5[\"BB\"].values.reshape(-1, 1)\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"BB\", \"xK\"]).values.reshape(-1, 76)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 4)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xBB\"] = RFpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"RA\"]).values.reshape(-1, 76)\n",
    "TrainLabel = Train5[\"RA\"].values.reshape(-1, 1)\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"BB\", \"xK\", \"xBB\"]).values.reshape(-1, 76)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 4)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xRA\"] = RFpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "TrainFeatures = Train5.drop(columns = [\"Outs\"]).values.reshape(-1, 76)\n",
    "TrainLabel = Train5[\"Outs\"].values.reshape(-1, 1)\n",
    "TodayFeatures = TodaysData2.drop(columns = [\"Starts\", \"Outs\", \"xK\", \"xBB\", \"xRA\"]).values.reshape(-1, 76)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 4)\n",
    "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
    "RFpred = rf_regressor.predict(TodayFeatures)\n",
    "\n",
    "TodaysData2[\"xOuts\"] = RFpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse encodes today's data so it can be understood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_10987/1190844444.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  TodaysData2[\"SP\"].fillna(TodaysData1[\"SP\"], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "for col in non_numeric_columns_today:\n",
    "    if col in label_encoders:\n",
    "        label_encoder = label_encoders[col]\n",
    "        # Handling default value of 536\n",
    "        TodaysData2[col] = TodaysData2[col].apply(lambda x: label_encoder.inverse_transform([x])[0] if x != 536 else np.nan)\n",
    "\n",
    "TodaysData2[\"SP\"].fillna(TodaysData1[\"SP\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_2_to_duplicates(df):\n",
    "    mask = df.duplicated(subset=['BatterTeam', 'RoadTeam', 'HomeTeam'], keep='first')\n",
    "    \n",
    "    df.loc[mask, 'BatterTeam'] += '2'\n",
    "    df.loc[mask, 'RoadTeam'] += '2'\n",
    "    df.loc[mask, 'HomeTeam'] += '2'\n",
    "    \n",
    "    return df\n",
    "\n",
    "TodaysData2 = add_2_to_duplicates(TodaysData2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates simple dataset to see the expected stats of all the predicted metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP</th>\n",
       "      <th>Starts</th>\n",
       "      <th>xK</th>\n",
       "      <th>xBB</th>\n",
       "      <th>xRA</th>\n",
       "      <th>xOuts</th>\n",
       "      <th>xFS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ross Stripling</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>16.10</td>\n",
       "      <td>14.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonathan Cannon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>16.05</td>\n",
       "      <td>15.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roddery Munoz</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3.43</td>\n",
       "      <td>14.57</td>\n",
       "      <td>18.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patrick Corbin</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2.78</td>\n",
       "      <td>15.54</td>\n",
       "      <td>19.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gavin Williams</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.04</td>\n",
       "      <td>13.79</td>\n",
       "      <td>19.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Max Scherzer</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>15.04</td>\n",
       "      <td>20.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Luis Severino</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>17.91</td>\n",
       "      <td>28.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.15</td>\n",
       "      <td>17.47</td>\n",
       "      <td>29.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Bassitt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.97</td>\n",
       "      <td>17.29</td>\n",
       "      <td>29.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Taj Bradley</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.78</td>\n",
       "      <td>16.81</td>\n",
       "      <td>31.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corbin Burnes</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.74</td>\n",
       "      <td>18.34</td>\n",
       "      <td>34.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dylan Cease</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>17.37</td>\n",
       "      <td>36.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chris Sale</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>17.97</td>\n",
       "      <td>39.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SP  Starts    xK   xBB   xRA  xOuts    xFS\n",
       "15   Ross Stripling    11.0  3.01  1.00  3.50  16.10  14.66\n",
       "7   Jonathan Cannon     8.0  4.00  1.00  4.14  16.05  15.63\n",
       "2     Roddery Munoz    10.0  4.67  2.59  3.43  14.57  18.30\n",
       "0    Patrick Corbin    20.0  4.00  1.01  2.78  15.54  19.29\n",
       "4    Gavin Williams     4.0  3.93  2.00  2.04  13.79  19.48\n",
       "6      Max Scherzer     6.0  4.00  1.00  2.08  15.04  20.83\n",
       "12    Luis Severino    19.0  4.98  2.00  2.06  17.91  28.94\n",
       "11       Logan Webb    21.0  5.64  1.00  2.15  17.47  29.51\n",
       "8     Chris Bassitt    20.0  5.65  2.00  1.97  17.29  29.71\n",
       "9       Taj Bradley    13.0  6.37  2.00  1.78  16.81  31.39\n",
       "3     Corbin Burnes    20.0  5.99  1.00  1.74  18.34  34.11\n",
       "1       Dylan Cease    21.0  7.70  2.00  1.90  17.37  36.25\n",
       "13       Chris Sale    18.0  8.01  1.00  1.72  17.97  39.28"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TodaysData2 = TodaysData2[TodaysData2[\"Starts\"] >= 3].dropna()\n",
    "\n",
    "# Performs a two \"sample\" z test to see the likelihood of a quality start occurring\n",
    "def row_z_score(row):\n",
    "    x_bar1 = row[\"xRA\"]\n",
    "    x_bar2 = row[\"xOuts\"]\n",
    "    mu1 = 3\n",
    "    mu2 = 18\n",
    "    sigma1 = Train2[\"RA\"].std()\n",
    "    sigma2 = Train2[\"Outs\"].std()\n",
    "    n1 = len(TodaysData2)\n",
    "    n2 = n1\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_score_xRA = (x_bar1 - mu1) / (sigma1 / np.sqrt(n1))\n",
    "    z_score_xOuts = (x_bar2 - mu2) / (sigma2 / np.sqrt(n2))\n",
    "    \n",
    "    # Calculate probabilities, want less than\n",
    "    prob_xRA_less_than_mu1 = 1 - stats.norm.cdf(z_score_xRA)\n",
    "    prob_xOuts_greater_than_mu2 = stats.norm.cdf(z_score_xOuts)\n",
    "\n",
    "    # Combine probabilities by multiplying it\n",
    "    combined_prob = prob_xRA_less_than_mu1 * prob_xOuts_greater_than_mu2\n",
    "    return combined_prob\n",
    "\n",
    "# Calculate the chance of a quality start occurring and finds the xQS points\n",
    "percent = TodaysData2.apply(row_z_score, axis=1)\n",
    "xQS = percent * 5\n",
    "\n",
    "# Adds the xQS to the xFS\n",
    "TodaysData2.loc[:, \"xFS\"] = (xQS + TodaysData2[\"xK\"] * 3 + TodaysData2[\"xOuts\"] - TodaysData2[\"xRA\"] * 3)\n",
    "TodaysData3 = TodaysData2[[\"SP\", \"Starts\", \"xK\", \"xBB\", \"xRA\", \"xOuts\", \"xFS\"]].round(2)\n",
    "TodaysData3.sort_values(\"xFS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
