{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 647,
      "metadata": {
        "id": "mSO_1a5fngNk"
      },
      "outputs": [],
      "source": [
        "import pybaseball\n",
        "from pybaseball import statcast\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from datetime import timezone\n",
        "from bs4 import BeautifulSoup\n",
        "import io\n",
        "import requests\n",
        "import unicodedata\n",
        "pybaseball.cache.enable()\n",
        "\n",
        "from RosterScraper import RosterScraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loads in StatCast ID so batter names show in the Statcast data and loads in a scraped DF with every 40 man roster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 648,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_3098/2021382589.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  PID['Name'] = PID['Name'].replace('Michael King', 'Mike King')\n"
          ]
        }
      ],
      "source": [
        "url = 'https://docs.google.com/spreadsheets/d/1JgczhD5VDQ1EiXqVG-blttZcVwbZd5_Ne_mefUGwJnk/pub?output=csv'\n",
        "res = requests.get(url)\n",
        "ID = pd.read_csv(io.BytesIO(res.content), sep=',')\n",
        "ID.dropna(subset=['MLBID'], inplace=True)\n",
        "ID['MLBID'] = ID['MLBID'].astype(int)\n",
        "\n",
        "Rosters = RosterScraper()\n",
        "BID = Rosters[Rosters[\"Position\"] == \"Batter\"]\n",
        "PID = Rosters[Rosters[\"Position\"] == \"Pitcher\"]\n",
        "PID['Name'] = PID['Name'].replace('Michael King', 'Mike King')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating functions for data manipulation so they can match when joining separate datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 649,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_name(name):\n",
        "    if name == 'Rockies':\n",
        "        return 'COL'\n",
        "    elif name == 'Reds':\n",
        "        return 'CIN'\n",
        "    elif name == 'Mariners':\n",
        "        return 'SEA'\n",
        "    elif name == 'Nationals':\n",
        "        return 'WSH'\n",
        "    elif name == 'Yankees':\n",
        "        return 'NYY'\n",
        "    elif name == 'Astros':\n",
        "        return 'HOU'\n",
        "    elif name == 'Red Sox':\n",
        "        return 'BOS'\n",
        "    elif name == 'Athletics':\n",
        "        return 'OAK'\n",
        "    elif name == 'Mets':\n",
        "        return 'NYM'\n",
        "    elif name == 'Braves':\n",
        "        return 'ATL'\n",
        "    elif name == 'Giants':\n",
        "        return 'SF'\n",
        "    elif name == 'Brewers':\n",
        "        return 'MIL'\n",
        "    elif name == 'Rays':\n",
        "        return 'TB'\n",
        "    elif name == 'Royals':\n",
        "        return 'KC'\n",
        "    elif name == 'White Sox':\n",
        "        return 'CWS'\n",
        "    elif name == 'Cubs':\n",
        "        return 'CHC'\n",
        "    elif name == 'Angels':\n",
        "        return 'LAA'\n",
        "    elif name == 'Tigers':\n",
        "        return 'DET'\n",
        "    elif name == 'Diamondbacks':\n",
        "        return 'ARI'\n",
        "    elif name == 'Guardians':\n",
        "        return 'CLE'\n",
        "    elif name == 'Orioles':\n",
        "        return 'BAL'\n",
        "    elif name == 'Twins':\n",
        "        return 'MIN'\n",
        "    elif name == 'Marlins':\n",
        "        return 'MIA'\n",
        "    elif name == 'Phillies':\n",
        "        return 'PHI'\n",
        "    elif name == 'Rangers':\n",
        "        return 'TEX'\n",
        "    elif name == 'Dodgers':\n",
        "        return 'LAD'\n",
        "    elif name == 'Padres':\n",
        "        return 'SD'\n",
        "    elif name == 'Pirates':\n",
        "        return 'PIT'\n",
        "    elif name == 'Blue Jays':\n",
        "        return 'TOR'\n",
        "    elif name == 'Cardinals':\n",
        "        return 'STL'\n",
        "    else:\n",
        "        return np.nan\n",
        "    \n",
        "def flip_names(name):\n",
        "    first_name, last_name = name.split(\", \")\n",
        "    return f\"{last_name} {first_name}\"\n",
        "\n",
        "def replace_special_chars(text):\n",
        "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scraping the RotoGrinders website for daily pitchers and lineups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 650,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDKData2024():\n",
        "    \n",
        "    eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
        "    todaysdate = eastern_time.strftime(\"%m-%d-%Y\")\n",
        "    url = 'https://rotogrinders.com/lineups/mlb?site=draftkings'\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "    gamelist = []\n",
        "    gamecards = soup.findAll(\"div\", {\"class\": \"game-card-teams\"})\n",
        "    for x in gamecards:\n",
        "        twoteams = x.findAll(\"span\", {\"class\": \"team-nameplate-mascot\"})\n",
        "        roadteam = convert_name(twoteams[0].text)\n",
        "        hometeam = convert_name(twoteams[1].text)\n",
        "        gamekey = \"{}@{}\".format(roadteam,hometeam)\n",
        "        gamelist.append(gamekey)\n",
        "\n",
        "    matchupsdf = pd.DataFrame()\n",
        "    for game in gamelist:\n",
        "        roadteam = game.split(\"@\")[0]\n",
        "        hometeam = game.split(\"@\")[1]\n",
        "        thisdf1 = pd.DataFrame({\"Team\": roadteam, \"Opp\": hometeam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
        "        thisdf2 = pd.DataFrame({\"Team\": hometeam, \"Opp\": roadteam, \"RoadTeam\": roadteam, \"HomeTeam\": hometeam},index=[0])\n",
        "        matchupsdf = pd.concat([matchupsdf,thisdf1,thisdf2])\n",
        "        \n",
        "    oppdict = dict(zip(matchupsdf.Team,matchupsdf.Opp))\n",
        "    hometeamdict = dict(zip(matchupsdf.Team,matchupsdf.HomeTeam))\n",
        "    roadteamdict = dict(zip(matchupsdf.Team,matchupsdf.RoadTeam))\n",
        "\n",
        "    disabled_span_list = []\n",
        "    for span in soup.findAll(\"span\", {\"class\": \"player-nameplate disabled\"}):\n",
        "        for a in span.findAll(\"a\"):\n",
        "            disabled_span_list.append(a.text)\n",
        "\n",
        "    spdata = pd.DataFrame()\n",
        "    for div in soup.findAll(\"span\", {\"class\": \"player-nameplate\", \"data-position\": \"SP\"}):\n",
        "        if \"TBD\" in str(div):\n",
        "            playername = \"TBD\"\n",
        "            pos = \"SP\"\n",
        "            sal = 0\n",
        "        else:\n",
        "            for a in div.findAll('a', {'class': 'player-nameplate-name'}):\n",
        "                playername = a.text.strip()\n",
        "\n",
        "            strdiv = str(div)\n",
        "            pos = strdiv[strdiv.find(\"data-position\")+15:strdiv.find(\"data-salary\")-2]\n",
        "            sal = strdiv[strdiv.find(\"data-salary\")+13:strdiv.find(\"<div class = 'player-nameplate-info'>\")-3]\n",
        "        try:\n",
        "            ownership = strdiv[strdiv.find('<span class=\"small muted\" data-auth=\"502\">') + 42:strdiv.find('%')]\n",
        "            ownership = ownership.replace(\"</span>\", \"\")\n",
        "            ownership = ownership.replace(\"</span\", \"\")\n",
        "            ownership = ownership.replace(\"</div>\", \"\")\n",
        "            ownership = ownership.replace(\" \", \"\")\n",
        "        except:\n",
        "            ownership = np.nan\n",
        "\n",
        "        thisspdata = pd.DataFrame([[playername, sal, ownership]], columns = [\"Player\", \"Salary\", \"Ownership\"])\n",
        "        spdata = pd.concat([spdata, thisspdata])\n",
        "\n",
        "    spdata2 = pd.merge(spdata, PID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"PitcherTeam\"})\n",
        "    spdata3 = pd.merge(spdata2, matchupsdf[[\"Team\", \"Opp\"]], left_on = [\"PitcherTeam\"], right_on = [\"Team\"], how = \"left\").drop(columns = [\"Team\"])\n",
        "\n",
        "    opp_spname_dict = dict(zip(spdata3.Opp, spdata3.Player))\n",
        "    opp_spsal_dict = dict(zip(spdata3.Opp, spdata.Salary))\n",
        "    opp_spown_dict = dict(zip(spdata3.Opp, spdata3.Ownership))\n",
        "\n",
        "    ludf = pd.DataFrame()\n",
        "    \n",
        "    for li in soup.findAll(\"li\", {\"class\": \"lineup-card-player\"}):\n",
        "        for a in li.findAll(\"a\", {\"class\": [\"player-nameplate-name\", \"player-nameplate disabled\"]}):\n",
        "            playername = a.text\n",
        "\n",
        "        listring = str(li)\n",
        "        for span in li.find(\"span\", {\"class\": \"small\"}):\n",
        "            luspot = span.text\n",
        "            luspot = luspot.replace(\"\\n\", \"\")\n",
        "            luspot = luspot.strip()\n",
        "            luspot = int(luspot)\n",
        "        pos = listring[listring.find(\"data-position\")+15:listring.find(\"data-salary\")-2]\n",
        "        sal = listring[listring.find(\"data-salary\")+13:listring.find(\"<span class='small'>\")-3]\n",
        "        ownership = ownership.replace(\"</span>\", \"\")\n",
        "        ownership = ownership.replace(\"</span\", \"\")\n",
        "        ownership = ownership.replace(\"</li\", \"\")\n",
        "        ownership = ownership.replace(\"</div>\", \"\")\n",
        "        ownership = ownership.replace(\" \", \"\")\n",
        "\n",
        "        try:\n",
        "            sal = int(sal)\n",
        "        except:\n",
        "            sal = 0\n",
        "        thisludf = pd.DataFrame([[playername, luspot, sal, ownership]], columns = [\"Player\", \"Spot\", \"Sal\", \"Ownership\"])\n",
        "        ludf = pd.concat([ludf, thisludf])\n",
        "\n",
        "    ludf2 = pd.merge(ludf, BID[[\"Name\", \"Team\"]], left_on = [\"Player\"], right_on = [\"Name\"], how = \"left\").rename(columns = {\"Team\": \"BatterTeam\"})\n",
        "    ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
        "\n",
        "    ludf2_teamlist = list(ludf2[\"BatterTeam\"])\n",
        "\n",
        "    dhteams = []\n",
        "    for x in ludf2_teamlist:\n",
        "        if ludf2_teamlist.count(x) > 11:\n",
        "            if x in dhteams:\n",
        "                pass\n",
        "            else:\n",
        "                dhteams.append(x)\n",
        "\n",
        "    extract_dh = ludf2[ludf2[\"BatterTeam\"].isin(dhteams)]\n",
        "    new_ludf2 = ludf2[~ludf2[\"BatterTeam\"].isin(dhteams)]\n",
        "\n",
        "    new_team_list = []\n",
        "    runcounter = 0\n",
        "\n",
        "    for x in list(extract_dh[\"BatterTeam\"].astype(str)):\n",
        "        if runcounter < 18:\n",
        "            new_team_list.append(x)\n",
        "            runcounter += 1\n",
        "        else:\n",
        "            new_team_list.append(x+\"2\")\n",
        "            runcounter += 1\n",
        "\n",
        "    extract_dh[\"BatterTeam\"] = new_team_list\n",
        "\n",
        "    ludf2 = pd.concat([extract_dh, new_ludf2])\n",
        "    ludf2[\"Opp\"] = ludf2[\"BatterTeam\"].map(oppdict)\n",
        "    ludf2[\"HomeTeam\"] = ludf2[\"BatterTeam\"].map(hometeamdict)\n",
        "    ludf2[\"RoadTeam\"] = ludf2[\"BatterTeam\"].map(roadteamdict)\n",
        "    ludf2['SP'] = ludf2['BatterTeam'].map(opp_spname_dict)\n",
        "    ludf2['SPSal'] = ludf2['BatterTeam'].map(opp_spsal_dict)\n",
        "    ludf2['SPOwnership'] = ludf2['BatterTeam'].map(opp_spown_dict)\n",
        "    ludf2['Date'] = todaysdate\n",
        "    ludf2['Time'] = np.nan\n",
        "\n",
        "    ludf3 = ludf2[['BatterTeam','RoadTeam','HomeTeam','Time','Spot','Player','Sal','Ownership','Date', \"SP\"]]\n",
        "\n",
        "    dkdata = ludf3.copy()\n",
        "\n",
        "    try:\n",
        "        checknan = dkdata[[\"BatterTeam\", \"SP\"]]\n",
        "        getnans = checknan[[\"SP\"].isna()]\n",
        "        if len(getnans) == 0:\n",
        "            nonans = 1\n",
        "            nanmapdict = {}\n",
        "        else:\n",
        "            nonans = 0\n",
        "            getnans[\"SP\"] = disabled_span_list\n",
        "            nanmapdict = dict(zip(getnans.Team, getnans.SP))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        dkdata[\"SP\"] = np.where(dkdata[\"SP\"].isna(), dkdata[\"BatterTeam\"].map(nanmapdict), dkdata[\"SP\"])\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    for i in range(1, len(dkdata) - 1):\n",
        "        if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i-1, 'BatterTeam']:\n",
        "            if dkdata.loc[i, 'BatterTeam'] != dkdata.loc[i+1, 'BatterTeam']:\n",
        "                dkdata.loc[i, 'BatterTeam'] = np.nan\n",
        "                dkdata.loc[i, 'HomeTeam'] = np.nan\n",
        "                dkdata.loc[i, 'RoadTeam'] = np.nan\n",
        "                dkdata.loc[i, 'SP'] = np.nan\n",
        "\n",
        "    \n",
        "    dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n",
        "    dkdata = dkdata.drop_duplicates(subset = [\"BatterTeam\", \"SP\"], keep = \"first\")\n",
        "    dkdata = dkdata.drop(columns = [\"Time\", \"Sal\", \"Ownership\"])\n",
        "\n",
        "    dkdata['BatterTeam'] = dkdata['BatterTeam'].replace('ARI', 'AZ')\n",
        "    dkdata['RoadTeam'] = dkdata['RoadTeam'].replace('ARI', 'AZ')\n",
        "    dkdata['HomeTeam'] = dkdata['HomeTeam'].replace('ARI', 'AZ')\n",
        "\n",
        "    dkdata['Date'] = pd.to_datetime(dkdata['Date'])\n",
        "    dkdata['Date'] = dkdata['Date'].dt.strftime('%Y-%m-%d')\n",
        "    dkdata = dkdata.set_index(\"Date\")\n",
        "    dkdata = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\", \"SP\"]]\n",
        "\n",
        "    return(dkdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loads regular season data from 2022-23 to train on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 651,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "u9X4Ucso25sI",
        "outputId": "72116ab4-f55a-44ac-881a-968f63ba7cb6"
      },
      "outputs": [],
      "source": [
        "#statcast(start_dt = \"2022-04-07\", end_dt = \"2022-10-05\")\n",
        "#statcast(start_dt = \"2023-03-30\", end_dt = \"2023-10-01\")\n",
        "savant2022 = pd.read_csv(\"~/Desktop/Random-Projects/MLB/savant2022.csv\")\n",
        "savant2023 = pd.read_csv(\"~/Desktop/Random-Projects/MLB/savant2023.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 652,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "EHsVm55sraiX",
        "outputId": "400df1ad-6fb9-41af-9620-64bdbdc06119"
      },
      "outputs": [],
      "source": [
        "#pd.set_option('display.max_columns', None)\n",
        "combined1 = pd.concat([savant2022, savant2023])\n",
        "combined1 = combined1[(combined1['inning'] == 1)]\n",
        "combined1['game_date'] = pd.to_datetime(combined1['game_date'])\n",
        "combined1['game_date'] = combined1['game_date'].dt.strftime('%Y-%m-%d')\n",
        "combined1['BatterTeam'] = np.where(combined1['inning_topbot'] == 'Top', combined1['away_team'], combined1['home_team'])\n",
        "combined1['PitcherTeam'] = np.where(combined1['inning_topbot'] == 'Top', combined1['home_team'], combined1['away_team'])\n",
        "combined1[\"player_name\"] = combined1[\"player_name\"].apply(flip_names)\n",
        "combined1[\"player_name\"] = combined1[\"player_name\"].apply(replace_special_chars)\n",
        "combined1['player_name'] = combined1['player_name'].replace('Michael King', 'Mike King')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 653,
      "metadata": {
        "id": "5iXSOF7Jrvap"
      },
      "outputs": [],
      "source": [
        "combined2 = combined1[[\"game_date\", \"home_team\", \"away_team\", \"inning\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\", \"BatterTeam\", \"MLBNAME\", \"events\", \"description\", \"bb_type\", \"estimated_woba_using_speedangle\", \"woba_value\", \"p_throws\", \"PitcherTeam\", \"player_name\", \"delta_home_win_exp\", \"delta_run_exp\", \"away_score\", \"home_score\"]].sort_values(by = [\"game_date\", \"home_team\", \"away_team\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\"], ascending=[True, True, True, False, True, True])\n",
        "combined2 = combined2.set_index(\"game_date\").sort_index(ascending = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grouping on a pitch level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 654,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train1 = combined2.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"at_bat_number\", \"player_name\", \"p_throws\"]).agg(\n",
        "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
        "    GB = ('bb_type', lambda x: (x == 'ground_ball').sum()),\n",
        "    LD = ('bb_type', lambda x: (x == 'line_drive').sum()),\n",
        "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
        "    PU = ('bb_type', lambda x: (x == 'popup').sum()),\n",
        "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
        "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
        "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
        "    HR = (\"events\", lambda x: (x == 'home_run').sum()),\n",
        "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
        "    wOBA = (\"woba_value\", \"mean\"),\n",
        "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
        "    AwayScore = (\"away_score\", \"sum\"),\n",
        "    HomeScore = (\"home_score\", \"sum\")).reset_index().fillna(0)\n",
        "\n",
        "# If there are more than six batters faced it gets rid of the 7th at bat and beyond to prevent skewness\n",
        "Train1[\"BF\"] = Train1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\"])[\"at_bat_number\"].cumcount()\n",
        "Train1 = Train1.drop(Train1[Train1[\"BF\"] >= 6].index, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grouping on an at bat level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 655,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train2 = Train1.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg(\n",
        "    AB = (\"at_bat_number\", \"size\"),\n",
        "    PA = (\"PA\", \"sum\"),\n",
        "    GB = ('GB', \"sum\"),\n",
        "    LD = ('LD', \"sum\"),\n",
        "    FB = ('FB', \"sum\"),\n",
        "    PU = ('PU', \"sum\"),\n",
        "    BB = (\"BB\", \"sum\"),\n",
        "    HBP = (\"HBP\", \"sum\"),\n",
        "    K = (\"K\", \"sum\"),\n",
        "    HR = (\"HR\", \"sum\"),\n",
        "    xwOBA = (\"wOBA\", \"mean\"),\n",
        "    wOBA = (\"wOBA\", \"mean\"),\n",
        "    RunExp = (\"RunExp\", \"mean\"),\n",
        "    AwayScore = (\"AwayScore\", \"sum\"),\n",
        "    HomeScore = (\"HomeScore\", \"sum\")).reset_index().fillna(0)\n",
        "\n",
        "Train2['BB%'] = round((Train2['BB'] / Train2['AB']) * 100, 2)\n",
        "#Train2['HR/9'] = round((Train2['HR'] / Train2['']) * 100, 2)\n",
        "Train2['NRFI'] = np.where((Train2['away_team'] == Train2['BatterTeam']) & (Train2['AwayScore'] == 0), 1, 0)\n",
        "Train2['NRFI'] = np.where((Train2['home_team'] == Train2['BatterTeam']) & (Train2['HomeScore'] == 0), 1, Train2['NRFI'])\n",
        "Train2 = Train2.drop(['AwayScore', 'HomeScore'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding rolling averages for the past 5 and 10 games"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 656,
      "metadata": {},
      "outputs": [],
      "source": [
        "window_size5 = 5\n",
        "window_size10 = 10\n",
        "\n",
        "# For pitchers\n",
        "# Rolling 5 and 10 game NRFI averages\n",
        "Train2['P5'] = Train2.groupby('player_name')['NRFI'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "# Rolling 5 game wOBA and xwOBA averages\n",
        "Train2['P5xwOBA'] = Train2.groupby('player_name')['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "# For batters\n",
        "# Rolling 5 and 10 game NRFI averages\n",
        "Train2['B5'] = Train2.groupby(['BatterTeam', \"p_throws\"])['NRFI'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "Train2['B10'] = Train2.groupby(['BatterTeam', \"p_throws\"])['NRFI'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "# Rolling 5 game wOBA and xwOBA averages\n",
        "Train2['B5xwOBA'] = Train2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "Train2['B10xwOBA'] = Train2.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creates functions for various ERA estimators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 657,
      "metadata": {},
      "outputs": [],
      "source": [
        "def FIP(HR, BB, HBP, K, IP):\n",
        "    fip = (((HR * 13) + (3 * (BB + HBP)) - (2 * K)) / IP + 3.137)\n",
        "    return round(fip, 3)\n",
        "\n",
        "def xFIP(FB, BB, HBP, K, IP):\n",
        "    lgHR = len(combined1[combined1[\"events\"] == \"home_run\"])\n",
        "    lgFB = len(combined1[combined1[\"bb_type\"] == \"fly_ball\"])\n",
        "\n",
        "    xfip = (13 * (FB * (lgHR/lgFB * 0.58)) + 3 * (BB + HBP) - 2 * K) / IP + 3.137\n",
        "    return round(xfip, 3)\n",
        "\n",
        "def SIERA(K, BB, GB, FB, PU, PA):\n",
        "    if PA == 0:\n",
        "        return 0\n",
        "\n",
        "    so_pa = K/PA\n",
        "    bb_pa = BB/PA\n",
        "    gb_pa = GB/PA\n",
        "    fb_pa = FB/PA\n",
        "    pu_pa = PU/PA\n",
        "\n",
        "    SIERA = 6.145 - 16.986 * (so_pa / 100) + 11.434 * (bb_pa / 100) - 1.858 * ((gb_pa - fb_pa - pu_pa) / 100) + 7.653 * (so_pa / 100) ** 2 - 6.664 * ((gb_pa - fb_pa - pu_pa) / 100) ** 2 + 10.130 * (so_pa / 100) * ((gb_pa - fb_pa - pu_pa) / 100) - 5.195 * (bb_pa / 100) * ((gb_pa - fb_pa - pu_pa) / 100)\n",
        "    return round(SIERA, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 658,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train2['FIP'] = Train2.apply(lambda row: FIP(row['HR'], row['BB'], row['HBP'], row['K'], 1), axis=1)\n",
        "Train2[\"AB\"] = Train2[\"AB\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finalizes the cleaned training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 659,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train4 = Train2[[\"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"AB\", \"BB%\", \"wOBA\", \"P5\", \"P5xwOBA\", \"B5\", \"B10\", \"B5xwOBA\", \"B10xwOBA\", \"NRFI\"]].round(3)\n",
        "Train4 = Train4.rename(columns={'away_team': 'RoadTeam', 'home_team': 'HomeTeam', \"player_name\": \"SP\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 660,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_3098/3305814355.py:95: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  ludf2['BatterTeam'] = ludf2['BatterTeam'].fillna(method='ffill')\n",
            "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_3098/3305814355.py:164: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]] = dkdata[[\"BatterTeam\", \"RoadTeam\", \"HomeTeam\"]].fillna(method='ffill')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BatterTeam</th>\n",
              "      <th>RoadTeam</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>SP</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>BOS</td>\n",
              "      <td>BOS</td>\n",
              "      <td>NYY</td>\n",
              "      <td>Gerrit Cole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>NYY</td>\n",
              "      <td>BOS</td>\n",
              "      <td>NYY</td>\n",
              "      <td>Josh Winckowski</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>HOU</td>\n",
              "      <td>HOU</td>\n",
              "      <td>MIN</td>\n",
              "      <td>Joe Ryan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>MIN</td>\n",
              "      <td>HOU</td>\n",
              "      <td>MIN</td>\n",
              "      <td>Hunter Brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>LAA</td>\n",
              "      <td>LAA</td>\n",
              "      <td>CHC</td>\n",
              "      <td>Kyle Hendricks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>CHC</td>\n",
              "      <td>LAA</td>\n",
              "      <td>CHC</td>\n",
              "      <td>Tyler Anderson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>NYM</td>\n",
              "      <td>NYM</td>\n",
              "      <td>PIT</td>\n",
              "      <td>Bailey Falter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>PIT</td>\n",
              "      <td>NYM</td>\n",
              "      <td>PIT</td>\n",
              "      <td>David Peterson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>STL</td>\n",
              "      <td>STL</td>\n",
              "      <td>WSH</td>\n",
              "      <td>MacKenzie Gore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>WSH</td>\n",
              "      <td>STL</td>\n",
              "      <td>WSH</td>\n",
              "      <td>Lance Lynn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>TB</td>\n",
              "      <td>TB</td>\n",
              "      <td>TEX</td>\n",
              "      <td>Andrew Heaney</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>TEX</td>\n",
              "      <td>TB</td>\n",
              "      <td>TEX</td>\n",
              "      <td>Taj Bradley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>BAL</td>\n",
              "      <td>BAL</td>\n",
              "      <td>OAK</td>\n",
              "      <td>Luis Medina</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>OAK</td>\n",
              "      <td>BAL</td>\n",
              "      <td>OAK</td>\n",
              "      <td>Cade Povich</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>SF</td>\n",
              "      <td>SF</td>\n",
              "      <td>CLE</td>\n",
              "      <td>Logan Allen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>CLE</td>\n",
              "      <td>SF</td>\n",
              "      <td>CLE</td>\n",
              "      <td>Kyle Harrison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>TOR</td>\n",
              "      <td>TOR</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Emerson Hancock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>SEA</td>\n",
              "      <td>TOR</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Yariel Rodriguez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>CWS</td>\n",
              "      <td>CWS</td>\n",
              "      <td>MIA</td>\n",
              "      <td>Yonny Chirinos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>MIA</td>\n",
              "      <td>CWS</td>\n",
              "      <td>MIA</td>\n",
              "      <td>Garrett Crochet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>CIN</td>\n",
              "      <td>Hunter Greene</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>CIN</td>\n",
              "      <td>DET</td>\n",
              "      <td>CIN</td>\n",
              "      <td>Alex Faedo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>PHI</td>\n",
              "      <td>PHI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>Spencer Schwellenbach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>ATL</td>\n",
              "      <td>PHI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>Ranger Suarez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>MIL</td>\n",
              "      <td>MIL</td>\n",
              "      <td>LAD</td>\n",
              "      <td>James Paxton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>LAD</td>\n",
              "      <td>MIL</td>\n",
              "      <td>LAD</td>\n",
              "      <td>Freddy Peralta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>KC</td>\n",
              "      <td>KC</td>\n",
              "      <td>COL</td>\n",
              "      <td>Austin Gomber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>COL</td>\n",
              "      <td>KC</td>\n",
              "      <td>COL</td>\n",
              "      <td>Seth Lugo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>AZ</td>\n",
              "      <td>AZ</td>\n",
              "      <td>SD</td>\n",
              "      <td>Matt Waldron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-07-06</th>\n",
              "      <td>SD</td>\n",
              "      <td>AZ</td>\n",
              "      <td>SD</td>\n",
              "      <td>Brandon Pfaadt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           BatterTeam RoadTeam HomeTeam                     SP\n",
              "Date                                                          \n",
              "2024-07-06        BOS      BOS      NYY            Gerrit Cole\n",
              "2024-07-06        NYY      BOS      NYY        Josh Winckowski\n",
              "2024-07-06        HOU      HOU      MIN               Joe Ryan\n",
              "2024-07-06        MIN      HOU      MIN           Hunter Brown\n",
              "2024-07-06        LAA      LAA      CHC         Kyle Hendricks\n",
              "2024-07-06        CHC      LAA      CHC         Tyler Anderson\n",
              "2024-07-06        NYM      NYM      PIT          Bailey Falter\n",
              "2024-07-06        PIT      NYM      PIT         David Peterson\n",
              "2024-07-06        STL      STL      WSH         MacKenzie Gore\n",
              "2024-07-06        WSH      STL      WSH             Lance Lynn\n",
              "2024-07-06         TB       TB      TEX          Andrew Heaney\n",
              "2024-07-06        TEX       TB      TEX            Taj Bradley\n",
              "2024-07-06        BAL      BAL      OAK            Luis Medina\n",
              "2024-07-06        OAK      BAL      OAK            Cade Povich\n",
              "2024-07-06         SF       SF      CLE            Logan Allen\n",
              "2024-07-06        CLE       SF      CLE          Kyle Harrison\n",
              "2024-07-06        TOR      TOR      SEA        Emerson Hancock\n",
              "2024-07-06        SEA      TOR      SEA       Yariel Rodriguez\n",
              "2024-07-06        CWS      CWS      MIA         Yonny Chirinos\n",
              "2024-07-06        MIA      CWS      MIA        Garrett Crochet\n",
              "2024-07-06        DET      DET      CIN          Hunter Greene\n",
              "2024-07-06        CIN      DET      CIN             Alex Faedo\n",
              "2024-07-06        PHI      PHI      ATL  Spencer Schwellenbach\n",
              "2024-07-06        ATL      PHI      ATL          Ranger Suarez\n",
              "2024-07-06        MIL      MIL      LAD           James Paxton\n",
              "2024-07-06        LAD      MIL      LAD         Freddy Peralta\n",
              "2024-07-06         KC       KC      COL          Austin Gomber\n",
              "2024-07-06        COL       KC      COL              Seth Lugo\n",
              "2024-07-06         AZ       AZ       SD           Matt Waldron\n",
              "2024-07-06         SD       AZ       SD         Brandon Pfaadt"
            ]
          },
          "execution_count": 660,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TodaysData = getDKData2024()\n",
        "TodaysData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 661,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a large query, it may take a moment to complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/101 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "  1%|          | 1/101 [00:07<12:25,  7.45s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "  2%|▏         | 2/101 [00:08<05:37,  3.41s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "  3%|▎         | 3/101 [00:08<03:35,  2.20s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "  7%|▋         | 7/101 [00:08<01:00,  1.55it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 11%|█         | 11/101 [00:12<01:04,  1.40it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 15%|█▍        | 15/101 [00:15<01:05,  1.31it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 17%|█▋        | 17/101 [00:16<00:46,  1.82it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 19%|█▉        | 19/101 [00:16<00:32,  2.49it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 20%|█▉        | 20/101 [00:16<00:30,  2.65it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 21%|██        | 21/101 [00:19<01:09,  1.15it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 23%|██▎       | 23/101 [00:20<00:49,  1.56it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 25%|██▍       | 25/101 [00:20<00:34,  2.19it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 26%|██▌       | 26/101 [00:24<01:41,  1.36s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 27%|██▋       | 27/101 [00:24<01:21,  1.11s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 28%|██▊       | 28/101 [00:25<01:02,  1.16it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 29%|██▊       | 29/101 [00:25<00:51,  1.40it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 31%|███       | 31/101 [00:25<00:33,  2.10it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 33%|███▎      | 33/101 [00:26<00:33,  2.02it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 34%|███▎      | 34/101 [00:27<00:30,  2.18it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 35%|███▍      | 35/101 [00:27<00:24,  2.66it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 36%|███▌      | 36/101 [00:27<00:23,  2.73it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 37%|███▋      | 37/101 [00:28<00:26,  2.37it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 38%|███▊      | 38/101 [00:31<01:24,  1.33s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 39%|███▊      | 39/101 [00:32<01:14,  1.20s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 40%|███▉      | 40/101 [00:33<00:57,  1.07it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 42%|████▏     | 42/101 [00:33<00:38,  1.52it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 45%|████▍     | 45/101 [00:34<00:26,  2.14it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 46%|████▌     | 46/101 [00:34<00:23,  2.36it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 47%|████▋     | 47/101 [00:35<00:22,  2.45it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 49%|████▊     | 49/101 [00:35<00:19,  2.62it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 50%|████▉     | 50/101 [00:38<00:46,  1.09it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 50%|█████     | 51/101 [00:41<01:03,  1.28s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 51%|█████▏    | 52/101 [00:41<00:51,  1.05s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 53%|█████▎    | 54/101 [00:41<00:32,  1.46it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 54%|█████▍    | 55/101 [00:42<00:26,  1.70it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 55%|█████▌    | 56/101 [00:42<00:22,  2.02it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 56%|█████▋    | 57/101 [00:42<00:18,  2.37it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 57%|█████▋    | 58/101 [00:42<00:14,  2.87it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 58%|█████▊    | 59/101 [00:43<00:17,  2.35it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 60%|██████    | 61/101 [00:43<00:14,  2.76it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 62%|██████▏   | 63/101 [00:49<00:52,  1.39s/it]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 65%|██████▌   | 66/101 [00:49<00:21,  1.61it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 67%|██████▋   | 68/101 [00:50<00:15,  2.09it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 69%|██████▉   | 70/101 [00:50<00:11,  2.81it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 76%|███████▌  | 77/101 [00:56<00:19,  1.26it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 83%|████████▎ | 84/101 [00:57<00:03,  4.67it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 94%|█████████▍| 95/101 [01:03<00:01,  3.47it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 98%|█████████▊| 99/101 [01:05<00:00,  3.48it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "100%|██████████| 101/101 [01:05<00:00,  1.54it/s]\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pybaseball/statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
          ]
        }
      ],
      "source": [
        "eastern_time = datetime.datetime.now(timezone.utc).astimezone(timezone(datetime.timedelta(hours=-5)))\n",
        "savant2024 = statcast(start_dt = \"2024-03-28\", end_dt = eastern_time.strftime(\"%Y-%m-%d\"))\n",
        "savant2024 = savant2024[(savant2024['inning'] == 1)]\n",
        "savant2024['game_date'] = pd.to_datetime(savant2024['game_date'])\n",
        "savant2024['game_date'] = savant2024['game_date'].dt.strftime('%Y-%m-%d')\n",
        "savant2024['BatterTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['away_team'], savant2024['home_team'])\n",
        "savant2024['PitcherTeam'] = np.where(savant2024['inning_topbot'] == 'Top', savant2024['home_team'], savant2024['away_team'])\n",
        "savant2024 = pd.merge(savant2024, ID[[\"MLBID\", \"MLBNAME\"]], left_on = 'batter', right_on = 'MLBID', how = 'left')\n",
        "savant2024.dropna(subset=['MLBNAME'], inplace=True)\n",
        "savant2024 = savant2024.drop_duplicates(subset = [\"pitch_type\", \"game_date\", \"release_speed\", \"release_pos_x\", \"release_pos_z\", \"player_name\"], keep='first')\n",
        "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(flip_names)\n",
        "savant2024['player_name'] = savant2024['player_name'].replace('Michael King', 'Mike King')\n",
        "savant2024 = savant2024[[\"game_date\", \"home_team\", \"away_team\", \"inning\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\", \"pitch_type\", \"BatterTeam\", \"MLBNAME\", \"balls\", \"strikes\", \"outs_when_up\", \"events\", \"description\", \"bb_type\", \"hit_distance_sc\", \"launch_speed\", \"launch_angle\", \"estimated_ba_using_speedangle\", \"estimated_woba_using_speedangle\", \"woba_value\", \"p_throws\", \"PitcherTeam\", \"player_name\", \"delta_home_win_exp\", \"delta_run_exp\", \"away_score\", \"home_score\"]].sort_values(by = [\"game_date\", \"home_team\", \"away_team\", \"inning_topbot\", \"at_bat_number\", \"pitch_number\"], ascending=[True, True, True, False, True, True])\n",
        "savant2024 = savant2024.set_index(\"game_date\").sort_index(ascending = True)\n",
        "savant2024[\"player_name\"] = savant2024[\"player_name\"].apply(replace_special_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Does the same grouping as the training data at the various levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 662,
      "metadata": {},
      "outputs": [],
      "source": [
        "Season2 = savant2024.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"at_bat_number\", \"player_name\", \"p_throws\"]).agg(\n",
        "    PA = ('events', lambda x: (x.isin(['other_out', 'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'field_error', 'fielders_choice', 'double_play', 'fielders_choice_out', 'strikeout_double_play', 'triple_play', 'grounded_into_double_play'])).sum()),\n",
        "    GB = ('bb_type', lambda x: (x == 'ground_ball').sum()),\n",
        "    LD = ('bb_type', lambda x: (x == 'line_drive').sum()),\n",
        "    FB = ('bb_type', lambda x: (x == 'fly_ball').sum()),\n",
        "    PU = ('bb_type', lambda x: (x == 'popup').sum()),\n",
        "    BB = ('events', lambda x: (x == 'walk').sum()),\n",
        "    HBP = ('events', lambda x: (x == 'hit_by_pitch').sum()),\n",
        "    K = ('events', lambda x: (x == 'strikeout').sum()),\n",
        "    HR = (\"events\", lambda x: (x == 'home_run').sum()),\n",
        "    xwOBA = (\"estimated_woba_using_speedangle\", \"mean\"),\n",
        "    wOBA = (\"woba_value\", \"mean\"),\n",
        "    RunExp = (\"delta_run_exp\", \"mean\"),\n",
        "    AwayScore = (\"away_score\", \"sum\"),\n",
        "    HomeScore = (\"home_score\", \"sum\")).reset_index().fillna(0)\n",
        "\n",
        "# If there are more than six batters faced it gets rid of the 7th at bat and beyond to prevent skewness\n",
        "Season2[\"BF\"] = Season2.groupby([\"BatterTeam\", \"away_team\", \"home_team\", \"player_name\"])[\"at_bat_number\"].cumcount()\n",
        "Season2 = Season2.drop(Season2[Season2[\"BF\"] >= 6].index, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 663,
      "metadata": {},
      "outputs": [],
      "source": [
        "Season3 = Season2.groupby([\"game_date\", \"BatterTeam\", \"away_team\", \"home_team\", \"player_name\", \"p_throws\"]).agg(\n",
        "    AB = (\"at_bat_number\", \"size\"),\n",
        "    PA = (\"PA\", \"sum\"),\n",
        "    GB = ('GB', \"sum\"),\n",
        "    LD = ('LD', \"sum\"),\n",
        "    FB = ('FB', \"sum\"),\n",
        "    PU = ('PU', \"sum\"),\n",
        "    BB = (\"BB\", \"sum\"),\n",
        "    HBP = (\"HBP\", \"sum\"),\n",
        "    K = (\"K\", \"sum\"),\n",
        "    HR = (\"HR\", \"sum\"),\n",
        "    xwOBA = (\"xwOBA\", \"mean\"),\n",
        "    wOBA = (\"wOBA\", \"mean\"),\n",
        "    RunExp = (\"RunExp\", \"mean\"),\n",
        "    AwayScore = (\"AwayScore\", \"sum\"),\n",
        "    HomeScore = (\"HomeScore\", \"sum\")).reset_index().fillna(0)\n",
        "\n",
        "Season3['NRFI'] = np.where((Season3 ['away_team'] == Season3 ['BatterTeam']) & (Season3['AwayScore'] == 0), 1, 0)\n",
        "Season3['NRFI'] = np.where((Season3['home_team'] == Season3['BatterTeam']) & (Season3['HomeScore'] == 0), 1, Season3['NRFI'])\n",
        "Season3 = Season3.drop(['AwayScore', 'HomeScore'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 664,
      "metadata": {},
      "outputs": [],
      "source": [
        "Season3['P5'] = Season3.groupby('player_name')['NRFI'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "Season3['P5xwOBA'] = Season3.groupby('player_name')['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "Season3['B5'] = Season3.groupby(['BatterTeam', \"p_throws\"])['NRFI'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "Season3['B10'] = Season3.groupby(['BatterTeam', \"p_throws\"])['NRFI'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "Season3['B5xwOBA'] = Season3.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size5, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "Season3['B10xwOBA'] = Season3.groupby(['BatterTeam', \"p_throws\"])['xwOBA'].rolling(window=window_size10, min_periods=1).mean().reset_index(level=[0,1], drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 665,
      "metadata": {},
      "outputs": [],
      "source": [
        "Season4 = Season3.groupby([\"player_name\", \"p_throws\"]).agg(\n",
        "    IP = (\"AB\", \"size\"),\n",
        "    AB = (\"AB\", \"sum\"),\n",
        "    PA = (\"PA\", \"sum\"),\n",
        "    BB = (\"BB\", \"sum\"),\n",
        "    HBP = (\"HBP\", \"sum\"),\n",
        "    K = (\"K\", \"sum\"),\n",
        "    GB = ('GB', \"sum\"),\n",
        "    LD = ('LD', \"sum\"),\n",
        "    FB = ('FB', \"sum\"),\n",
        "    PU = ('PU', \"sum\"),\n",
        "    HR = (\"HR\", \"sum\"),\n",
        "    wOBA = (\"wOBA\", \"mean\"),\n",
        "    RunExp = (\"RunExp\", \"mean\"),\n",
        "    NRFI = (\"NRFI\", \"mean\"),\n",
        "    P5 = (\"P5\", \"last\"),\n",
        "    P5xwOBA = (\"P5xwOBA\", \"last\"),\n",
        "    B5 = (\"B5\", \"last\"),\n",
        "    B10 = (\"B10\", \"last\"),\n",
        "    B5xwOBA = (\"B5xwOBA\", \"last\"),\n",
        "    B10xwOBA = (\"B10xwOBA\", \"last\")).reset_index().fillna(0)\n",
        "\n",
        "Season4['BB%'] = round((Season4['BB'] / Season4['AB']) * 100, 2)\n",
        "Season4 = Season4[Season4['player_name'].isin(TodaysData['SP'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 666,
      "metadata": {},
      "outputs": [],
      "source": [
        "Season4['FIP'] = Season4.apply(lambda row: FIP(row['HR'], row['BB'], row['HBP'], row['K'], row['IP']), axis=1)\n",
        "Season4[\"AB\"] = Season4[\"AB\"] / Season4[\"IP\"]\n",
        "Season5 = Season4[[\"player_name\", \"IP\", \"AB\", \"BB%\", \"wOBA\", \"P5\", \"P5xwOBA\", \"B5\", \"B10\", \"B5xwOBA\", \"B10xwOBA\", \"NRFI\"]].round(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data being predicted on takes season first inning averages and gives league average 2022-23 data if no data exists for that player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 667,
      "metadata": {},
      "outputs": [],
      "source": [
        "TodaysData.dropna(subset=['SP'], inplace=True)\n",
        "TodaysData1 = pd.merge(TodaysData, Season5[[\"player_name\", \"IP\", \"AB\", \"BB%\", \"wOBA\", \"P5\", \"P5xwOBA\", \"B5\", \"B10\", \"B5xwOBA\", \"B10xwOBA\", \"NRFI\"]], left_on = ['SP'], right_on = ['player_name'], how = 'left').drop(columns = [\"player_name\"])\n",
        "TodaysData1['IP'] = TodaysData1['IP'].astype(float)\n",
        "\n",
        "# If no 2024 savant data exists then gives them the league averages from 2022-23\n",
        "TrainMeans = Train4.drop(['BatterTeam', 'RoadTeam', \"HomeTeam\", \"SP\"], axis=1).mean()\n",
        "TodaysData1 = TodaysData1.fillna(TrainMeans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encodes the teams and players allowing to be fed into the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 668,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure Train5 and TodaysData2 are copies of Train4 and TodaysData1 respectively\n",
        "Train5 = Train4.copy()\n",
        "TodaysData2 = TodaysData1.copy()\n",
        "\n",
        "# Dictionary to store the label encoders\n",
        "label_encoders = {}\n",
        "\n",
        "# Encode non-numeric columns in Train4\n",
        "non_numeric_columns_train = Train5.select_dtypes(exclude=['float64', 'int64']).columns\n",
        "for col in non_numeric_columns_train:\n",
        "    label_encoder = LabelEncoder()\n",
        "    Train5[col] = label_encoder.fit_transform(Train5[col])\n",
        "    label_encoders[col] = label_encoder\n",
        "\n",
        "# Ensure all non-numeric columns in Train4 are in TodaysData1\n",
        "for col in non_numeric_columns_train:\n",
        "    if col not in TodaysData2.columns:\n",
        "        print(f\"Warning: Column {col} from training data is not present in today's data.\")\n",
        "        # Adding the missing column with a default value\n",
        "        TodaysData2[col] = 536\n",
        "\n",
        "# Encode non-numeric columns in TodaysData1 using the same encoders\n",
        "non_numeric_columns_today = TodaysData2.select_dtypes(exclude=['float64', 'int64']).columns\n",
        "for col in non_numeric_columns_today:\n",
        "    if col in label_encoders:\n",
        "        label_encoder = label_encoders[col]\n",
        "        unique_values = set(label_encoder.classes_)\n",
        "        encoded_values = []\n",
        "        for item in TodaysData2[col]:\n",
        "            if item in unique_values:\n",
        "                encoded_values.append(label_encoder.transform([item])[0])\n",
        "            else:\n",
        "                encoded_values.append(536)  # Using 536 as a placeholder for unknown categories\n",
        "        TodaysData2[col] = encoded_values\n",
        "    else:\n",
        "        print(f\"Warning: Column {col} is not present in the training data.\")\n",
        "        # Fit a new label encoder for columns not present in Train4, but be cautious with this\n",
        "        label_encoder = LabelEncoder()\n",
        "        TodaysData2[col] = label_encoder.fit_transform(TodaysData2[col])\n",
        "        label_encoders[col] = label_encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Runs Random Forest, Gradient Boosting, and Extreme Gradient Boosting models on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 669,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "TrainFeatures = Train5.drop(columns = [\"NRFI\"]).values.reshape(-1, 13)\n",
        "TrainLabel = Train5[\"NRFI\"].values.reshape(-1, 1)\n",
        "TodayFeatures = TodaysData2.drop(columns = [\"IP\", \"NRFI\"]).values.reshape(-1, 13)\n",
        "\n",
        "rf_regressor = RandomForestRegressor(n_estimators = 152, max_depth = 15, min_samples_leaf = 4)\n",
        "rf_regressor.fit(TrainFeatures, TrainLabel)\n",
        "RFpred = rf_regressor.predict(TodayFeatures)\n",
        "\n",
        "TodaysData2[\"RFPred\"] = RFpred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 670,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
          ]
        }
      ],
      "source": [
        "gb_regressor = GradientBoostingRegressor(n_estimators = 106, min_samples_leaf = 4, max_depth=8, max_features='log2', learning_rate=0.1)\n",
        "gb_regressor.fit(TrainFeatures, TrainLabel)\n",
        "GBpred = gb_regressor.predict(TodayFeatures)\n",
        "\n",
        "TodaysData2[\"GBPred\"] = GBpred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 671,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(learning_rate = 0.1, n_estimators= 60, scale_pos_weight=1, max_depth = 35, min_child_weight = 20)\n",
        "xgb_regressor.fit(TrainFeatures, TrainLabel)\n",
        "XGBpred = xgb_regressor.predict(TodayFeatures)\n",
        "\n",
        "TodaysData2[\"XGBPred\"] = XGBpred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 672,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "TrainLabel = TrainLabel.ravel()\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(TrainFeatures, TrainLabel)\n",
        "LogRegProba = log_reg.predict_proba(TodayFeatures)[:, 1]\n",
        "\n",
        "TodaysData2[\"LogPred\"] = LogRegProba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reverse encodes today's data so it can be understood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 673,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bs/6lp27nzn3wvg1ygrkwrcl96w0000gn/T/ipykernel_3098/1190844444.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  TodaysData2[\"SP\"].fillna(TodaysData1[\"SP\"], inplace = True)\n"
          ]
        }
      ],
      "source": [
        "for col in non_numeric_columns_today:\n",
        "    if col in label_encoders:\n",
        "        label_encoder = label_encoders[col]\n",
        "        # Handling default value of 536\n",
        "        TodaysData2[col] = TodaysData2[col].apply(lambda x: label_encoder.inverse_transform([x])[0] if x != 536 else np.nan)\n",
        "\n",
        "TodaysData2[\"SP\"].fillna(TodaysData1[\"SP\"], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 674,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BatterTeam</th>\n",
              "      <th>RoadTeam</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>SP</th>\n",
              "      <th>IP</th>\n",
              "      <th>AB</th>\n",
              "      <th>BB%</th>\n",
              "      <th>wOBA</th>\n",
              "      <th>P5</th>\n",
              "      <th>P5xwOBA</th>\n",
              "      <th>B5</th>\n",
              "      <th>B10</th>\n",
              "      <th>B5xwOBA</th>\n",
              "      <th>B10xwOBA</th>\n",
              "      <th>NRFI</th>\n",
              "      <th>RFPred</th>\n",
              "      <th>GBPred</th>\n",
              "      <th>XGBPred</th>\n",
              "      <th>LogPred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BOS</td>\n",
              "      <td>BOS</td>\n",
              "      <td>NYY</td>\n",
              "      <td>Gerrit Cole</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.478</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.418000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.334000</td>\n",
              "      <td>0.321000</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.399349</td>\n",
              "      <td>0.835476</td>\n",
              "      <td>0.635512</td>\n",
              "      <td>0.854250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NYY</td>\n",
              "      <td>BOS</td>\n",
              "      <td>NYY</td>\n",
              "      <td>Josh Winckowski</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.25</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.186000</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.999791</td>\n",
              "      <td>0.981544</td>\n",
              "      <td>0.992282</td>\n",
              "      <td>0.998509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOU</td>\n",
              "      <td>HOU</td>\n",
              "      <td>MIN</td>\n",
              "      <td>Joe Ryan</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.118</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.287</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.204000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.194000</td>\n",
              "      <td>0.204000</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.992215</td>\n",
              "      <td>0.998288</td>\n",
              "      <td>1.000347</td>\n",
              "      <td>0.978064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MIN</td>\n",
              "      <td>HOU</td>\n",
              "      <td>MIN</td>\n",
              "      <td>Hunter Brown</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.438</td>\n",
              "      <td>8.45</td>\n",
              "      <td>0.315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.997368</td>\n",
              "      <td>1.000242</td>\n",
              "      <td>0.988064</td>\n",
              "      <td>0.996899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LAA</td>\n",
              "      <td>LAA</td>\n",
              "      <td>CHC</td>\n",
              "      <td>Kyle Hendricks</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.57</td>\n",
              "      <td>0.139</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.282000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.195000</td>\n",
              "      <td>0.261000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.011501</td>\n",
              "      <td>1.000743</td>\n",
              "      <td>0.999786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CHC</td>\n",
              "      <td>LAA</td>\n",
              "      <td>CHC</td>\n",
              "      <td>Tyler Anderson</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.353</td>\n",
              "      <td>12.16</td>\n",
              "      <td>0.295</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.306000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.993124</td>\n",
              "      <td>0.953944</td>\n",
              "      <td>1.045350</td>\n",
              "      <td>0.913979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NYM</td>\n",
              "      <td>NYM</td>\n",
              "      <td>PIT</td>\n",
              "      <td>Bailey Falter</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.938</td>\n",
              "      <td>7.94</td>\n",
              "      <td>0.279</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.413000</td>\n",
              "      <td>0.335000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.040957</td>\n",
              "      <td>0.977188</td>\n",
              "      <td>0.996474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PIT</td>\n",
              "      <td>NYM</td>\n",
              "      <td>PIT</td>\n",
              "      <td>David Peterson</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.667</td>\n",
              "      <td>9.09</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.347000</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999942</td>\n",
              "      <td>0.999042</td>\n",
              "      <td>1.000577</td>\n",
              "      <td>0.998827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>STL</td>\n",
              "      <td>STL</td>\n",
              "      <td>WSH</td>\n",
              "      <td>MacKenzie Gore</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.059</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.367000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.395000</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>0.989989</td>\n",
              "      <td>1.048230</td>\n",
              "      <td>0.970518</td>\n",
              "      <td>0.990192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>WSH</td>\n",
              "      <td>STL</td>\n",
              "      <td>WSH</td>\n",
              "      <td>Lance Lynn</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.294</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.245</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.326000</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.983318</td>\n",
              "      <td>0.986418</td>\n",
              "      <td>1.003417</td>\n",
              "      <td>0.994203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>TB</td>\n",
              "      <td>TB</td>\n",
              "      <td>TEX</td>\n",
              "      <td>Andrew Heaney</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.375</td>\n",
              "      <td>12.86</td>\n",
              "      <td>0.268</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.359000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.296000</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.962077</td>\n",
              "      <td>0.976013</td>\n",
              "      <td>0.919337</td>\n",
              "      <td>0.944680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>TEX</td>\n",
              "      <td>TB</td>\n",
              "      <td>TEX</td>\n",
              "      <td>Taj Bradley</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.236</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.305000</td>\n",
              "      <td>0.363000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.995897</td>\n",
              "      <td>1.000553</td>\n",
              "      <td>0.996388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BAL</td>\n",
              "      <td>BAL</td>\n",
              "      <td>OAK</td>\n",
              "      <td>Luis Medina</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>14.81</td>\n",
              "      <td>0.274</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.378000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.989612</td>\n",
              "      <td>1.019031</td>\n",
              "      <td>0.996677</td>\n",
              "      <td>0.921828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>OAK</td>\n",
              "      <td>BAL</td>\n",
              "      <td>OAK</td>\n",
              "      <td>Cade Povich</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>13.04</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.307000</td>\n",
              "      <td>0.327000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.593817</td>\n",
              "      <td>0.461193</td>\n",
              "      <td>0.503897</td>\n",
              "      <td>0.203645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SF</td>\n",
              "      <td>SF</td>\n",
              "      <td>CLE</td>\n",
              "      <td>Logan Allen</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.412</td>\n",
              "      <td>9.33</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.326000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.238000</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.588000</td>\n",
              "      <td>0.453185</td>\n",
              "      <td>0.609079</td>\n",
              "      <td>0.581149</td>\n",
              "      <td>0.309339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CLE</td>\n",
              "      <td>SF</td>\n",
              "      <td>CLE</td>\n",
              "      <td>Kyle Harrison</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.286</td>\n",
              "      <td>6.67</td>\n",
              "      <td>0.316</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.306000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.308000</td>\n",
              "      <td>0.283000</td>\n",
              "      <td>0.786000</td>\n",
              "      <td>0.980260</td>\n",
              "      <td>0.953816</td>\n",
              "      <td>1.002720</td>\n",
              "      <td>0.964512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>TOR</td>\n",
              "      <td>TOR</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Emerson Hancock</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.38</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.316000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.276000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.018159</td>\n",
              "      <td>1.007671</td>\n",
              "      <td>0.996787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SEA</td>\n",
              "      <td>TOR</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Yariel Rodriguez</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.167</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.178</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.265000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.307000</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.986585</td>\n",
              "      <td>0.933293</td>\n",
              "      <td>0.993821</td>\n",
              "      <td>0.956478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CWS</td>\n",
              "      <td>CWS</td>\n",
              "      <td>MIA</td>\n",
              "      <td>Yonny Chirinos</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.667</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.254458</td>\n",
              "      <td>0.216483</td>\n",
              "      <td>0.244649</td>\n",
              "      <td>0.062973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MIA</td>\n",
              "      <td>CWS</td>\n",
              "      <td>MIA</td>\n",
              "      <td>Garrett Crochet</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.174000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.944000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.008764</td>\n",
              "      <td>1.003909</td>\n",
              "      <td>0.997581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>CIN</td>\n",
              "      <td>Hunter Greene</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.118</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.824000</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>1.005656</td>\n",
              "      <td>1.009322</td>\n",
              "      <td>0.990421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>CIN</td>\n",
              "      <td>DET</td>\n",
              "      <td>CIN</td>\n",
              "      <td>Alex Faedo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.908457</td>\n",
              "      <td>7.260057</td>\n",
              "      <td>0.278414</td>\n",
              "      <td>0.727472</td>\n",
              "      <td>0.275811</td>\n",
              "      <td>0.723411</td>\n",
              "      <td>0.723445</td>\n",
              "      <td>0.278234</td>\n",
              "      <td>0.278274</td>\n",
              "      <td>0.723424</td>\n",
              "      <td>0.937971</td>\n",
              "      <td>0.949176</td>\n",
              "      <td>0.898243</td>\n",
              "      <td>0.928120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PHI</td>\n",
              "      <td>PHI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>Spencer Schwellenbach</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.833</td>\n",
              "      <td>13.04</td>\n",
              "      <td>0.149</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.274000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.015735</td>\n",
              "      <td>1.002136</td>\n",
              "      <td>0.999357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ATL</td>\n",
              "      <td>PHI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>Ranger Suarez</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.176</td>\n",
              "      <td>7.04</td>\n",
              "      <td>0.281</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.399000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.309000</td>\n",
              "      <td>0.241000</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.940486</td>\n",
              "      <td>0.883218</td>\n",
              "      <td>0.943435</td>\n",
              "      <td>0.806692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>MIL</td>\n",
              "      <td>MIL</td>\n",
              "      <td>LAD</td>\n",
              "      <td>James Paxton</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.267</td>\n",
              "      <td>14.06</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.217000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.404000</td>\n",
              "      <td>0.379000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.991581</td>\n",
              "      <td>1.004126</td>\n",
              "      <td>0.991842</td>\n",
              "      <td>0.966127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>LAD</td>\n",
              "      <td>MIL</td>\n",
              "      <td>LAD</td>\n",
              "      <td>Freddy Peralta</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.941</td>\n",
              "      <td>11.94</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>0.301000</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.937149</td>\n",
              "      <td>0.879234</td>\n",
              "      <td>0.888435</td>\n",
              "      <td>0.743319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>KC</td>\n",
              "      <td>KC</td>\n",
              "      <td>COL</td>\n",
              "      <td>Austin Gomber</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.688</td>\n",
              "      <td>10.67</td>\n",
              "      <td>0.414</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.389000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.246000</td>\n",
              "      <td>0.273000</td>\n",
              "      <td>0.438000</td>\n",
              "      <td>0.180252</td>\n",
              "      <td>0.289381</td>\n",
              "      <td>0.294168</td>\n",
              "      <td>0.300934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>COL</td>\n",
              "      <td>KC</td>\n",
              "      <td>COL</td>\n",
              "      <td>Seth Lugo</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.889</td>\n",
              "      <td>5.71</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>0.309000</td>\n",
              "      <td>0.889000</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.991878</td>\n",
              "      <td>1.009662</td>\n",
              "      <td>0.993571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>AZ</td>\n",
              "      <td>AZ</td>\n",
              "      <td>SD</td>\n",
              "      <td>Matt Waldron</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.412</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.294000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.292000</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.529000</td>\n",
              "      <td>0.958415</td>\n",
              "      <td>0.994908</td>\n",
              "      <td>1.059425</td>\n",
              "      <td>0.942211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>SD</td>\n",
              "      <td>AZ</td>\n",
              "      <td>SD</td>\n",
              "      <td>Brandon Pfaadt</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.824</td>\n",
              "      <td>7.69</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.428000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.999342</td>\n",
              "      <td>1.008358</td>\n",
              "      <td>1.023914</td>\n",
              "      <td>0.999317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   BatterTeam RoadTeam HomeTeam                     SP    IP        AB  \\\n",
              "0         BOS      BOS      NYY            Gerrit Cole   3.0       5.0   \n",
              "1         NYY      BOS      NYY        Josh Winckowski   4.0       4.0   \n",
              "2         HOU      HOU      MIN               Joe Ryan  17.0     4.118   \n",
              "3         MIN      HOU      MIN           Hunter Brown  16.0     4.438   \n",
              "4         LAA      LAA      CHC         Kyle Hendricks  10.0       3.5   \n",
              "5         CHC      LAA      CHC         Tyler Anderson  17.0     4.353   \n",
              "6         NYM      NYM      PIT          Bailey Falter  16.0     3.938   \n",
              "7         PIT      NYM      PIT         David Peterson   6.0     3.667   \n",
              "8         STL      STL      WSH         MacKenzie Gore  17.0     4.059   \n",
              "9         WSH      STL      WSH             Lance Lynn  17.0     4.294   \n",
              "10         TB       TB      TEX          Andrew Heaney  16.0     4.375   \n",
              "11        TEX       TB      TEX            Taj Bradley  10.0       4.0   \n",
              "12        BAL      BAL      OAK            Luis Medina   6.0       4.5   \n",
              "13        OAK      BAL      OAK            Cade Povich   5.0       4.6   \n",
              "14         SF       SF      CLE            Logan Allen  17.0     4.412   \n",
              "15        CLE       SF      CLE          Kyle Harrison  14.0     4.286   \n",
              "16        TOR      TOR      SEA        Emerson Hancock   8.0       4.0   \n",
              "17        SEA      TOR      SEA       Yariel Rodriguez   6.0     4.167   \n",
              "18        CWS      CWS      MIA         Yonny Chirinos   3.0     4.667   \n",
              "19        MIA      CWS      MIA        Garrett Crochet  18.0       3.5   \n",
              "20        DET      DET      CIN          Hunter Greene  17.0     4.118   \n",
              "21        CIN      DET      CIN             Alex Faedo   NaN  3.908457   \n",
              "22        PHI      PHI      ATL  Spencer Schwellenbach   6.0     3.833   \n",
              "23        ATL      PHI      ATL          Ranger Suarez  17.0     4.176   \n",
              "24        MIL      MIL      LAD           James Paxton  15.0     4.267   \n",
              "25        LAD      MIL      LAD         Freddy Peralta  17.0     3.941   \n",
              "26         KC       KC      COL          Austin Gomber  16.0     4.688   \n",
              "27        COL       KC      COL              Seth Lugo  18.0     3.889   \n",
              "28         AZ       AZ       SD           Matt Waldron  17.0     4.412   \n",
              "29         SD       AZ       SD         Brandon Pfaadt  17.0     3.824   \n",
              "\n",
              "         BB%      wOBA        P5   P5xwOBA        B5       B10   B5xwOBA  \\\n",
              "0       20.0     0.478  0.667000  0.418000  0.800000  0.900000  0.334000   \n",
              "1       6.25     0.202  0.750000  0.451000  1.000000  0.800000  0.186000   \n",
              "2       2.86     0.287  0.800000  0.204000  1.000000  0.900000  0.194000   \n",
              "3       8.45     0.315  1.000000  0.200000  1.000000  0.900000  0.259000   \n",
              "4       8.57     0.139  1.000000  0.282000  1.000000  0.800000  0.195000   \n",
              "5      12.16     0.295  0.600000  0.306000  0.800000  0.900000  0.315000   \n",
              "6       7.94     0.279  0.800000  0.383000  0.800000  0.800000  0.413000   \n",
              "7       9.09      0.19  1.000000  0.396000  0.600000  0.700000  0.347000   \n",
              "8        8.7      0.26  0.800000  0.367000  0.600000  0.700000  0.475000   \n",
              "9       8.22     0.245  0.800000  0.375000  0.800000  0.700000  0.344000   \n",
              "10     12.86     0.268  0.600000  0.359000  0.800000  0.800000  0.296000   \n",
              "11       5.0     0.236  1.000000  0.176000  0.800000  0.900000  0.305000   \n",
              "12     14.81     0.274  0.600000  0.340000  0.800000  0.600000  0.290000   \n",
              "13     13.04      0.29  0.400000  0.259000  0.600000  0.600000  0.307000   \n",
              "14      9.33     0.353  0.400000  0.326000  0.800000  0.600000  0.238000   \n",
              "15      6.67     0.316  0.600000  0.306000  1.000000  0.900000  0.308000   \n",
              "16      9.38     0.206  0.800000  0.316000  1.000000  0.700000  0.191000   \n",
              "17      12.0     0.178  0.600000  0.265000  0.800000  0.600000  0.307000   \n",
              "18      7.14     0.368  0.333000  0.288000  0.600000  0.700000  0.337000   \n",
              "19      1.59     0.101  1.000000  0.174000  0.800000  0.600000  0.184000   \n",
              "20      10.0     0.272  0.800000  0.312000  1.000000  0.700000  0.170000   \n",
              "21  7.260057  0.278414  0.727472  0.275811  0.723411  0.723445  0.278234   \n",
              "22     13.04     0.149  1.000000  0.274000  0.800000  0.700000  0.290000   \n",
              "23      7.04     0.281  0.600000  0.399000  0.600000  0.800000  0.309000   \n",
              "24     14.06     0.227  0.800000  0.217000  0.600000  0.700000  0.404000   \n",
              "25     11.94     0.276  0.600000  0.255000  0.600000  0.700000  0.342000   \n",
              "26     10.67     0.414  0.400000  0.389000  0.800000  0.800000  0.246000   \n",
              "27      5.71     0.208  0.800000  0.249000  0.800000  0.800000  0.371000   \n",
              "28       8.0     0.369  0.800000  0.294000  0.800000  0.900000  0.292000   \n",
              "29      7.69     0.223  0.800000  0.428000  1.000000  0.700000  0.280000   \n",
              "\n",
              "    B10xwOBA      NRFI    RFPred    GBPred   XGBPred   LogPred  \n",
              "0   0.321000  0.667000  0.399349  0.835476  0.635512  0.854250  \n",
              "1   0.253000  0.750000  0.999791  0.981544  0.992282  0.998509  \n",
              "2   0.204000  0.706000  0.992215  0.998288  1.000347  0.978064  \n",
              "3   0.325000  0.688000  0.997368  1.000242  0.988064  0.996899  \n",
              "4   0.261000  1.000000  1.000000  1.011501  1.000743  0.999786  \n",
              "5   0.260000  0.706000  0.993124  0.953944  1.045350  0.913979  \n",
              "6   0.335000  0.750000  1.000000  1.040957  0.977188  0.996474  \n",
              "7   0.337000  1.000000  0.999942  0.999042  1.000577  0.998827  \n",
              "8   0.395000  0.882000  0.989989  1.048230  0.970518  0.990192  \n",
              "9   0.326000  0.706000  0.983318  0.986418  1.003417  0.994203  \n",
              "10  0.259000  0.688000  0.962077  0.976013  0.919337  0.944680  \n",
              "11  0.363000  0.800000  1.000000  0.995897  1.000553  0.996388  \n",
              "12  0.378000  0.500000  0.989612  1.019031  0.996677  0.921828  \n",
              "13  0.327000  0.400000  0.593817  0.461193  0.503897  0.203645  \n",
              "14  0.249000  0.588000  0.453185  0.609079  0.581149  0.309339  \n",
              "15  0.283000  0.786000  0.980260  0.953816  1.002720  0.964512  \n",
              "16  0.276000  0.750000  1.000000  1.018159  1.007671  0.996787  \n",
              "17  0.295000  0.667000  0.986585  0.933293  0.993821  0.956478  \n",
              "18  0.312000  0.333000  0.254458  0.216483  0.244649  0.062973  \n",
              "19  0.253000  0.944000  1.000000  1.008764  1.003909  0.997581  \n",
              "20  0.208000  0.824000  0.979754  1.005656  1.009322  0.990421  \n",
              "21  0.278274  0.723424  0.937971  0.949176  0.898243  0.928120  \n",
              "22  0.325000  1.000000  1.000000  1.015735  1.002136  0.999357  \n",
              "23  0.241000  0.706000  0.940486  0.883218  0.943435  0.806692  \n",
              "24  0.379000  0.800000  0.991581  1.004126  0.991842  0.966127  \n",
              "25  0.301000  0.706000  0.937149  0.879234  0.888435  0.743319  \n",
              "26  0.273000  0.438000  0.180252  0.289381  0.294168  0.300934  \n",
              "27  0.309000  0.889000  0.999983  0.991878  1.009662  0.993571  \n",
              "28  0.253000  0.529000  0.958415  0.994908  1.059425  0.942211  \n",
              "29  0.304000  0.765000  0.999342  1.008358  1.023914  0.999317  "
            ]
          },
          "execution_count": 674,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TodaysData2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiplies the predictions of each game together as they are independent events\n",
        "## Creates a score composite of the various model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 675,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Games</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(NYM, PIT)</th>\n",
              "      <td>0.813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(AZ, SD)</th>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(STL, WSH)</th>\n",
              "      <td>0.802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(HOU, MIN)</th>\n",
              "      <td>0.799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CHC, LAA)</th>\n",
              "      <td>0.792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(SEA, TOR)</th>\n",
              "      <td>0.786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(TB, TEX)</th>\n",
              "      <td>0.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CIN, DET)</th>\n",
              "      <td>0.742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(ATL, PHI)</th>\n",
              "      <td>0.718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(LAD, MIL)</th>\n",
              "      <td>0.678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(BOS, NYY)</th>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CLE, SF)</th>\n",
              "      <td>0.340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(BAL, OAK)</th>\n",
              "      <td>0.305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(COL, KC)</th>\n",
              "      <td>0.149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(CWS, MIA)</th>\n",
              "      <td>0.086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Score\n",
              "Games            \n",
              "(NYM, PIT)  0.813\n",
              "(AZ, SD)    0.807\n",
              "(STL, WSH)  0.802\n",
              "(HOU, MIN)  0.799\n",
              "(CHC, LAA)  0.792\n",
              "(SEA, TOR)  0.786\n",
              "(TB, TEX)   0.764\n",
              "(CIN, DET)  0.742\n",
              "(ATL, PHI)  0.718\n",
              "(LAD, MIL)  0.678\n",
              "(BOS, NYY)  0.518\n",
              "(CLE, SF)   0.340\n",
              "(BAL, OAK)  0.305\n",
              "(COL, KC)   0.149\n",
              "(CWS, MIA)  0.086"
            ]
          },
          "execution_count": 675,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TodaysData2[[\"RFPred\", \"GBPred\", \"XGBPred\", \"LogPred\"]] = TodaysData2[[\"RFPred\", \"GBPred\", \"XGBPred\", \"LogPred\"]].sub(0.1)\n",
        "TodaysData3 = TodaysData2.groupby([\"RoadTeam\", \"HomeTeam\"])[[\"RFPred\", \"GBPred\", \"XGBPred\", \"LogPred\"]].prod().reset_index()\n",
        "\n",
        "TodaysData3['Games'] = TodaysData3.apply(lambda x: tuple(sorted([x['RoadTeam'], x['HomeTeam']])), axis=1)\n",
        "TodaysData3['Score'] = TodaysData3[['RFPred', 'GBPred', \"XGBPred\", \"LogPred\"]].mean(axis=1)\n",
        "TodaysData4 = TodaysData3.set_index(\"Games\").drop(columns = [\"RoadTeam\", \"HomeTeam\"]).sort_values(\"Score\", ascending = False).drop(columns = [\"RFPred\", \"GBPred\", \"XGBPred\", \"LogPred\"]).round(3)\n",
        "TodaysData4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writes this to an excel file creating a sheet so the daily performance can be tracked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 676,
      "metadata": {},
      "outputs": [],
      "source": [
        "excel_file = 'NRFI-Tracker.xlsx'\n",
        "\n",
        "# If deleting the mode and engine it rewrites the whole file\n",
        "with pd.ExcelWriter(excel_file, mode='a', engine='openpyxl') as writer:\n",
        "    TodaysData4.reset_index().to_excel(writer, index=False, sheet_name = eastern_time.strftime(\"%m-%d-%y\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
